<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>rustWood</title>
        <link>https://rusthx.github.io/</link>
        <description>Recent content on rustWood</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>rustWood</copyright>
        <lastBuildDate>Sun, 02 Feb 2025 22:44:44 +0800</lastBuildDate><atom:link href="https://rusthx.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>DataX 编译插件</title>
        <link>https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/</link>
        <pubDate>Sun, 02 Feb 2025 22:44:44 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/</guid>
        <description>&lt;p&gt;我出于自身需要，已经编译好了doriswriter和clickhousewriter，有相同需求的可以直接云盘下载。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://wwsx.lanzouw.com/b00y9w9ovg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wwsx.lanzouw.com/b00y9w9ovg&lt;/a&gt;
密码:byxl&lt;/p&gt;
&lt;p&gt;前置准备工作：准备一个JDK8及以上，安装好maven。&lt;/p&gt;
&lt;h2 id=&#34;拉取datax源码&#34;&gt;拉取DataX源码
&lt;/h2&gt;&lt;p&gt;这里有两种方法，一种是通过git直接拉取DataX的项目代码。另外一种则是下载项目提供的打包源码。
&lt;img src=&#34;https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/1.png&#34;
	width=&#34;1830&#34;
	height=&#34;1014&#34;
	srcset=&#34;https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/1_hu10951412409216039274.png 480w, https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/1_hu5380446507320320259.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;拉取源代码
建立一个空文件夹，然后在文件夹内执行如下命令：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/alibaba/DataX.git
cd DataX
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;下载源码
直接下载压缩包，然后解压打开文件夹即可。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;全量编译项目&#34;&gt;全量编译项目
&lt;/h2&gt;&lt;p&gt;执行命令：&lt;code&gt;mvn clean package&lt;/code&gt;。这个命令会清理之前的构建输出 (clean) 并重新打包项目 (package)。它会遍历所有模块，执行测试，并生成最终的 jar 文件和其他构建产物。这一步需要保证网络畅通，因为编译时Maven需要从远程仓管下载所需的依赖库。&lt;/p&gt;
&lt;p&gt;顺利地话到这里就解决了，但是很显然没这么简单。接下来会语句一堆报错，而且还是我们所不关心的插件。那可不可以使用尚硅谷教程里提供的已经编译好的DataX呢？&lt;/p&gt;
&lt;h2 id=&#34;单独编译需要的插件&#34;&gt;单独编译需要的插件
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;注：Doris官网中编译doriswriter插件是在Linux中执行shell命令。我懒得再建一个Linux环境。就放弃了这条路线。
使用Linux的可以直接查看&lt;a class=&#34;link&#34; href=&#34;https://doris.apache.org/zh-CN/docs/2.0/ecosystem/datax&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Doris官网的相关部分&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;尚硅谷提供的已经编译好的压缩包虽然好，但是我所需要的&lt;code&gt;doriswriter&lt;/code&gt;插件是很早期的插件。和我现在用的Doris2.1.7不兼容。
那我就需要自行编译&lt;code&gt;doriswriter&lt;/code&gt;插件，然后将编译好的jar包替换尚硅谷提供的压缩包里的jar包。&lt;/p&gt;
&lt;p&gt;在doriswriter目录下执行&lt;code&gt;mvn clean package -DskipTests&lt;/code&gt;就可以得到所需jar包。&lt;/p&gt;
&lt;p&gt;然后就遇见了以下报错：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[ERROR] Failed to execute goal on project doriswriter: Could not resolve dependencies for project com.alibaba.datax:doriswriter:jar:0.0.1-SNAPSHOT: The following artifacts could not be
 resolved: com.alibaba.datax:datax-common:jar:0.0.1-SNAPSHOT, com.alibaba.datax:plugin-rdbms-util:jar:0.0.1-SNAPSHOT: Could not find artifact com.alibaba.datax:datax-common:jar:0.0.1-S
NAPSHOT in central (https://maven.aliyun.com/repository/central) -&amp;gt; [Help 1]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从错误信息来看，Maven 在尝试编译 doriswriter 插件时无法找到依赖项 datax-common 和 plugin-rdbms-util。这是因为这些依赖项没有在中央仓库中可用，它们是 DataX 项目内部的模块。&lt;/p&gt;
&lt;p&gt;所以需要先确保 DorisWriter 插件依赖的模块（ datax-common 和 plugin-rdbms-util）已经被正确安装到本地 Maven 仓库中。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd common
mvn clean install -DskipTests

cd ../plugin-rdbms-util
mvn clean install -DskipTests

cd ../doriswriter/
mvn clean package -DskipTests
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common&amp;gt;mvn clean install -DskipTests
[INFO] Scanning for projects...
[INFO]
[INFO] -------------------&amp;lt; com.alibaba.datax:datax-common &amp;gt;-------------------
[INFO] Building datax-common 0.0.1-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[INFO]
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ datax-common ---
[INFO] Deleting D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ datax-common ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] Copying 6 resources
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ datax-common ---
[INFO] Compiling 45 source files to D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\target\classes
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ datax-common ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\src\test\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ datax-common ---
[INFO] No sources to compile
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ datax-common ---
[INFO] Tests are skipped.
[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ datax-common ---
[INFO] Building jar: D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\target\datax-common-0.0.1-SNAPSHOT.jar
[INFO]
[INFO] --- maven-install-plugin:2.4:install (default-install) @ datax-common ---
[INFO] Installing D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\target\datax-common-0.0.1-SNAPSHOT.jar to D:\maven-3.8.6\respository\com\alibaba\datax\datax-common\0.0.1-SNAPSHOT\datax-common-0.0.1-SNAPSHOT.jar
[INFO] Installing D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common\pom.xml to D:\maven-3.8.6\respository\com\alibaba\datax\datax-common\0.0.1-SNAPSHOT\datax-common-0.0.1-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  2.041 s
[INFO] Finished at: 2025-02-03T17:26:33+08:00
[INFO] ------------------------------------------------------------------------

D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\common&amp;gt;cd ../plugin-rdbms-util

D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util&amp;gt;mvn clean install -DskipTests
[INFO] Scanning for projects...
[INFO]
[INFO] ----------------&amp;lt; com.alibaba.datax:plugin-rdbms-util &amp;gt;-----------------
[INFO] Building plugin-rdbms-util 0.0.1-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
Downloading from spring: https://maven.aliyun.com/repository/spring/com/alibaba/datax/datax-all/0.0.1-SNAPSHOT/maven-metadata.xml
Downloading from central: https://maven.aliyun.com/repository/central/com/alibaba/datax/datax-all/0.0.1-SNAPSHOT/maven-metadata.xml
[INFO]
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ plugin-rdbms-util ---
[INFO] Deleting D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ plugin-rdbms-util ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] Copying 0 resource
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ plugin-rdbms-util ---
[INFO] Compiling 25 source files to D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\target\classes
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ plugin-rdbms-util ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\src\test\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ plugin-rdbms-util ---
[INFO] No sources to compile
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ plugin-rdbms-util ---
[INFO] Tests are skipped.
[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ plugin-rdbms-util ---
[INFO] Building jar: D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\target\plugin-rdbms-util-0.0.1-SNAPSHOT.jar
[INFO]
[INFO] --- maven-install-plugin:2.4:install (default-install) @ plugin-rdbms-util ---
[INFO] Installing D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\target\plugin-rdbms-util-0.0.1-SNAPSHOT.jar to D:\maven-3.8.6\respository\com\alibaba\datax\plugin-rdbms-util\0.0.1-SNAPSHOT\plugin-rdbms-util-0.0.1-SNAPSHOT.jar
[INFO] Installing D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util\pom.xml to D:\maven-3.8.6\respository\com\alibaba\datax\plugin-rdbms-util\0.0.1-SNAPSHOT\plugin-rdbms-util-0.0.1-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  2.183 s
[INFO] Finished at: 2025-02-03T17:27:38+08:00
[INFO] ------------------------------------------------------------------------

D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\plugin-rdbms-util&amp;gt;cd ../doriswriter/

D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter&amp;gt;mvn clean package -DskipTests
[INFO] Scanning for projects...
[INFO]
[INFO] -------------------&amp;lt; com.alibaba.datax:doriswriter &amp;gt;--------------------
[INFO] Building doriswriter 0.0.1-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[INFO]
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ doriswriter ---
[INFO] Deleting D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ doriswriter ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] Copying 0 resource
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ doriswriter ---
[INFO] Compiling 13 source files to D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\target\classes
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ doriswriter ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\src\test\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ doriswriter ---
[INFO] No sources to compile
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ doriswriter ---
[INFO] Tests are skipped.
[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ doriswriter ---
[INFO] Building jar: D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\target\doriswriter-0.0.1-SNAPSHOT.jar
[INFO]
[INFO] --- maven-assembly-plugin:2.2-beta-5:single (dwzip) @ doriswriter ---
[INFO] Reading assembly descriptor: src/main/assembly/package.xml
[INFO] Copying files to D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\target\datax
[WARNING] Assembly file: D:\DeskTop\煊\笔记\DataX\DataX-datax_v202309\doriswriter\target\datax is not a regular file (it may be a directory). It cannot be attached to the project build for installation or deployment.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  2.912 s
[INFO] Finished at: 2025-02-03T17:28:12+08:00
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;成功完成编译，这时候就可以在&lt;code&gt;doriswriter/target&lt;/code&gt;目录下看到生成的 JAR 文件
&lt;img src=&#34;https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/2.png&#34;
	width=&#34;892&#34;
	height=&#34;329&#34;
	srcset=&#34;https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/2_hu15743830796818348885.png 480w, https://rusthx.github.io/p/datax-%E7%BC%96%E8%AF%91%E6%8F%92%E4%BB%B6/2_hu3655523356224308540.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;271&#34;
		data-flex-basis=&#34;650px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;然后再替换旧的插件。旧的插件放在&lt;code&gt;datax\datax\plugin\writer\doriswriter&lt;/code&gt;。
注意不是在&lt;code&gt;datax\plugin\writer\doriswriter&lt;/code&gt;里。&lt;/p&gt;
&lt;h2 id=&#34;补充报错&#34;&gt;补充报错
&lt;/h2&gt;&lt;p&gt;实际在使用时还遇见了找不到 com.alibaba.fastjson2.JSON 类。的报错。这个错误通常是由于缺少必要的依赖库或版本不匹配导致的。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;DataX运行报错Exception in thread &amp;quot;Thread-1&amp;quot; java.lang.NoClassDefFoundError: com/alibaba/fastjson2/JSON
	at com.alibaba.datax.plugin.writer.doriswriter.DorisStreamLoadObserver.put(DorisStreamLoadObserver.java:186)
	at com.alibaba.datax.plugin.writer.doriswriter.DorisStreamLoadObserver.streamLoad(DorisStreamLoadObserver.java:63)
	at com.alibaba.datax.plugin.writer.doriswriter.DorisWriterManager.asyncFlush(DorisWriterManager.java:163)
	at com.alibaba.datax.plugin.writer.doriswriter.DorisWriterManager.access$000(DorisWriterManager.java:19)
	at com.alibaba.datax.plugin.writer.doriswriter.DorisWriterManager$1.run(DorisWriterManager.java:134)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: com.alibaba.fastjson2.JSON
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 6 more
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在&lt;code&gt;datax\datax\plugin\writer\doriswriter\lib&lt;/code&gt;下有Doris插件所需的工具包，这里有一个&lt;code&gt;fastjson-1.1.46.sec10.jar&lt;/code&gt;。果然是版本依赖错误。
直接下载最新版本的fastjson2，替换这个jar包。
下面这个命令直接在lib文件夹下执行，会直接下在jar包到当前目录下。下载好后记得删除或者将原来的jar包改后缀。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://repo1.maven.org/maven2/com/alibaba/fastjson2/fastjson2/2.0.3/fastjson2-2.0.3.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后就能正常执行了。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>MySQL主从复制</title>
        <link>https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
        <pubDate>Fri, 24 Jan 2025 22:23:10 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</guid>
        <description>&lt;p&gt;主从复制可以用来做数据库的实时备份，保证数据的完整性；也可以做读写分离，提升数据库系统整体的读写性能。&lt;/p&gt;
&lt;h2 id=&#34;主从复制原理&#34;&gt;主从复制原理
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://xiaolincoding.com/mysql/log/how_update.html#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0
&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/2.png&#34;
	width=&#34;960&#34;
	height=&#34;405&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/2_hu12276740477023013187.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/2_hu11267129864193341543.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;568px&#34;
	
&gt;
MySQL集群的主从复制过程梳理成3个阶段：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。&lt;/li&gt;
&lt;li&gt;同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。&lt;/li&gt;
&lt;li&gt;回放 Binlog：回放 binlog，并更新存储引l擎中的数据。
具体详细过程如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;MySQL 主库在收到客户端提交事务的请求之后，会先写入binlog，再提交事务，更新存储引擎中的数
据，事务提交完成后，返回给客户端&amp;quot;操作成功&amp;quot;的响应。&lt;/li&gt;
&lt;li&gt;从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把
binlog 信息写入 relay log 的中继日志里，再返回给主库&amp;quot;复制成功&amp;quot;的响应。&lt;/li&gt;
&lt;li&gt;从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中
的数据，最终实现主从的数据一致性。
在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者
锁记录，也不会影响读请求的执行。
&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/3.png&#34;
	width=&#34;612&#34;
	height=&#34;607&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/3_hu14524736388878011446.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/3_hu12211041723728468306.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;241px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;主从复制配置&#34;&gt;主从复制配置
&lt;/h2&gt;&lt;h3 id=&#34;前置工作&#34;&gt;前置工作
&lt;/h3&gt;&lt;p&gt; 在两台机上分别安装MySQL,相关教程可查看我的相关博客&lt;a class=&#34;link&#34; href=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ubuntu22.04安装MySQL8.0.35&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/1.png&#34;
	width=&#34;1074&#34;
	height=&#34;906&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/1_hu9957867129983456533.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/1_hu13404604853172762023.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;284px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;hadoop1和hadoop2两台机上都将安装好MySQL，然后hadoop1将作为主节点，hadoop2将作为从节点。主节点提前创建用户用来进行主从连接。注意要给&lt;code&gt;slave&lt;/code&gt;权限&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CREATE USER &#39;rust&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;
GRANT REPLICATION SLAVE ON *.* TO &#39;rust&#39;@&#39;%&#39; WITH GRANT OPTION;
FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;修改配置文件&#34;&gt;修改配置文件
&lt;/h3&gt;&lt;p&gt;修改主库配置文件如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo gedit /etc/mysql/my.cnf
# 也可以通过vim修改，命令如下。
#sudo vim /etc/mysql/my.cnf

# 添加如下内容
[mysqld]

server-id = 1
log-bin=mysql-bin
binlog_format=row #这一行可省略，因为MySQL在5.7.7开始的默认值就是row了

binlog-do-db=master_try #用来主从复制的数据库。需要提前创建
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/4.png&#34;
	width=&#34;1142&#34;
	height=&#34;796&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/4_hu17169091789042476138.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/4_hu11920911155031730745.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;修改后保存重启生效。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo systemctl restart mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改从库配置文件如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[mysqld]
server-id=2 # 从数据库的唯一标识符，通常大于主数据库的server-id
relay-log=mysql-relay-bin # 启用中继日志，用于在从数据库上复制主数据库的操作
read-only=1 # 设置从数据库为只读，防止在从数据库上直接写入数据
enforce_gtid_consistency = ON
gtid_mode = ON
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/5.png&#34;
	width=&#34;1288&#34;
	height=&#34;672&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/5_hu13300301466352054486.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/5_hu5035409371873853278.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;460px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;登录从库连接到主库&#34;&gt;登录从库，连接到主库
&lt;/h3&gt;&lt;p&gt;登录主库，查看所需信息：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mysql -uroot -p
show master status;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/6.png&#34;
	width=&#34;1031&#34;
	height=&#34;590&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/6_hu6635927571981079756.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/6_hu14305490593648961526.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;419px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;登录从库&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mysql -uroot -p                                  #登录mysql
CHANGE MASTER TO MASTER_HOST=&#39;192.168.146.161&#39;,  #指向主库             
MASTER_USER=&#39;rust&#39;,                              #用于复制的MySQL账户,需要提前给定权限
MASTER_PASSWORD=&#39;123456&#39;,                        #密码
MASTER_LOG_FILE=&#39;mysql-bin.000093&#39;,              #主库bin log名称，主库上用SHOW MASTER STATUS查看
MASTER_LOG_POS=197;                              #主库bin log位置，主库上用SHOW MASTER STATUS查看
                      
START SLAVE;                                     #启动从库进程
SHOW SLAVE STATUS\G;                             #显示进程状态

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/7.png&#34;
	width=&#34;973&#34;
	height=&#34;754&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/7_hu14326689744804357760.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/7_hu13688712789841800896.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;309px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/8.png&#34;
	width=&#34;1293&#34;
	height=&#34;885&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/8_hu18223804750484652481.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/8_hu6435194916313471316.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;350px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;注意这里一定要出现两个Yes才行。&lt;/p&gt;
&lt;h3 id=&#34;测试&#34;&gt;测试
&lt;/h3&gt;&lt;p&gt;登录主库，建表插入如下数据。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;use master_try;
create table student(
    `id` int auto_increment primary key,
    `name` varchar(50),
    `age` int
);

insert into student(id,`name`,age) values (&#39;1&#39;,&#39;姬丝秀忒·雅赛劳拉莉昂·刃下心&#39;,&#39;598&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/9.png&#34;
	width=&#34;1016&#34;
	height=&#34;347&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/9_hu5200674971078331333.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/9_hu3142568949465835453.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;292&#34;
		data-flex-basis=&#34;702px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;登录从库，查看建表及插入情况。
&lt;img src=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/10.png&#34;
	width=&#34;1294&#34;
	height=&#34;829&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/10_hu10252075385053311553.png 480w, https://rusthx.github.io/p/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/10_hu14866522803788232565.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;156&#34;
		data-flex-basis=&#34;374px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同步成功，完成主从复制搭建。&lt;/p&gt;
&lt;h3 id=&#34;踩坑与备注&#34;&gt;踩坑与备注
&lt;/h3&gt;&lt;h3 id=&#34;slave_io_runningno&#34;&gt;slave_io_running：no
&lt;/h3&gt;&lt;p&gt; 这是因为从库连接主库填写的信息有误，比如log_file和pos。补救方法，在从库执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;stop slave;

reset slave all;

#再执行一遍正确的连接主库命令
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;从库show-slave-statusg正常但查看不到主库数据&#34;&gt;从库show slave status\G;正常，但查看不到主库数据
&lt;/h3&gt;&lt;p&gt; 这种是主库建的数据库和主库配置文件开启的数据库不同导致的，也就是说主库没有建立配置文件里的数据库。
（我呆得不行，主库配置文件里写的master_try，结果我建表转眼就建成mastertry。查不到数据我还以为是权限的问题，走了好多弯路）&lt;/p&gt;
&lt;!-- ### MySQL新版本相关命令已改变
&gt;参考：https://www.cnblogs.com/architectforest/p/18429705

1. show master status; 不能用了
```shell
# mysql 8.4版本前使用这条命令查看
show master status; 

# MySQL 8.4版本后使用这条命令查看
SHOW BINARY LOG STATUS;
```
2. change master to不能用了
```shell
# MySQL 8.23前
CHANGE MASTER TO MASTER_HOST=&#39;192.168.6.133&#39;, MASTER_USER=&#39;remote&#39;, MASTER_PASSWORD=&#39;yourpassword&#39;, MASTER_LOG_FILE=&#39;binlog.000003&#39;, MASTER_LOG_POS=158;
​
# MySQL 8.23后
CHANGE REPLICATION SOURCE TO SOURCE_HOST=&#39;192.168.6.133&#39;, SOURCE_USER=&#39;remote&#39;, SOURCE_PASSWORD=&#39;yourpassword&#39;, SOURCE_LOG_FILE=&#39;binlog.000003&#39;, SOURCE_LOG_POS=158;
​
CHANGE REPLICATION SOURCE TO SOURCE_HOST=&#39;192.168.6.136&#39;, SOURCE_USER=&#39;remote&#39;, SOURCE_PASSWORD=&#39;yourpassword&#39;, SOURCE_LOG_FILE=&#39;binlog.000004&#39;, SOURCE_LOG_POS=158,GET_SOURCE_PUBLIC_KEY=1;
```
3. start slave不能用了
```shell
# 开启同步
start replica ; #8.0.22之后 
start slave ; #8.0.22之前
```
4. show slave status不能用了
```shell
# 查看状态,\G表示行转列，便于查看
show replica status\G ; #8.0.22之后 
show slave status\G ; #8.0.22之前
``` --&gt;
</description>
        </item>
        <item>
        <title>运维面经</title>
        <link>https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/</link>
        <pubDate>Mon, 13 Jan 2025 14:58:48 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/</guid>
        <description>&lt;p&gt;2025/01/13 腾讯音乐运维一面&lt;/p&gt;
&lt;h2 id=&#34;linux&#34;&gt;Linux
&lt;/h2&gt;&lt;h3 id=&#34;linux启动顺序&#34;&gt;Linux启动顺序
&lt;/h3&gt;&lt;h4 id=&#34;biosuefi阶段&#34;&gt;BIOS/UEFI阶段
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;BIOS(Basic Input Output System)：基本输入输出系统。它是一组固化到计算机内主板上一个daoROM芯片上的程序，它保存着计算机最重要的基本输入输出的程序、系统设置信息、开机后自检程序和系统自启动程序。 其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。BIOS应该是连接软件程序与硬件设备的一座&amp;quot;桥梁&amp;quot;，负责解决硬件的即时要求。简单地说，BIOS就是一个加载在计算机主板上最基础的一段程序，负责最基础的硬件控制和设置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;MBR(Master Boot Record):主引导程序，是分区计算器大容量存储设备（如固定硬盘或移动硬盘）的第一个块中的一种引导扇区。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;加载位于主板ROM中地址&lt;code&gt;0xFFFF0&lt;/code&gt;的BIOS信息，主要包括系统BIOS和显卡BIOS；进行POST自检，检查CPU、内存、主板等硬件；建立终端向量表和中断服务程序；检测可引导设备；加载MBR(主引导程序)的前446字节到内存&lt;code&gt;0x7c00&lt;/code&gt;处。&lt;/p&gt;
&lt;p&gt;注：老电脑用MBR，较新的电脑，2017年之后的系统如Ubuntu17.04都默认使用GPT+UEFI组合。UEFI最大的好处就是启动方便，有图形化界面。&lt;/p&gt;
&lt;p&gt;目前主板多设置成三种启动模式，即：Auto、UEFI、Legacy。在设置启动时，带有UEFI的BIOS还提供了启动选项供大家选择以何种方式启，各种模式含义如下：&lt;/p&gt;
&lt;p&gt;Auto(自动)/Both：自动按照启动设备列表中的顺序启动，优先采用UEFI方式；&lt;/p&gt;
&lt;p&gt;UEFI only(仅UEFI)：只选择具备UEFI启动条件的设备启动；&lt;/p&gt;
&lt;p&gt;Legacy only(仅Legacy)：只选择具备Legacy启动条件的设备启动。&lt;/p&gt;
&lt;p&gt;简单的来说uefi启动是新一代的bios，功能更加强大，而且它是以图形图像模式显示，让用户更便捷的直观操作。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MBR最大支持2TB硬盘;最多支持4个主分区，或3个主分区+1个扩展分区;扩展分区可以包含多个逻辑分区;分区表只有一份，易损坏;启动代码占446字节，分区表占64字节;兼容传统BIOS系统
GPT (GUID Partition Table)支持超过2TB的硬盘（最大18EB）;支持最多128个分区（理论上可更多）;分区表有主副两份，更安全;每个分区都有全球唯一标识符(GUID);支持更多分区类型;需要UEFI启动支持&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;boot-loader阶段&#34;&gt;Boot Loader阶段
&lt;/h4&gt;&lt;p&gt;显示内核选择菜单；加载选定的内核镜像到内存；加载initramfs到内存；然后将控制权移交给内核&lt;/p&gt;
&lt;h4 id=&#34;kernel初始化阶段&#34;&gt;Kernel初始化阶段
&lt;/h4&gt;&lt;p&gt;系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。
系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。
然后系统会初始化CPU、内存、设备驱动；挂载根文件系统；运行/sbin/init(PID 1)&lt;/p&gt;
&lt;h4 id=&#34;init进程systemd阶段&#34;&gt;Init进程(systemd)阶段
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Unit:systemd管理的基本单元，包括&lt;code&gt;service服务&lt;/code&gt;、&lt;code&gt;socket进程间通信套接字&lt;/code&gt;、&lt;code&gt;target启动目标（类似于运行级别）&lt;/code&gt;、&lt;code&gt;mount文件系统挂载点&lt;/code&gt;、&lt;code&gt;device设备文件&lt;/code&gt;、&lt;code&gt;timer定时器&lt;/code&gt;。配置文件优先级依次是：&lt;code&gt;/etc/systemd/system/&lt;/code&gt; 系统管理员创建的配置，优先级最高;&lt;code&gt;/run/systemd/system/&lt;/code&gt; 运行时配置文件;&lt;code&gt;/usr/lib/systemd/system/&lt;/code&gt;软件包安装的默认配置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;读取默认target配置文件；分析unit间依赖关系；激活系统服务；准备各类daemon进程；准备用户环境。&lt;/p&gt;
&lt;p&gt;备注：系统级自启动程序就是在这时候启动的，如通过apt安装的Mysql、Docker。&lt;/p&gt;
&lt;h4 id=&#34;用户空间阶段&#34;&gt;用户空间阶段
&lt;/h4&gt;&lt;p&gt;依次读取&lt;code&gt;/etc/profile&lt;/code&gt;系统环境变量、&lt;code&gt; ~/.bashrc&lt;/code&gt;用户环境变量、 &lt;code&gt;/etc/passwd&lt;/code&gt;用户账户信息、 &lt;code&gt;/etc/shadow&lt;/code&gt;用户密码信息
启动显示管理器，加载桌面环境，准备终端设备；等待用户登录&lt;/p&gt;
&lt;p&gt;备注：用户级自启动程序在读取&lt;code&gt;~/.bashrc&lt;/code&gt;后自动执行，也就是说想要设置用户级自启动命令可以将启动命令写入到&lt;code&gt;~/.bashrc&lt;/code&gt;中&lt;/p&gt;
&lt;h3 id=&#34;linux开机自启动&#34;&gt;Linux开机自启动
&lt;/h3&gt;&lt;p&gt;Linux有三种级别的开机自启动：&lt;/p&gt;
&lt;h4 id=&#34;系统级别&#34;&gt;系统级别
&lt;/h4&gt;&lt;p&gt;通过apt包管理器安装的包默认就是这种级别的开机自启。
可以通过 &lt;code&gt;sudo systemctl enable mysql&lt;/code&gt;来启用开机自启（&lt;code&gt;sudo systemctl disable mysql&lt;/code&gt;为关闭开机自启命令）。&lt;/p&gt;
&lt;p&gt;除了包管理器，还可以自己制作service来实现，以nginx为例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在&lt;code&gt;/etc/systemd/system/&lt;/code&gt;下创建nginx.service文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /etc/systemd/system/
vim nginx.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;写入如下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[Unit]
Description=nginx - high performance web server
After=nginx.service
[Service]
Type=forking
ExecStart=/usr/local/nginx/sbin/nginx
ExecReload=/usr/local/nginx/sbin/nginx -s reload
ExecStop=/usr/local/nginx/sbin/nginx -s stop
Execenable=/usr/local/nginx/sbin/nginx
[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;设置开机自启&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 设置开机启动
systemctl enable nginx
# 取消开机自启动
#systemctl disable nginx
# 查看服务当前状态
systemctl status nginx
# 启动nginx服务
systemctl start nginx
# 停止nginx服务
systemctl stop nginx
# 重启nginx服务
systemctl restart nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;用户级别&#34;&gt;用户级别
&lt;/h4&gt;&lt;p&gt;将需要自启动的命令写入&lt;code&gt;~/.bashrc&lt;/code&gt;中，即可实现用户级开机自启。具体操作时如果命令较为简单，比如使用&lt;code&gt;alias&lt;/code&gt;给命令指定别名或者&lt;code&gt;ulimit -n 65536&lt;/code&gt;修改最大打开文件句柄数（我的Ubuntu不知道为什么永久修改怎么也修改不成功，只能通过这种方式曲线救国），就可以直接把命令写到&lt;code&gt;~/.bashrc&lt;/code&gt;中。如果命令比较复杂，可以考虑将命令打包成脚本，然后在&lt;code&gt;~/.bashrc&lt;/code&gt;中执行启动脚本的命令。&lt;/p&gt;
&lt;h4 id=&#34;桌面级别&#34;&gt;桌面级别
&lt;/h4&gt;&lt;p&gt;大体步骤类似系统级自启动：切换到&lt;code&gt;/etc/xdg/autostart/&lt;/code&gt;目录，创建后缀为desktop的文件，编辑并保存。重启生效。
&lt;img src=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/1.png&#34;
	width=&#34;1243&#34;
	height=&#34;829&#34;
	srcset=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/1_hu2426779653841869099.png 480w, https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/1_hu8478774365589774668.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据库&#34;&gt;数据库
&lt;/h2&gt;&lt;h3 id=&#34;mysql主从复制配置过程宕机恢复&#34;&gt;MySQL主从复制配置过程，宕机恢复
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://xiaolincoding.com/mysql/log/how_update.html#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主从复制可以用来做数据库的实时备份，保证数据的完整性；也可以做读写分离，提升数据库系统整体的读写性能。&lt;/p&gt;
&lt;h4 id=&#34;主从复制原理&#34;&gt;主从复制原理：
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/2.png&#34;
	width=&#34;960&#34;
	height=&#34;405&#34;
	srcset=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/2_hu12276740477023013187.png 480w, https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/2_hu11267129864193341543.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;568px&#34;
	
&gt;
MySQL集群的主从复制过程梳理成3个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。&lt;/li&gt;
&lt;li&gt;同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。&lt;/li&gt;
&lt;li&gt;回放 Binlog：回放 binlog，并更新存储引l擎中的数据。
具体详细过程如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;MySQL 主库在收到客户端提交事务的请求之后，会先写入binlog，再提交事务，更新存储引擎中的数
据，事务提交完成后，返回给客户端&amp;quot;操作成功&amp;quot;的响应。&lt;/li&gt;
&lt;li&gt;从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把
binlog 信息写入 relay log 的中继日志里，再返回给主库&amp;quot;复制成功&amp;quot;的响应。&lt;/li&gt;
&lt;li&gt;从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中
的数据，最终实现主从的数据一致性。
在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者
锁记录，也不会影响读请求的执行。
&lt;img src=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/3.png&#34;
	width=&#34;612&#34;
	height=&#34;607&#34;
	srcset=&#34;https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/3_hu14524736388878011446.png 480w, https://rusthx.github.io/p/%E8%BF%90%E7%BB%B4%E9%9D%A2%E7%BB%8F/3_hu12211041723728468306.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;241px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;主从复制配置过程&#34;&gt;主从复制配置过程
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://www.cnblogs.com/nulige/articles/9273537.html
两台机器都操作，确保 server-id 要不同，通常主ID要小于从ID。一定注意。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;mysql-binlog格式&#34;&gt;MySQL binlog格式
&lt;/h3&gt;&lt;p&gt;binlog 是 MySQL 中的一种重要日志类型，用于记录所有的DDL和DML操作（不包括数据查询语句）。它主要用于数据恢复和主从复制。Binlog有三种模式：STATEMENT(语句模式)、ROW(行模式) 和 MIXED(混合模式)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;STATEMENT模式&lt;/strong&gt;：基于SQL语句的复制（Statement-Based Replication, SBR），每一条修改数据的SQL语句都会记录到binlog中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：减少日志量：不需要记录每一行数据的变化，减少了磁盘IO，提高了性能&lt;/li&gt;
&lt;li&gt;缺点：数据不一致：在某些情况下，主从库的数据可能会不一致。例如，使用 uuid() 函数时，每次执行都会生成不同的值；自增字段在执行时可能得到错误的值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ROW模式&lt;/strong&gt;：基于行的复制（Row-Based Replication, RBR），不记录SQL语句的上下文信息，仅记录哪条数据被修改了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：准确复制：不会出现存储过程、函数或触发器调用无法正确复制的问题&lt;/li&gt;
&lt;li&gt;缺点：日志量大：尤其是在执行批量更新或删除操作时，会产生大量日志，影响IO性能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;MIXED模式&lt;/strong&gt;：是前两种模式的混合体（Mixed-Based Replication, MBR），MySQL会根据具体的SQL语句选择使用STATEMENT或ROW模式。
一般情况下，使用STATEMENT模式保存binlog，对于无法准确复制的操作则使用ROW模式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置和查看Binlog&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;要开启和配置Binlog，可以修改MySQL的配置文件 my.cnf&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[mysqld]
log-bin=ON
binlog_format=mixed
server-id=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看Binlog日志可以使用 mysqlbinlog 工具&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mysqlbinlog mysql-bin.000001
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或者使用SQL命令查看事件：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SHOW BINLOG EVENTS IN &#39;mysql-bin.000001&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过合理选择和配置Binlog模式，可以有效提高MySQL的性能和数据一致性&lt;/p&gt;
&lt;h3 id=&#34;mysql-备份逻辑备份与物理备份&#34;&gt;MySQL 备份，逻辑备份与物理备份
&lt;/h3&gt;&lt;p&gt;MySQL的物理备份和逻辑备份的主要区别在于备份文件的形式和备份恢复的灵活性。
物理备份直接复制数据库的二进制文件(binlog)，备份文件较大，恢复时只能在相同架构的MySQL服务器上使用。
逻辑备份将数据库导出为SQL语句的形式，备份文件较小，恢复时可跨平台使用，也可以进行数据的修改和筛选。&lt;/p&gt;
&lt;h2 id=&#34;容器化&#34;&gt;容器化
&lt;/h2&gt;&lt;h3 id=&#34;k8s移动pod&#34;&gt;k8s移动pod
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://blog.csdn.net/yanggd1987/article/details/108139436&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;k8s集群中的node节点要升级内存，以应对服务迁入、pod扩缩容导致的资源短缺，需要对node节点进行停机维护。此时就需要对pod进行迁移。&lt;/p&gt;
&lt;h4 id=&#34;默认迁移&#34;&gt;默认迁移
&lt;/h4&gt;&lt;p&gt;当node节点关机后，k8s集群并没有立刻发生任何自动迁移动作，如果该node节点上的副本数为1，则会出现服务中断的情况。其实事实并非如此，k8s在等待5分钟后，会自动将停机node节点上的pod自动迁移到其他node节点上。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 1.模拟node节点停机，停止kubelet
systemctl stop kubelet

# 2.集群状态
# 此时停机的node点处于NotReady状态
# kubectl get node
NAME                STATUS     ROLES     AGE   VERSION
k8s-3-217   Ready        master     88d   v1.18.2
k8s-3-218   NotReady   &amp;lt;none&amp;gt;   88d   v1.18.2
k8s-3-219   Ready        &amp;lt;none&amp;gt;   88d   v1.18.2

# 3.监控pod状态，大约等待5分钟左右，集群开始有动作
# kubectl get pod -n test -o wide -n test -w
NAME                                   READY   STATUS    RESTARTS   AGE   IP             NODE           NOMINATED NODE   READINESS GATES
helloworld-79956d95b4-q7jjg            1/1     Running   0          19h   10.244.1.154   k8s-3-218   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-q7jjg            1/1     Running   0          19h   10.244.1.154   k8s-3-218   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
# 5分钟后，pod终止并进行重建
helloworld-79956d95b4-q7jjg            1/1     Terminating   0          19h   10.244.1.154   k8s-3-218   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-nnlrq            0/1     Pending       0          0s    &amp;lt;none&amp;gt;         &amp;lt;none&amp;gt;         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-nnlrq            0/1     Pending       0          0s    &amp;lt;none&amp;gt;         k8s-3-219   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-nnlrq            0/1     ContainerCreating   0          1s    &amp;lt;none&amp;gt;         k8s-3-219   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

helloworld-79956d95b4-nnlrq            0/1     Running             0          3s    10.244.2.215   k8s-3-219   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-nnlrq            1/1     Running             0          66s   10.244.2.215   k8s-3-219   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

# 4.访问测试：在pod重新迁移到其他node节点时，服务是不可用的。
# curl -x 192.168.3.219:80 hello.test.cn
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;503 Service Temporarily Unavailable&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;503 Service Temporarily Unavailable&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt;
&amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx/1.17.8&amp;lt;/center&amp;gt;

# 5.迁移完毕：服务正常访问
# curl -x 192.168.3.219:80 hello.test.cn
Hello,world!

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从以上过程看出，停机node节点上的pod在5分钟后先终止再重建，直到pod在新节点启动并由readiness探针检测正常后并处于1\1 Running状态才可以正式对外提供服务。因此&lt;strong&gt;服务中断时间=停机等待5分钟时间+重建时间+服务启动时间+readiness探针检测正常时间。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为什么pod在5分钟后开始迁移呢?
此时需要涉及到k8s中的Taint（污点）和 Toleration（容忍），这是从Kubernetes 1.6开始提供的高级调度功能。Taint和Toleration相互配合，可以避免pod被分配到不合适的节点上。每个节点上都可以应用一个或多个Taint，这表示对于那些不能容忍Taint的pod，是不会被该节点接受的。如果将Toleration应用于pod上，则表示这些pod可以（但不要求）被调度到具有匹配Taint的节点上。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 1.查看停止服务节点的状态
# kubelet停止后，node节点自动添加了Taints；
# kubectl describe node k8s-3-218

Name:               k8s-3-218
Roles:              &amp;lt;none&amp;gt;
CreationTimestamp:  Fri, 22 May 2020 11:36:16 +0800
Taints:             node.kubernetes.io/unreachable:NoExecute
                    node.kubernetes.io/unreachable:NoSchedule
Unschedulable:      false
Lease:
  HolderIdentity:  k8s-3-218
  AcquireTime:     &amp;lt;unset&amp;gt;
  RenewTime:       Wed, 19 Aug 2020 09:31:22 +0800
Conditions:
  Type                 Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message
  ----                 ------    -----------------                 ------------------                ------              -------
  NetworkUnavailable   False     Tue, 18 Aug 2020 09:07:59 +0800   Tue, 18 Aug 2020 09:07:59 +0800   FlannelIsUp         Flannel is running on this node
  MemoryPressure       Unknown   Wed, 19 Aug 2020 09:29:56 +0800   Wed, 19 Aug 2020 09:32:07 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  DiskPressure         Unknown   Wed, 19 Aug 2020 09:29:56 +0800   Wed, 19 Aug 2020 09:32:07 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  PIDPressure          Unknown   Wed, 19 Aug 2020 09:29:56 +0800   Wed, 19 Aug 2020 09:32:07 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
  Ready                Unknown   Wed, 19 Aug 2020 09:29:56 +0800   Wed, 19 Aug 2020 09:32:07 +0800   NodeStatusUnknown   Kubelet stopped posting node status.
...省略...
Events:              &amp;lt;none&amp;gt;

# 2.查看pod状态
# kubectl describe pod helloworld-8565c4687b-rrfmj -n test
Name:                      helloworld-8565c4687b-rrfmj
Namespace:                 test
Priority:                  0
......
Node-Selectors:  &amp;lt;none&amp;gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时pod的Tolerations 默认对于具有相应Taint的node节点容忍时间为300s，超过此时间pod将会被驱逐到其他可用node节点上。因此5分钟后node节点上所有的pod重新被调度，在此期间服务是中断的。&lt;/p&gt;
&lt;h4 id=&#34;手动迁移&#34;&gt;手动迁移
&lt;/h4&gt;&lt;p&gt;默认的pod迁移无法避免服务中断，那么我们在node节点停机前，我们可以手动迁移。
为避免等待默认的5分钟，我们还可以使用cordon、drain、uncordor三个命令实现节点的主动维护。此时需要用到以下三个命令：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cordon&lt;/code&gt;:标记节点不可调度，后续新的pod不会被调度到此节点，但是该节点上的pod可以正常对外服务；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;drain&lt;/code&gt;:驱逐节点上的pod至其他可调度节点；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uncordon&lt;/code&gt;:标记节点可调度
具体操作如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 1.标记节点不可调度
# kubectl cordon k8s-3-219
node/k8s-3-219 cordoned

# 查看节点状态，此时219被标记为不可调度
# kubectl get node
NAME           STATUS                     ROLES    AGE   VERSION
k8s-3-217   Ready                      master   89d   v1.18.2
k8s-3-218   Ready                      &amp;lt;none&amp;gt;   88d   v1.18.2
k8s-3-219   Ready,SchedulingDisabled   &amp;lt;none&amp;gt;   88d   v1.18.2

# 2.驱逐pod
# kubectl drain k8s-3-219 --delete-local-data --ignore-daemonsets --force
node/k8s-3-219 already cordoned
WARNING: ignoring DaemonSet-managed Pods: ingress-nginx/nginx-ingress-controller-gmzq6, kube-system/kube-flannel-ds-amd64-5gfwh, kube-system/kube-proxy-vdckk
evicting pod kube-system/tiller-deploy-6c65968d87-75pfm
evicting pod kube-system/metrics-server-7f96bbcc66-bgt7j
evicting pod test/helloworld-79956d95b4-nnlrq

# 参数如下：
--delete-local-data  删除本地数据，即使emptyDir也将删除；
--ignore-daemonsets  忽略DeamonSet，否则DeamonSet被删除后，仍会自动重建；
--force  不加force参数只会删除该node节点上的ReplicationController, ReplicaSet, DaemonSet,StatefulSet or Job，加上后所有pod都将删除；

# 3. 查看驱逐，219上的pod迁移到218上了。
# kubectl get pod -n test -o wide
NAME                                   READY   STATUS        RESTARTS   AGE   IP             NODE           NOMINATED NODE   READINESS GATES
helloworld-79956d95b4-gg58c            0/1     Running       0          20s   10.244.1.165   k8s-3-218   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
helloworld-79956d95b4-nnlrq            1/1     Terminating   0          77m   10.244.2.215   k8s-3-219   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时与默认迁移不同的是，pod会先重建再终止，此时的&lt;strong&gt;服务中断时间=重建时间+服务启动时间+readiness探针检测正常时间&lt;/strong&gt;，必须等到1/1 Running服务才会正常。因此在单副本时迁移时，服务中断是不可避免的。&lt;/p&gt;
&lt;h4 id=&#34;平滑迁移&#34;&gt;平滑迁移
&lt;/h4&gt;&lt;p&gt;要做到平滑迁移就需要用的pdb(PodDisruptionBudget)，即主动驱逐保护。无论是默认迁移和手动迁移，都会导致服务中断，而pdb能可以实现节点维护期间不低于一定数量的pod正常运行，从而保证服务的可用性。&lt;/p&gt;
&lt;p&gt;在仍以helloworld为例，由于只有一个副本，因此需要保证维护期间这个副本在迁移完成后，才会终止。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 从218 驱逐到 219
# 1.标记节点不可调度
# kubectl cordon k8s-3-218
node/k8s-3-218 cordoned

# 2.新建pdb
vim pdb-test.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: pdb-test
  namespace: test
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: helloworld

# 2.应用并查看状态
# kubectl apply -f pdb-test.yaml
# kubectl get pdb -n test
NAME       MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
pdb-test   1                         N/A                          0                                       7s

# 3.驱逐
# kubectl drain k8s-3-218 --delete-local-data --ignore-daemonsets --force
node/k8s-3-218 already cordoned
WARNING: ignoring DaemonSet-managed Pods: ingress-nginx/nginx-ingress-controller-hhb6h, kube-system/kube-flannel-ds-amd64-pb4d7, kube-system/kube-proxy-rzdcj
evicting pod kube-system/tiller-deploy-6c65968d87-ktqmm
evicting pod kube-system/metrics-server-7f96bbcc66-6p6wm
evicting pod test/helloworld-79956d95b4-gg58c
error when evicting pod &amp;quot;helloworld-79956d95b4-gg58c&amp;quot; (will retry after 5s): Cannot evict pod as it would violate the pod&#39;s disruption budget.
evicting pod test/helloworld-79956d95b4-gg58c
error when evicting pod &amp;quot;helloworld-79956d95b4-gg58c&amp;quot; (will retry after 5s): Cannot evict pod as it would violate the pod&#39;s disruption budget.
pod/tiller-deploy-6c65968d87-ktqmm evicted

#此时由于只有一个副本，最小可用为1，则ALLOWED就为0，因此在一个副本通过pdb是不会发生驱逐的。我们需要先扩容，将副本数调整为大于1。

# 3.手动调整副本数，将replicas为2
kubectl edit deploy helloworld -n test
# 再次查看pdb
# kubectl get pdb -n test
NAME       MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
pdb-test   1               N/A               1                     13m

#此时最小可用为1 ，ALLOWED为1，此时是数量会自动计算。

# 4.驱逐
# kubectl drain k8s-3-218 --delete-local-data --ignore-daemonsets --force

# 5.维护完毕，将node调整为可调度
# kubectl uncordon k8s-3-218
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;本次驱逐，由于helloworld始终保持有一个pod在提供服务，因此服务是不中断的。
最后将副本数可以调节为1并将node节点调整为可调度，维护完毕。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;:通过简单了解了Taint（污点）和 Toleration（容忍）作用，我们既可以通过设置tolerationSeconds来缩短等待时间，也可以自行定义匹配规则实现符合实际情况的调度规则。&lt;/p&gt;
&lt;p&gt;另外还要注意先重建再终止和先终止再重建，在此过程中服务启动时间和探针检测时间决定你的服务中断时间。&lt;/p&gt;
&lt;h3 id=&#34;k8s镜像拉取配置参数及优先级&#34;&gt;k8s镜像拉取配置参数及优先级
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;参考：https://www.cnblogs.com/leojazz/p/18686403&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 Kubernetes（简称 K8s）中，容器镜像的更新行为主要由 imagePullPolicy 参数控制。该策略决定了 Kubernetes 在启动或重启容器时是否从镜像仓库拉取新的镜像版本。常见的镜像更新策略有三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Always
如果容器的&lt;code&gt;imagePullPolicy&lt;/code&gt;设置为 Always，每次创建 Pod 或者重启容器时，Kubelet 都会从镜像仓库拉取最新的镜像版本。这对于使用 latest 标签或者希望始终获取最新镜像的场景非常有用，但在生产环境中应谨慎使用，因为 latest 标签的镜像内容可能会随时变化，导致版本不一致或潜在的不稳定。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;建议： 在生产环境中避免直接使用 latest 标签，使用明确的版本号（如 v1.0.1）来确保一致性，并记录镜像版本历史以便于追踪和排查问题。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;IfNotPresent（默认值）
当&lt;code&gt;imagePullPolicy&lt;/code&gt;设置为 IfNotPresent 时，如果本地节点上已经存在该镜像，则 Kubelet 不会尝试从镜像仓库拉取镜像；仅当本地不存在该镜像时，Kubelet 才会去远程仓库拉取镜像。通常，使用带有明确版本标签（如 v1.0）的镜像时，推荐使用此策略，以避免不必要的镜像拉取。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意： 默认情况下，如果镜像标签是 latest，imagePullPolicy 会自动设置为 Always；如果是版本号标签（如 v1.0），则默认使用 IfNotPresent。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Never
如果&lt;code&gt;imagePullPolicy&lt;/code&gt;设置为 Never，无论本地是否存在该镜像，Kubelet 都不会尝试从镜像仓库拉取镜像，而是始终使用本地已有的镜像。这种策略适用于不希望自动升级镜像版本，且希望始终使用特定版本的场景。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;更新应用镜像的常见方法
在 Kubernetes 中，更新应用镜像的常见方法是通过修改 Deployment、StatefulSet 等控制器中定义的 Pod 模板内的镜像版本，然后执行 kubectl apply 命令将更改推送到集群，触发滚动更新。&lt;/p&gt;
&lt;p&gt;滚动更新的过程中，Kubernetes 会逐步替换旧的容器实例，确保服务的持续可用性。您可以使用以下命令来更新镜像版本：&lt;/p&gt;
&lt;p&gt;示例：更新 Deployment 中的镜像
假设我们有一个名为 example-deployment 的 Deployment，其中定义了一个容器镜像 myapp:v1.0。我们将镜像版本更新为 myapp:v2.0，并通过 kubectl apply 命令触发更新。&lt;/p&gt;
&lt;p&gt;修改 Deployment 配置文件 deployment.yaml 中的镜像版本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      containers:
      - name: example-container
        image: myapp:v2.0  # 修改为新的镜像版本
        imagePullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行 kubectl apply 命令将变更推送到集群：
kubectl apply -f deployment.yaml
在执行该命令后，Kubernetes 会根据定义的镜像更新策略（例如，imagePullPolicy: IfNotPresent）决定是否从仓库拉取新的镜像，并按滚动更新的方式逐步替换旧版本的容器实例。&lt;/p&gt;
&lt;p&gt;滚动更新控制
在滚动更新过程中，您还可以通过以下参数控制更新过程的行为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;maxUnavailable&lt;/code&gt;：定义更新过程中允许不可用的最大 Pod 数量，控制更新期间服务的最小可用性。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxSurge&lt;/code&gt;：定义在更新过程中可以超出期望副本数的最大 Pod 数量，帮助提升更新的速度。
合理设置这两个参数可以在保证服务可用性的同时加速或控制更新过程。例如：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;spec:
  replicas: 3
  strategy:
    rollingUpdate:
      maxUnavailable: 1  # 最多允许 1 个 Pod 不可用
      maxSurge: 1        # 可以增加 1 个 Pod 以加速更新
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过设置这些参数，您可以精细控制容器的滚动更新行为，以平衡服务可用性和更新速度。&lt;/p&gt;
&lt;p&gt;这种修订版本提供了更为清晰的策略解释、更新的实践方法和对滚动更新的详细控制，适用于生产环境中的实际操作。&lt;/p&gt;
&lt;h3 id=&#34;k8s镜像仓库&#34;&gt;k8s镜像仓库
&lt;/h3&gt;&lt;p&gt;k8s镜像仓库分为远程仓库和本地仓库。本地仓库就是存储在本机的镜像文件，可以通过工具(如Docker Registry、Harbor)搭建，用于管理和分发镜像；&lt;/p&gt;
&lt;p&gt;由于 Kubernetes 使用的是容器运行时(如 containerd),直接在 Docker 中构建的镜像无法直接被 Kubernetes 使用。需要将镜像导入到对应的容器运行时中。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# containerd：使用 ctr 工具导入镜像
ctr -n k8s.io images import my-image.tar

# CRI-O：使用 skopeo 或 crictl 工具导入镜像
crictl load my-image.tar
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Kubernetes 较新版本（1.24+）已移除对 Docker 的支持，转为使用 containerd 或 CRI-O。&lt;/li&gt;
&lt;li&gt;不同运行时的镜像存储路径如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Docker：&lt;code&gt;/var/lib/docker&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;containerd：&lt;code&gt;/var/lib/containerd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;CRI-O：&lt;code&gt;/var/lib/containers&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;如果需要使用本地镜像，需根据运行时类型将镜像导入到对应的存储系统中，例如使用 ctr 或 crictl。
Kubernetes 配置文件中需设置 imagePullPolicy 为 Never，并确保所有节点都加载了本地镜像。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;远程仓库&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;公共镜像仓库:
这些仓库通常是开放和免费的，供开发者和用户共享或下载镜像。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docker Hub&lt;/a&gt;:Docker 官方提供的公共镜像仓库，默认与 Docker CLI 配合使用。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://gcr.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Container Registry (GCR)&lt;/a&gt;:Google 提供的镜像仓库(k8s1.24版本前的默认仓库)，适合与 Google Cloud Platform (GCP) 集成。k8s1.24后的默认仓库：https://registry.k8s.io&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://ghcr.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub Container Registry (GHCR)&lt;/a&gt;:GitHub 提供的容器镜像服务，适合与 GitHub 项目结合使用。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://quay.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Quay.io&lt;/a&gt;:Red Hat 提供的镜像仓库，支持高级功能和企业用途。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;私有镜像仓库:
为了安全性和隐私原因，很多企业会搭建自己的私有镜像仓库。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://goharbor.io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Harbor&lt;/a&gt;:一个开源的企业级私有镜像仓库，支持镜像管理、访问控制和漏洞扫描。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://jfrog.com/artifactory&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Artifactory&lt;/a&gt;:JFrog 提供的企业级解决方案，支持多种包管理器，包括 Docker 镜像。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/docker/distribution&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;自建私有仓库&lt;/a&gt;:使用 Docker Registry 开源项目搭建的简单私有仓库。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;云厂商提供的镜像仓库:
各大云厂商为其云服务提供了专属的容器镜像仓库，方便与云平台集成。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://aws.amazon.com/ecr&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazon Elastic Container Registry (ECR)&lt;/a&gt;:AWS 提供的镜像仓库，深度集成 AWS 生态。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/en-us/services/container-registry/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Azure Container Registry (ACR)&lt;/a&gt;:Azure 提供的镜像仓库，支持与 Azure     Kubernetes 服务无缝集成。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.aliyun.com/product/acr&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Alibaba Cloud Container Registry (ACR)&lt;/a&gt;:阿里云提供的镜像服务，支持国内加速访问和与阿里云服务集 成。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://cloud.tencent.com/product/tcr&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tencent Container Registry (TCR)&lt;/a&gt;:腾讯云提供的镜像仓库，适合国内用户使用。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.huaweicloud.com/intl/en-us/product/swr.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Huawei Cloud SWR (SoftWare Repository for Container)&lt;/a&gt;:华为云提供的容器镜像服务，支持企业级容器管理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;国内公共镜像加速器
由于国内网络环境的限制，许多镜像从国外仓库拉取较慢，因此国内厂商提供了一些公共镜像加速器。&lt;/p&gt;
&lt;p&gt;阿里云容器镜像服务加速器:https://cr.console.aliyun.com&lt;/p&gt;
&lt;p&gt;腾讯云容器镜像服务加速器：https://cloud.tencent.com/document/product/457/35996&lt;/p&gt;
&lt;p&gt;华为云容器镜像加速器：https://www.huaweicloud.com/product/swr.html&lt;/p&gt;
&lt;p&gt;网易云加速器：https://www.163yun.com/product/container&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;监控&#34;&gt;监控
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考：https://flashcat.cloud/blog/ops-monitor/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;nginx&#34;&gt;nginx
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Spark源码学习 Shuffle</title>
        <link>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/</link>
        <pubDate>Mon, 09 Dec 2024 22:01:04 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;作者由于水平问题，文中也许有一些错误遗漏的地方，欢迎联系指正(&lt;code&gt;2024087171@qq.com&lt;/code&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://blog.csdn.net/weixin_42868529/article/details/84622803&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Shuffle 过程本质上都是将 Map 端获得的数据使用分区器进行划分，并将数据发送给对应的 Reducer 的过程。&lt;/p&gt;
&lt;p&gt;前一个stage的ShuffleMapTask进行shuffle write，把数据存储在blockManager上面，并且把数据元信息上报到dirver的mapOutTarck组件中，下一个stage根据数据位置源信息，进行shuffle read，拉取上一个stage的输出数据&lt;/p&gt;
&lt;h2 id=&#34;hadoopmapreduce-shuffle&#34;&gt;Hadoop(MapReduce) shuffle
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：尚硅谷Hadoop相关课程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;MapReduce的shuffle机制：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MapTask收集我们的map()方法输出的kv对，放到环形缓冲区中&lt;/li&gt;
&lt;li&gt;从环形缓冲区不断溢写本地磁盘文件，可能会溢出多个文件&lt;/li&gt;
&lt;li&gt;多个溢出文件会被合并成大的溢出文件&lt;/li&gt;
&lt;li&gt;在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序&lt;/li&gt;
&lt;li&gt;ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据&lt;/li&gt;
&lt;li&gt;ReduceTask会抓取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）&lt;/li&gt;
&lt;li&gt;合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/1.png&#34;
	width=&#34;1058&#34;
	height=&#34;513&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/1_hu3767354565587542623.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/1_hu10364141614106133650.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;206&#34;
		data-flex-basis=&#34;494px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;spark-shuffle详细机制&#34;&gt;Spark shuffle详细机制
&lt;/h2&gt;&lt;p&gt;Spark的shuffle机制：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;前提条件：Spark的代码在运行到action算子时触发任务（job），然后DAGscheduler按算子间的血缘（依赖关系）划分形成DAG图（有向无环图），
有shuffle操作的依赖关系称为宽依赖，没有的称为窄依赖。DAGscheduler按宽依赖将任务划分为多个stage，stage的数量就等于宽依赖数量+1。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;根据 spark.shuffle.manager 设置，SparkEnv 会在driver和每个executor上创建一个 ShuffleManager。 driver在其中注册shuffle，executor（或在driver中本地运行的任务）可以要求读写数据。&lt;/li&gt;
&lt;li&gt;前一个stage的ShuffleMapTask将mapTaskID和partitions传入sortShuffleManager，调用getWriter（）方法后，首先会判断是否需要对计算结果进行聚合，然后将最终结果按照不同的 reduce 端进行区分，返回writeHandle,
根据不同的writeHandle选择不同的writer（&lt;code&gt;UnsafeShuffleWriter&lt;/code&gt;、&lt;code&gt;BypassMergeSortShuffleWriter&lt;/code&gt;、&lt;code&gt;SortShuffleWriter&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;writer将数据写入到executor的blockManager中&lt;/li&gt;
&lt;li&gt;shuffleManager为后一个stage创建一个&lt;code&gt;BlockStoreShuffleReader&lt;/code&gt;，根据位置信息（&lt;code&gt;startMapIndex, endMapIndex, startPartition, endPartition&lt;/code&gt;）拉取blockManger中的数据，根据数据的 Key 进行聚合，然后判断是否需要排序，最后生成新的 RDD。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/2.png&#34;
	width=&#34;1920&#34;
	height=&#34;1030&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/2_hu3537821498809195093.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-shuffle/2_hu9124599422288604458.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  
  /**
   * Obtains a [[ShuffleHandle]] to pass to tasks.
   */
  override def registerShuffle[K, V, C](
      shuffleId: Int,
      dependency: ShuffleDependency[K, V, C]): ShuffleHandle = {
    if (SortShuffleWriter.shouldBypassMergeSort(conf, dependency)) {
      // If there are fewer than spark.shuffle.sort.bypassMergeThreshold partitions and we don&#39;t
      // need map-side aggregation, then write numPartitions files directly and just concatenate
      // them at the end. This avoids doing serialization and deserialization twice to merge
      // together the spilled files, which would happen with the normal code path. The downside is
      // having multiple files open at a time and thus more memory allocated to buffers.
      new BypassMergeSortShuffleHandle[K, V](
        shuffleId, dependency.asInstanceOf[ShuffleDependency[K, V, V]])
    } else if (SortShuffleManager.canUseSerializedShuffle(dependency)) {
      // Otherwise, try to buffer map outputs in a serialized form, since this is more efficient:
      new SerializedShuffleHandle[K, V](
        shuffleId, dependency.asInstanceOf[ShuffleDependency[K, V, V]])
    } else {
      // Otherwise, buffer map outputs in a deserialized form:
      new BaseShuffleHandle(shuffleId, dependency)
    }
  }

  /**
   * Get a reader for a range of reduce partitions (startPartition to endPartition-1, inclusive) to
   * read from a range of map outputs(startMapIndex to endMapIndex-1, inclusive).
   * If endMapIndex=Int.MaxValue, the actual endMapIndex will be changed to the length of total map
   * outputs of the shuffle in `getMapSizesByExecutorId`.
   *
   * Called on executors by reduce tasks.
   */
  override def getReader[K, C](
      handle: ShuffleHandle,
      startMapIndex: Int,
      endMapIndex: Int,
      startPartition: Int,
      endPartition: Int,
      context: TaskContext,
      metrics: ShuffleReadMetricsReporter): ShuffleReader[K, C] = {
    val baseShuffleHandle = handle.asInstanceOf[BaseShuffleHandle[K, _, C]]
    val (blocksByAddress, canEnableBatchFetch) =
      if (baseShuffleHandle.dependency.isShuffleMergeFinalizedMarked) {
        val res = SparkEnv.get.mapOutputTracker.getPushBasedShuffleMapSizesByExecutorId(
          handle.shuffleId, startMapIndex, endMapIndex, startPartition, endPartition)
        (res.iter, res.enableBatchFetch)
      } else {
        val address = SparkEnv.get.mapOutputTracker.getMapSizesByExecutorId(
          handle.shuffleId, startMapIndex, endMapIndex, startPartition, endPartition)
        (address, true)
      }
    new BlockStoreShuffleReader(
      handle.asInstanceOf[BaseShuffleHandle[K, _, C]], blocksByAddress, context, metrics,
      shouldBatchFetch =
        canEnableBatchFetch &amp;amp;&amp;amp; canUseBatchFetch(startPartition, endPartition, context))
  }

  /** Get a writer for a given partition. Called on executors by map tasks. */
  override def getWriter[K, V](
      handle: ShuffleHandle,
      mapId: Long,
      context: TaskContext,
      metrics: ShuffleWriteMetricsReporter): ShuffleWriter[K, V] = {
    val mapTaskIds = taskIdMapsForShuffle.computeIfAbsent(
      handle.shuffleId, _ =&amp;gt; new OpenHashSet[Long](16))
    mapTaskIds.synchronized { mapTaskIds.add(mapId) }
    val env = SparkEnv.get
    handle match {
      case unsafeShuffleHandle: SerializedShuffleHandle[K @unchecked, V @unchecked] =&amp;gt;
        new UnsafeShuffleWriter(
          env.blockManager,
          context.taskMemoryManager(),
          unsafeShuffleHandle,
          mapId,
          context,
          env.conf,
          metrics,
          shuffleExecutorComponents)
      case bypassMergeSortHandle: BypassMergeSortShuffleHandle[K @unchecked, V @unchecked] =&amp;gt;
        new BypassMergeSortShuffleWriter(
          env.blockManager,
          bypassMergeSortHandle,
          mapId,
          env.conf,
          metrics,
          shuffleExecutorComponents)
      case other: BaseShuffleHandle[K @unchecked, V @unchecked, _] =&amp;gt;
        new SortShuffleWriter(other, mapId, context, shuffleExecutorComponents)
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;与hadoopmapreduce-shuffle的区别&#34;&gt;与Hadoop(MapReduce) shuffle的区别
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考：https://zhuanlan.zhihu.com/p/136466667&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;功能上，MR的shuffle和Spark的shuffle是没啥区别的，都是对Map端的数据进行分区，要么聚合排序，要么不聚合排序，然后Reduce端或者下一个调度阶段进行拉取数据，完成map端到reduce端的数据传输功能。&lt;/li&gt;
&lt;li&gt;方案上，有很大的区别，MR的shuffle是基于合并排序的思想，在数据进入reduce端之前，都会进行sort，为了方便后续的reduce端的全局排序，而Spark的shuffle是可选择的聚合，特别是1.2之后，需要通过调用特定的算子才会触发排序聚合的功能。&lt;/li&gt;
&lt;li&gt;流程上，MR的Map端和Reduce区分非常明显，两块涉及到操作也是各司其职，而Spark的RDD是内存级的数据转换，不落盘，所以没有明确的划分，只是区分不同的调度阶段，不同的算子模型。&lt;/li&gt;
&lt;li&gt;数据拉取，MR的reduce是直接拉取Map端的分区数据，而Spark是根据MapId和TaskContext读取，而且是在action触发的时候才会拉取数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;shufflewriter及其选择策略&#34;&gt;ShuffleWriter及其选择策略
&lt;/h2&gt;&lt;h3 id=&#34;unsafeshufflewriter&#34;&gt;UnsafeShuffleWriter
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;@VisibleForTesting
public void write(Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  write(JavaConverters.asScalaIteratorConverter(records).asScala());
}
@Override
public void write(scala.collection.Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
    // Keep track of success so we know if we encountered an exception
    // We do this rather than a standard try/catch/re-throw to handle
    // generic throwables.
    boolean success = false;
    try {
      while (records.hasNext()) {
        insertRecordIntoSorter(records.next());
      }
      closeAndWriteOutput();
      success = true;
    } finally {
      if (sorter != null) {
        try {
          sorter.cleanupResources();
        } catch (Exception e) {
          // Only throw this error if we won&#39;t be masking another
          // error.
          if (success) {
            throw e;
          } else {
            logger.error(&amp;quot;In addition to a failure during writing, we failed during &amp;quot; +
                         &amp;quot;cleanup.&amp;quot;, e);
          }
        }
      }
    }
  }

@VisibleForTesting
void insertRecordIntoSorter(Product2&amp;lt;K, V&amp;gt; record) throws IOException {
  assert(sorter != null);
  final K key = record._1();
  final int partitionId = partitioner.getPartition(key);
  serBuffer.reset();
  serOutputStream.writeKey(key, OBJECT_CLASS_TAG);
  serOutputStream.writeValue(record._2(), OBJECT_CLASS_TAG);
  serOutputStream.flush();
  final int serializedRecordSize = serBuffer.size();
  assert (serializedRecordSize &amp;gt; 0);
  sorter.insertRecord(
    serBuffer.getBuf(), Platform.BYTE_ARRAY_OFFSET, serializedRecordSize, partitionId);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当shuffle后的分区数小于等于&lt;code&gt;sortShuffleManager&lt;/code&gt;的最大分区数时，进行&lt;code&gt;unsafeShuffle&lt;/code&gt;。主要步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将内存中的对象通过Java可迭代对象转换器转换为Scala的可迭代对象（并没有进行序列化相关操作，只是为了兼容性）&lt;/li&gt;
&lt;li&gt;判断排序器（&lt;code&gt;sorter&lt;/code&gt;）是否为空，使用分区器(&lt;code&gt;partitioner&lt;/code&gt;)确认记录所属分区&lt;/li&gt;
&lt;li&gt;重置序列化缓冲区，遍历可迭代对象（&lt;code&gt;iterator&lt;/code&gt;），将记录的键和值依次序列化后写入，并刷写脏页，确保数据写入缓冲区&lt;/li&gt;
&lt;li&gt;将序列化记录插入到排序器中。sorter负责按分区组织记录，并&lt;font color=red&gt;可能&lt;/font&gt;在每个分区内对其进行排序。方法使用缓冲区、偏移量、大小和分区ID来正确放置记录。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;sorter什么时候排序？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shuffle操作的需求（最高优先级）：
如果上层的Spark操作（如sortByKey）要求数据在每个分区内有序，那么排序器会对数据进行排序。
对于不需要排序的操作（如groupByKey），排序器可能只负责将数据按分区组织，而不进行排序。&lt;/li&gt;
&lt;li&gt;排序器的类型和实现：
Spark中有多种排序器实现，例如UnsafeExternalSorter。这些排序器可以根据需要对数据进行排序。
如果排序器的实现支持排序，并且配置要求排序，那么数据会在每个分区内被排序。&lt;/li&gt;
&lt;li&gt;配置和优化（最低优先级）：
Spark的某些配置参数可以影响排序行为。例如，spark.shuffle.sort.bypassMergeThreshold可以决定在某些情况下是否绕过排序。
在某些优化场景下，为了提高性能，Spark可能会选择不进行排序。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bypassmergesortshufflewriter&#34;&gt;BypassMergeSortShuffleWriter
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;@Override
  public void write(Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
    assert (partitionWriters == null);
    ShuffleMapOutputWriter mapOutputWriter = shuffleExecutorComponents
        .createMapOutputWriter(shuffleId, mapId, numPartitions);
    try {
      if (!records.hasNext()) {
        partitionLengths = mapOutputWriter.commitAllPartitions(
          ShuffleChecksumHelper.EMPTY_CHECKSUM_VALUE).getPartitionLengths();
        mapStatus = MapStatus$.MODULE$.apply(
          blockManager.shuffleServerId(), partitionLengths, mapId);
        return;
      }
      final SerializerInstance serInstance = serializer.newInstance();
      final long openStartTime = System.nanoTime();
      partitionWriters = new DiskBlockObjectWriter[numPartitions];
      partitionWriterSegments = new FileSegment[numPartitions];
      for (int i = 0; i &amp;lt; numPartitions; i++) {
        final Tuple2&amp;lt;TempShuffleBlockId, File&amp;gt; tempShuffleBlockIdPlusFile =
            blockManager.diskBlockManager().createTempShuffleBlock();
        final File file = tempShuffleBlockIdPlusFile._2();
        final BlockId blockId = tempShuffleBlockIdPlusFile._1();
        DiskBlockObjectWriter writer =
          blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, writeMetrics);
        if (partitionChecksums.length &amp;gt; 0) {
          writer.setChecksum(partitionChecksums[i]);
        }
        partitionWriters[i] = writer;
      }
      // Creating the file to write to and creating a disk writer both involve interacting with
      // the disk, and can take a long time in aggregate when we open many files, so should be
      // included in the shuffle write time.
      writeMetrics.incWriteTime(System.nanoTime() - openStartTime);

      while (records.hasNext()) {
        final Product2&amp;lt;K, V&amp;gt; record = records.next();
        final K key = record._1();
        partitionWriters[partitioner.getPartition(key)].write(key, record._2());
      }

      for (int i = 0; i &amp;lt; numPartitions; i++) {
        try (DiskBlockObjectWriter writer = partitionWriters[i]) {
          partitionWriterSegments[i] = writer.commitAndGet();
        }
      }

      partitionLengths = writePartitionedData(mapOutputWriter);
      mapStatus = MapStatus$.MODULE$.apply(
        blockManager.shuffleServerId(), partitionLengths, mapId);
    } catch (Exception e) {
      try {
        mapOutputWriter.abort(e);
      } catch (Exception e2) {
        logger.error(&amp;quot;Failed to abort the writer after failing to write map output.&amp;quot;, e2);
        e.addSuppressed(e2);
      }
      throw e;
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;BypassMergeSortShuffleWriter，专门用于处理小规模的 shuffle 操作。它通过绕过排序步骤来提高性能，适用于分区数较少的情况。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化和检查：确保在写入开始时，partitionWriters 为空，防止重复初始化，然后创建一个用于写入 shuffle 输出的对象(&lt;code&gt;ShuffleMapOutputWriter&lt;/code&gt;)。&lt;/li&gt;
&lt;li&gt;处理空记录集：如果没有记录需要写入，更新 map 状态,直接向blockkManager提交所有分区并返回。&lt;/li&gt;
&lt;li&gt;初始化序列化和写入器：创建一个新的序列化实例，初始化分区磁盘写入器数组(&lt;code&gt;DiskBlockObjectWriter[numPartitions]&lt;/code&gt;)，初始化分区文件段数组。&lt;/li&gt;
&lt;li&gt;创建分区写入器：循环遍历每个分区，创建临时的 shuffle 块和对应的磁盘写入器。为每个分区创建一个磁盘写入器。&lt;/li&gt;
&lt;li&gt;写入记录： 遍历所有记录，根据键的分区，将记录写入对应的分区写入器。&lt;/li&gt;
&lt;li&gt;提交和获取分区数据：遍历每个分区，提交写入的数据并获取文件段。提交写入并获取文件段信息。&lt;/li&gt;
&lt;li&gt;写入分区数据和更新状态： 将分区数据写入输出。更新 map 状态。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 文件段信息通常指的是每个分区在磁盘上的物理存储信息，包括：文件路径(数据在磁盘上的具体存储位置)、偏移量(数据在文件中的起始位置)、
长度(数据的字节长度)。&lt;/p&gt;
&lt;p&gt; 更新 map 状态是指在 shuffle 写入完成后，更新 Spark 的内部状态以反映当前任务的输出状态。具体来说：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MapStatus: 这是 Spark 用于跟踪每个 map 任务输出状态的对象（在一个 stage 中，map 任务完成后生成的输出信息。这些信息用于指导后续的 shuffle 操作，确保数据能够正确地传递到下一个 stage 的 reduce 任务中。）。它包含了每个分区的数据长度信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;源码中介绍如下：&lt;/p&gt;
&lt;p&gt;Result returned by a ShuffleMapTask to a scheduler. Includes the block manager address that the task has shuffle files stored on as well as the sizes of outputs for each reducer, for passing on to the reduce tasks.&lt;/p&gt;
&lt;p&gt;ShuffleMapTask 返回给调度程序的结果。 包括该任务存储了 Shuffle 文件的blockManager地址，以及给每个reducer的输出文件大小，以便传递给reduce。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;blockManager.shuffleServerId(): 这是当前节点的标识符，用于标识数据存储的位置。&lt;/li&gt;
&lt;li&gt;partitionLengths: 这是一个数组，包含了每个分区的数据长度。
更新 map 状态的目的是为了让 Spark 的调度器和后续的 reduce 任务知道每个分区的数据存储在哪里，以及每个分区的数据大小。这对于后续的 shuffle 读取操作至关重要，因为 reduce 任务需要知道从哪里读取数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;也即是，前一个stage写数据确定分区是通过分区器，而后一个stage读数据确定分区是通过&lt;code&gt;MapStatus&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;sortshufflewriter&#34;&gt;SortShuffleWriter
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  override def write(records: Iterator[Product2[K, V]]): Unit = {
    sorter = if (dep.mapSideCombine) {
      new ExternalSorter[K, V, C](
        context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer)
    } else {
      // In this case we pass neither an aggregator nor an ordering to the sorter, because we don&#39;t
      // care whether the keys get sorted in each partition; that will be done on the reduce side
      // if the operation being run is sortByKey.
      new ExternalSorter[K, V, V](
        context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer)
    }
    sorter.insertAll(records)

    // Don&#39;t bother including the time to open the merged output file in the shuffle write time,
    // because it just opens a single file, so is typically too fast to measure accurately
    // (see SPARK-3570).
    val mapOutputWriter = shuffleExecutorComponents.createMapOutputWriter(
      dep.shuffleId, mapId, dep.partitioner.numPartitions)
    sorter.writePartitionedMapOutput(dep.shuffleId, mapId, mapOutputWriter)
    partitionLengths = mapOutputWriter.commitAllPartitions(sorter.getChecksums).getPartitionLengths
    mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths, mapId)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;初始化一个sorter，如果map侧（上一个stage）需要聚合，那么就创建带&lt;code&gt;aggregater&lt;/code&gt;并按键排序的sorter，否则创建一个不带&lt;code&gt;aggregater&lt;/code&gt;的sorter;&lt;/li&gt;
&lt;li&gt;创建一个shuffleMapOutputWriter，写入器开启一个输出流，然后将给定reduce任务分区id的字节流持久化;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Creates a writer that can open an output stream to persist bytes targeted for a given reduce partition id.
The chunk corresponds to bytes in the given reduce partition. This will not be called twice for the same partition within any given map task. The partition identifier will be in the range of precisely 0 (inclusive) to numPartitions (exclusive), where numPartitions was provided upon the creation of this map output writer via ShuffleExecutorComponents.createMapOutputWriter(int, long, int).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;将记录写入sorter中，在sorter中经过处理后写出分区器分区后的数据&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;虽然叫sorter，但是如果map侧没有排序的需求，不会进行排序，如果map侧没有聚合的需求，也不会进行聚合。&lt;/p&gt;
&lt;p&gt;什么时候会排序：sortByKey,sortBy&lt;/p&gt;
&lt;p&gt;补充：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;orderBy(SparkSQL中，RDD没有这个api):对 DataFrame 或 Dataset 进行全局排序。
类似于 SQL 中的 ORDER BY，会对整个数据集进行排序。
需要进行 shuffle 操作，以确保全局排序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sortWithinPartitions:数据被写入 ExternalSorter，在内存中进行排序。
如果数据量超过内存限制，ExternalSorter 会将部分数据溢出到磁盘，并在需要时进行归并排序。
最终，排序后的数据被取出并生成新的 RDD。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;什么时候会聚合：reduceByKey,combineByKey,aggregateByKey(map侧和reduce侧都进行聚合，支持不同的聚合操作),foldByKey(map侧和reduce侧聚合操作相同时等同于aggregateByKey)&lt;/p&gt;
&lt;p&gt;注：map侧也叫分区内，reduce侧也叫分区间&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;向blockManager提交分区数据，并更新&lt;code&gt;MapStatus&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;选择策略&#34;&gt;选择策略
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  override def getWriter[K, V](
      handle: ShuffleHandle,
      mapId: Long,
      context: TaskContext,
      metrics: ShuffleWriteMetricsReporter): ShuffleWriter[K, V] = {
    val mapTaskIds = taskIdMapsForShuffle.computeIfAbsent(
      handle.shuffleId, _ =&amp;gt; new OpenHashSet[Long](16))
    mapTaskIds.synchronized { mapTaskIds.add(mapId) }
    val env = SparkEnv.get
    handle match {
      case unsafeShuffleHandle: SerializedShuffleHandle[K @unchecked, V @unchecked] =&amp;gt;
        new UnsafeShuffleWriter(
          env.blockManager,
          context.taskMemoryManager(),
          unsafeShuffleHandle,
          mapId,
          context,
          env.conf,
          metrics,
          shuffleExecutorComponents)
      case bypassMergeSortHandle: BypassMergeSortShuffleHandle[K @unchecked, V @unchecked] =&amp;gt;
        new BypassMergeSortShuffleWriter(
          env.blockManager,
          bypassMergeSortHandle,
          mapId,
          env.conf,
          metrics,
          shuffleExecutorComponents)
      case other: BaseShuffleHandle[K @unchecked, V @unchecked, _] =&amp;gt;
        new SortShuffleWriter(other, mapId, context, shuffleExecutorComponents)
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; 由源码可以看出，Spark的shuffle选择&lt;code&gt;shuffleWriter&lt;/code&gt;的策略是匹配shuffleHandle，依次匹配SerializedShuffleHandle、BypassMergeSortShuffleHandle、BaseShuffleHandle。&lt;/p&gt;
&lt;p&gt;而shuffleHandle的类型如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SerializedShuffleHandle:适用于需要高效序列化的场景。通常与 UnsafeShuffleWriter 搭配使用。
这种 handle 主要用于 Spark 的 Tungsten 引擎优化路径，利用了 Spark 的内存管理和序列化优化。&lt;/li&gt;
&lt;li&gt;BypassMergeSortShuffleHandle:适用于小规模 shuffle 操作，特别是当分区数较少时。
通常与 BypassMergeSortShuffleWriter 搭配使用。
这种 handle 通过绕过排序步骤来提高性能，适合分区数小于 spark.shuffle.sort.bypassMergeThreshold 的情况。&lt;/li&gt;
&lt;li&gt;BaseShuffleHandle:这是一个通用的 handle 类型，适用于大多数 shuffle 操作。
通常与 SortShuffleWriter 搭配使用。
适合需要排序的 shuffle 操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;选择策略&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;依赖类型:
Spark 的 shuffle 依赖（ShuffleDependency）在 RDD 的转换操作中被创建。
依赖类型决定了 shuffle 的处理方式。例如，ShuffleDependency 中的 serializer 和 partitioner 会影响 ShuffleHandle 的选择。&lt;/li&gt;
&lt;li&gt;配置参数:
spark.shuffle.sort.bypassMergeThreshold: 这个参数决定了是否使用 BypassMergeSortShuffleHandle。如果分区数小于这个阈值，Spark 会选择 BypassMergeSortShuffleHandle。
spark.shuffle.manager: 这个参数可以配置 shuffle 的管理方式，影响 ShuffleHandle 的选择。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;相关代码位于&lt;code&gt;org.apache.spark.internal.config.package.scala&lt;/code&gt;1497行&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  private[spark] val SHUFFLE_SORT_BYPASS_MERGE_THRESHOLD =
    ConfigBuilder(&amp;quot;spark.shuffle.sort.bypassMergeThreshold&amp;quot;)
      .doc(&amp;quot;In the sort-based shuffle manager, avoid merge-sorting data if there is no &amp;quot; +
        &amp;quot;map-side aggregation and there are at most this many reduce partitions&amp;quot;)
      .version(&amp;quot;1.1.1&amp;quot;)
      .intConf
      .createWithDefault(200)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;数据规模和分区数:
小规模数据和少量分区通常会使用 BypassMergeSortShuffleHandle。
大规模数据和大量分区通常会使用 SerializedShuffleHandle 或 BaseShuffleHandle。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;shufflereader&#34;&gt;ShuffleReader
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  
  /**
   * Get a reader for a range of reduce partitions (startPartition to endPartition-1, inclusive) to
   * read from a range of map outputs(startMapIndex to endMapIndex-1, inclusive).
   * If endMapIndex=Int.MaxValue, the actual endMapIndex will be changed to the length of total map
   * outputs of the shuffle in `getMapSizesByExecutorId`.
   *
   * Called on executors by reduce tasks.
   */
  override def getReader[K, C](
      handle: ShuffleHandle,
      startMapIndex: Int,
      endMapIndex: Int,
      startPartition: Int,
      endPartition: Int,
      context: TaskContext,
      metrics: ShuffleReadMetricsReporter): ShuffleReader[K, C] = {
    val baseShuffleHandle = handle.asInstanceOf[BaseShuffleHandle[K, _, C]]
    val (blocksByAddress, canEnableBatchFetch) =
      if (baseShuffleHandle.dependency.isShuffleMergeFinalizedMarked) {
        val res = SparkEnv.get.mapOutputTracker.getPushBasedShuffleMapSizesByExecutorId(
          handle.shuffleId, startMapIndex, endMapIndex, startPartition, endPartition)
        (res.iter, res.enableBatchFetch)
      } else {
        val address = SparkEnv.get.mapOutputTracker.getMapSizesByExecutorId(
          handle.shuffleId, startMapIndex, endMapIndex, startPartition, endPartition)
        (address, true)
      }
    new BlockStoreShuffleReader(
      handle.asInstanceOf[BaseShuffleHandle[K, _, C]], blocksByAddress, context, metrics,
      shouldBatchFetch =
        canEnableBatchFetch &amp;amp;&amp;amp; canUseBatchFetch(startPartition, endPartition, context))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spark的shuffleReader比起shuffleWriter来说就简单很多，只有一个&lt;code&gt;BlockStoreShuffleReader&lt;/code&gt;子类。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ShuffleHandle 转换：ShuffleHandle 被转换为 BaseShuffleHandle，以便访问 shuffle 依赖的详细信息。&lt;/li&gt;
&lt;li&gt;获取块地址和批量获取能力：
代码检查是否完成了 shuffle 合并（isShuffleMergeFinalizedMarked）。
如果合并已完成，使用推送式 shuffle 方法 getPushBasedShuffleMapSizesByExecutorId 获取块大小和批量获取能力。
否则，使用常规方法 getMapSizesByExecutorId 获取块地址。&lt;/li&gt;
&lt;li&gt;创建 BlockStoreShuffleReader：
使用获取的块地址和批量获取能力创建 BlockStoreShuffleReader。
shouldBatchFetch 参数决定是否启用批量获取，取决于 canEnableBatchFetch 和 canUseBatchFetch 的结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;BlockStoreShuffleReader&lt;/code&gt;读数据流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化&lt;/li&gt;
&lt;li&gt;获取数据块：
创建&lt;code&gt;ShuffleBlockFetcherIterator&lt;/code&gt;实例，用于从其他节点获取数据块。
该迭代器负责处理数据块的网络传输、反序列化和错误处理。
支持批量获取连续的数据块（如果条件允许），以提高网络传输效率。&lt;/li&gt;
&lt;li&gt;反序列化：
使用&lt;code&gt;serializerManager.wrapStream&lt;/code&gt;包装从网络获取的输入流。
使用&lt;code&gt;serializerInstance.deserializeStream&lt;/code&gt;将流反序列化为键值对迭代器。&lt;/li&gt;
&lt;li&gt;聚合(可选)：
如果&lt;code&gt;dep.aggregator&lt;/code&gt;被定义，使用聚合器对数据进行聚合。
如果&lt;code&gt;mapSideCombine&lt;/code&gt;为 true，则数据已经在 map 端部分聚合，使用 combineCombinersByKey。
否则，使用 combineValuesByKey 进行聚合。&lt;/li&gt;
&lt;li&gt;排序(可选)：
如果&lt;code&gt;dep.keyOrdering&lt;/code&gt;被定义，使用 ExternalSorter 对数据进行排序。
ExternalSorter 可以处理大规模数据集，通过将数据溢出到磁盘来进行排序。&lt;/li&gt;
&lt;li&gt;迭代器包装：
使用 InterruptibleIterator 包装最终的结果迭代器，以支持任务取消。
确保在任务取消时能够及时中断数据处理。&lt;/li&gt;
&lt;li&gt;结果返回：
返回一个 Iterator[Product2[K, C]]，包含所有读取和处理后的键值对&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Spark源码学习 Join策略</title>
        <link>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/</link>
        <pubDate>Sun, 17 Nov 2024 23:55:36 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/</guid>
        <description>&lt;p&gt;学习源码所用的Spark的版本是Spark3.3.2_2.12(Scala2.12写的Spark3.3.2)&lt;/p&gt;
&lt;h2 id=&#34;类别&#34;&gt;类别
&lt;/h2&gt;&lt;p&gt;Spark底层有五种join实现方式&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/1.png&#34;
	width=&#34;1920&#34;
	height=&#34;1030&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/1_hu16373391895739476467.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/1_hu16192374523649459711.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;前置介绍hashjoin&#34;&gt;前置介绍：HashJoin
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://www.6aiq.com/article/1533984288407&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;先来看看这样一条SQL语句：&lt;code&gt;select * from order,item where item.id = order.i_id&lt;/code&gt;，很简单一个Join节点，参与join的两张表是item和order，join key分别是item.id以及order.i_id。现在假设这个Join采用的是hash join算法，整个过程会经历三步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;确定Build Table以及Probe Table：这个概念比较重要，Build Table使用join key构建Hash Table，而Probe Table使用join key进行探测，探测成功就可以join在一起。通常情况下，小表会作为Build Table，大表作为Probe Table。此事例中item为Build Table，order为Probe Table。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;构建Hash Table：依次读取Build Table（item）的数据，对于每一行数据根据join key（item.id）进行hash，hash到对应的Bucket，生成hash table中的一条记录。数据缓存在内存中，如果内存放不下需要dump到外存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;探测：再依次扫描Probe Table（order）的数据，使用相同的hash函数映射Hash Table中的记录，映射成功之后再检查join条件（item.id = order.i_id），如果匹配成功就可以将两者join在一起。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/2.png&#34;
	width=&#34;640&#34;
	height=&#34;392&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/2_hu12648101483709186989.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/2_hu10412664838980808260.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;391px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;基本流程可以参考上图，这里有两个小问题需要关注：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hash join性能如何？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;很显然，hash join基本都只扫描两表一次，可以认为o(a+b)，较之最极端的笛卡尔集运算a*b，效率大大提升。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;为什么Build Table选择小表？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;道理很简单，因为构建的Hash Table最好能全部加载在内存，效率最高；这也决定了hash join算法只适合至少一个小表的join场景，对于两个大表的join场景并不适用。&lt;/p&gt;
&lt;p&gt;hash join是传统数据库中的单机join算法，在分布式环境下需要经过一定的分布式改造，就是尽可能利用分布式计算资源进行并行化计算，提高总体效率。hash join分布式改造一般有两种经典方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;broadcast hash join&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;将其中一张小表广播分发到另一张大表所在的分区节点上，分别并发地与其上的分区记录进行hash join。broadcast适用于小表很小，可以直接广播的场景。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;shuffled hash join&lt;/strong&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一旦小表数据量较大，此时就不再适合进行广播分发。这种情况下，可以根据join key相同必然分区相同的原理，将两张表分别按照join key进行重新组织分区，这样就可以将join分而治之，划分为很多小join，充分利用集群资源并行化。&lt;/p&gt;
&lt;p&gt;下面分别进行详细讲解。&lt;/p&gt;
&lt;h3 id=&#34;broadcasthashjoinexec&#34;&gt;BroadcastHashJoinExec
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;broadcast阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;将小表广播分发到大表所在的所有主机。广播算法可以有很多，最简单的是先发给driver，driver再统一分发给所有executor；要不就是基于BitTorrent的TorrentBroadcast。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;hash join阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在每个executor上执行单机版hash join，小表映射，大表试探。
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/3.png&#34;
	width=&#34;640&#34;
	height=&#34;351&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/3_hu5878782776316041114.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/3_hu14107248078688552454.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;437px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;SparkSQL规定broadcast hash join执行的基本条件为被广播小表必须小于参数&lt;code&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，默认为10M。
源码位于&lt;code&gt;org.apache.spark.sql.internal.SQLConf.scala&lt;/code&gt;,没找到SQLConf文件可以在BaseSessionStateBuilder里找到conf引用，然后&lt;code&gt;CTRL+左键&lt;/code&gt;查看源码。
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/4.png&#34;
	width=&#34;1920&#34;
	height=&#34;1030&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/4_hu12917825796720597905.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/4_hu12430590560678393374.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;shuffledhashjoinexec&#34;&gt;ShuffledHashJoinExec
&lt;/h3&gt;&lt;p&gt;在大数据条件下如果一张表很小，执行join操作最优的选择无疑是broadcast hash join，效率最高。但是一旦小表数据量增大，广播所需内存、带宽等资源必然就会太大，broadcast hash join就不再是最优方案。此时可以按照join key进行分区，根据key相同必然分区相同的原理，就可以将大表join分而治之，划分为很多小表的join，充分利用集群资源并行化。如下图所示，shuffle hash join也可以分为两步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shuffle阶段:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;分别将两个表按照join key进行分区，将相同join key的记录重分布到同一节点，两张表的数据会被重分布到集群中所有节点。这个过程称为shuffle。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;hash join阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每个分区节点上的数据单独执行单机hash join算法。
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/5.png&#34;
	width=&#34;640&#34;
	height=&#34;222&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/5_hu13792204227143600783.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/5_hu13175992835024326903.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;288&#34;
		data-flex-basis=&#34;691px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;sortmergejoinexec&#34;&gt;SortMergeJoinExec
&lt;/h3&gt;&lt;p&gt;SparkSQL对两张大表join采用了全新的算法——sort merge join，整个过程分为三个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shuffle阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;sort阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对单个分区节点的两表数据，分别进行排序。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;merge阶段：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则取更小一边。如下图所示：
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/6.png&#34;
	width=&#34;395&#34;
	height=&#34;237&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/6_hu8829640617333598188.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/6_hu1107606516430444359.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/7.png&#34;
	width=&#34;640&#34;
	height=&#34;330&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/7_hu268948268638298732.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-join%E7%AD%96%E7%95%A5/7_hu6909571737077120363.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;465px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;cartesianproductexec&#34;&gt;CartesianProductExec:
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;初始化：两个数据集被加载并分区。&lt;/li&gt;
&lt;li&gt;分区组合：每个分区的所有元素与另一个分区的所有元素组合。这在逻辑上类似于嵌套循环。&lt;/li&gt;
&lt;li&gt;生成所有组合：对每一对元素生成一个元组，形成笛卡尔积。结果集的大小为两个数据集大小的乘积。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;笛卡尔积会占用大量内存，使用笛卡尔积之前最好先过滤掉无用数据，其中一张表为极小表时建议广播。&lt;/p&gt;
&lt;h3 id=&#34;broadcastnestedloopjoinexec&#34;&gt;BroadcastNestedLoopJoinExec
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;broadcast阶段：将小表的数据复制并广播到大表分区数据所在的每个执行节点。&lt;/li&gt;
&lt;li&gt;嵌套循环连接：
&lt;ul&gt;
&lt;li&gt;在每个执行节点上，对于分区中的每一行，逐行扫描广播的小表。&lt;/li&gt;
&lt;li&gt;对每一对行执行连接条件，生成匹配的结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;生成结果：将匹配的行组合成结果集。结果在每个节点独立生成，最后输出为完整的连接结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外，Spark对非等值连接的支持只有这种和笛卡尔积（CartesianProduct）。
如果两张表都很大且无法广播，Spark 可能需要通过优化或变通的方法来处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据过滤：在连接前尽量过滤数据，减少处理的数据量。&lt;/li&gt;
&lt;li&gt;分区和缓存：有效地分区和缓存数据以提高性能。&lt;/li&gt;
&lt;li&gt;自定义 UDF：在某些情况下，使用自定义 UDF 可能会帮助实现复杂的连接逻辑。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;选择join的机制&#34;&gt;选择join的机制
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;相关源码位于&lt;code&gt;org.apache.spark.sql.execution&lt;/code&gt;下的141行&lt;code&gt;JoinSelection&lt;/code&gt;对象&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据连接策略提示、等价连接键的可用性和连接关系的大小，选择合适的连接物理计划。 以下是现有的连接策略、其特点和局限性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;broadcast hash join（BHJ）： 仅支持等价连接，而连接键无需可排序。 支持除全外部连接外的所有连接类型。 当广播方较小时，BHJ 通常比其他连接算法执行得更快。 不过，广播表是一种网络密集型操作，在某些情况下可能会导致 OOM 或性能不佳，尤其是当构建/广播方较大时。&lt;/li&gt;
&lt;li&gt;shuffled hash join： 仅支持等价连接，而连接键无需可排序。 支持所有连接类型。 从表中构建哈希映射是一个内存密集型操作，当联编侧很大时可能会导致 OOM。&lt;/li&gt;
&lt;li&gt;shuffle sort merge join（SMJ）： 仅支持等连接，且连接键必须是可排序的。 支持所有连接类型。&lt;/li&gt;
&lt;li&gt;Broadcast nested loop join(广播嵌套循环连接 BNLJ)： 支持等连接和非等连接。 支持所有连接类型，但优化了以下方面的实现： 1）在右外连接中广播左侧；2）在左外、左半、左反或存在连接中广播右侧；3）在类内连接中广播任一侧。 对于其他情况，我们需要多次扫描数据，这可能会相当慢。&lt;/li&gt;
&lt;li&gt;Shuffle-and-replicate nested loop join (洗牌复制嵌套循环连接,又称笛卡尔积连接)： 支持等连接和非等连接。 只支持内同类连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;源码中关于等值连接选择join的机制介绍如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;If it is an equi-join, we first look at the join hints w.r.t. the following order:
   1. broadcast hint: pick broadcast hash join if the join type is supported. If both sides
      have the broadcast hints, choose the smaller side (based on stats) to broadcast.
   2. sort merge hint: pick sort merge join if join keys are sortable.
   3. shuffle hash hint: We pick shuffle hash join if the join type is supported. If both
      sides have the shuffle hash hints, choose the smaller side (based on stats) as the
      build side.
   4. shuffle replicate NL hint: pick cartesian product if join type is inner like.

 If there is no hint or the hints are not applicable, we follow these rules one by one:
   1. Pick broadcast hash join if one side is small enough to broadcast, and the join type
      is supported. If both sides are small, choose the smaller side (based on stats)
      to broadcast.
   2. Pick shuffle hash join if one side is small enough to build local hash map, and is
      much smaller than the other side, and `spark.sql.join.preferSortMergeJoin` is false.
   3. Pick sort merge join if the join keys are sortable.
   4. Pick cartesian product if join type is inner like.
   5. Pick broadcast nested loop join as the final solution. It may OOM but we don&#39;t have
      other choice.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;翻译如下：&lt;/p&gt;
&lt;p&gt;如果是等值连接，我们首先按以下顺序查看连接提示(join hints)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;broadcast hint：如果支持广播散列连接(BHJ)，则选择广播散列连接。
如果双方有广播提示，则选择较小的一方（根据统计信息）进行广播。&lt;/li&gt;
&lt;li&gt;sort merge hint：如果连接键可排序，则选择排序合并连接。&lt;/li&gt;
&lt;li&gt;shuffle hash hint：如果支持连接类型，我们会选择洗牌散列连接。 如果双方都有洗牌散列提示，则选择较小的一方（基于统计信息）作为构建方。
构建侧。&lt;/li&gt;
&lt;li&gt;shuffle replicate NL 提示：如果连接类型是内连接，则选择笛卡尔积。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果没有提示或提示不适用，我们将逐一遵循这些规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果有一方足够小，可以广播，且连接类型支持，则选择广播散列连接。
支持。 如果两边都很小，则选择较小的一边（根据统计数据）
进行广播。&lt;/li&gt;
&lt;li&gt;如果一方的规模小到足以建立本地哈希映射，并且比另一方小很多，并且支持 &amp;ldquo;space&amp;rdquo;，则选择 &amp;ldquo;洗牌哈希连接&amp;rdquo;。
且 &lt;code&gt;spark.sql.join.preferSortMergeJoin&lt;/code&gt; 为 false。&lt;/li&gt;
&lt;li&gt;如果连接键可排序，则选择排序合并连接。&lt;/li&gt;
&lt;li&gt;如果连接类型为inner join（就是不明写join的join，即类似&lt;code&gt;select * from order,item&lt;/code&gt;），则选择笛卡尔积。&lt;/li&gt;
&lt;li&gt;选择广播嵌套循环连接作为最终解决方案。 可能会出现 OOM，但我们没有
其他选择。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;相关关键源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;def createJoinWithoutHint() = {
  createBroadcastHashJoin(false)
    .orElse(createShuffleHashJoin(false))
    .orElse(createSortMergeJoin())
    .orElse(createCartesianProduct())
    .getOrElse {
      // This join could be very slow or OOM
      val buildSide = getSmallerSide(left, right)
      Seq(joins.BroadcastNestedLoopJoinExec(
        planLater(left), planLater(right), buildSide, joinType, j.condition))
    }
}
        
if (hint.isEmpty) {
  createJoinWithoutHint()
} else {
  createBroadcastHashJoin(true)
    .orElse { if (hintToSortMergeJoin(hint)) createSortMergeJoin() else None }
    .orElse(createShuffleHashJoin(true))
    .orElse { if (hintToShuffleReplicateNL(hint)) createCartesianProduct() else None }
    .getOrElse(createJoinWithoutHint())
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;综上所述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有连接提示时,优先级从高到低：BroadcastHashJoin &amp;gt; SortMergeJoin &amp;gt; ShuffledHashJoin &amp;gt; CartesianProduct&lt;/li&gt;
&lt;li&gt;没有连接提示时，优先级从高到低(join代价从小到大)：BroadcastHashJoin &amp;gt; ShuffledHashJoin &amp;gt; SortMergeJoin &amp;gt; CartesianProduct &amp;gt; BroadcastNestedLoopJoin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：有提示时优先&lt;code&gt;SortMergeJoin&lt;/code&gt;,然后&lt;code&gt;ShuffledHashJoin&lt;/code&gt;；而没有提示时，优先&lt;code&gt;ShuffledHashJoin&lt;/code&gt;,然后&lt;code&gt;SortMergeJoin&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;总结：
数据仓库设计时最好避免大表与大表的join查询，SparkSQL也可以根据内存资源、带宽资源适量将参数spark.sql.autoBroadcastJoinThreshold调大，让更多join实际执行为broadcast hash join。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大表join极小表(表大小小于10M,可调整&lt;code&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;参数进行修改)，用BroadcastHashJoin&lt;/li&gt;
&lt;li&gt;大表join小表，用ShuffledHashJoin&lt;/li&gt;
&lt;li&gt;大表join大表，用SortMergeJoin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;非等值连接仅CartesianProduct 和 BroadcastNestedLoopJoin支持，常用BroadcastNestedLoopJoin。&lt;/p&gt;
&lt;h2 id=&#34;补充rdd中的join&#34;&gt;补充：RDD中的join
&lt;/h2&gt;&lt;p&gt;前文中介绍的join都是SparkSQL中join的底层实现，但是在Spark的RDD中，也有一个join函数。
具体实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Return an RDD containing all pairs of elements with matching keys in `this` and `other`. Each
   * pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in `this` and
   * (k, v2) is in `other`. Uses the given Partitioner to partition the output RDD.
   */
  def join[W](other: RDD[(K, W)], partitioner: Partitioner): RDD[(K, (V, W))] = self.withScope {
    this.cogroup(other, partitioner).flatMapValues( pair =&amp;gt;
      for (v &amp;lt;- pair._1.iterator; w &amp;lt;- pair._2.iterator) yield (v, w)
    )
  }

  /**
   * Perform a left outer join of `this` and `other`. For each element (k, v) in `this`, the
   * resulting RDD will either contain all pairs (k, (v, Some(w))) for w in `other`, or the
   * pair (k, (v, None)) if no elements in `other` have key k. Uses the given Partitioner to
   * partition the output RDD.
   */
  def leftOuterJoin[W](
      other: RDD[(K, W)],
      partitioner: Partitioner): RDD[(K, (V, Option[W]))] = self.withScope {
    this.cogroup(other, partitioner).flatMapValues { pair =&amp;gt;
      if (pair._2.isEmpty) {
        pair._1.iterator.map(v =&amp;gt; (v, None))
      } else {
        for (v &amp;lt;- pair._1.iterator; w &amp;lt;- pair._2.iterator) yield (v, Some(w))
      }
    }
  }

  /**
   * Perform a right outer join of `this` and `other`. For each element (k, w) in `other`, the
   * resulting RDD will either contain all pairs (k, (Some(v), w)) for v in `this`, or the
   * pair (k, (None, w)) if no elements in `this` have key k. Uses the given Partitioner to
   * partition the output RDD.
   */
  def rightOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner)
      : RDD[(K, (Option[V], W))] = self.withScope {
    this.cogroup(other, partitioner).flatMapValues { pair =&amp;gt;
      if (pair._1.isEmpty) {
        pair._2.iterator.map(w =&amp;gt; (None, w))
      } else {
        for (v &amp;lt;- pair._1.iterator; w &amp;lt;- pair._2.iterator) yield (Some(v), w)
      }
    }
  }

  /**
   * Perform a full outer join of `this` and `other`. For each element (k, v) in `this`, the
   * resulting RDD will either contain all pairs (k, (Some(v), Some(w))) for w in `other`, or
   * the pair (k, (Some(v), None)) if no elements in `other` have key k. Similarly, for each
   * element (k, w) in `other`, the resulting RDD will either contain all pairs
   * (k, (Some(v), Some(w))) for v in `this`, or the pair (k, (None, Some(w))) if no elements
   * in `this` have key k. Uses the given Partitioner to partition the output RDD.
   */
  def fullOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner)
      : RDD[(K, (Option[V], Option[W]))] = self.withScope {
    this.cogroup(other, partitioner).flatMapValues {
      case (vs, Seq()) =&amp;gt; vs.iterator.map(v =&amp;gt; (Some(v), None))
      case (Seq(), ws) =&amp;gt; ws.iterator.map(w =&amp;gt; (None, Some(w)))
      case (vs, ws) =&amp;gt; for (v &amp;lt;- vs.iterator; w &amp;lt;- ws.iterator) yield (Some(v), Some(w))
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RDD的join实际是匹配两个RDD,以join为例，遍历(iterator)两个RDD的分区，调用cogroup函数将两个RDD的相同分区联合成一个turple返回。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Spark源码学习 累加器</title>
        <link>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/</link>
        <pubDate>Sat, 09 Nov 2024 20:39:50 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/</guid>
        <description>&lt;h2 id=&#34;简介&#34;&gt;简介
&lt;/h2&gt;&lt;p&gt; 累加器用来把 Executor 端变量信息聚合到 Driver 端。在 Driver 程序中定义的变量，在
Executor 端的每个 Task 都会得到这个变量的一份新的副本，每个 task 更新这些副本的值后，
传回 Driver 端进行 merge。&lt;/p&gt;
&lt;h2 id=&#34;快速上手&#34;&gt;快速上手
&lt;/h2&gt;&lt;p&gt;数据如下，数据格式为学生姓名，学生课程，课程成绩。要求计算选择了Database课程的人数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/1.png&#34;
	width=&#34;966&#34;
	height=&#34;650&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/1_hu14818999790699540141.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/1_hu16384632438318607173.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;148&#34;
		data-flex-basis=&#34;356px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SprakReview

import org.apache.spark.util.LongAccumulator
import org.apache.spark.{SparkConf, SparkContext}

object AccumulatorTry {
  def main(args: Array[String]): Unit = {
    val sparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;累加器学习&amp;quot;)
    val sc = new SparkContext(sparkConf)

    val data = sc.textFile(&amp;quot;E:\\TestData\\sparkjob3\\task1\\Data01.txt&amp;quot;)
    val dbCount: LongAccumulator = sc.longAccumulator(&amp;quot;dbCount&amp;quot;)
    data.foreach { line =&amp;gt;
      val course = line.split(&amp;quot;,&amp;quot;)(1)
      if (course == &amp;quot;DataBase&amp;quot;) {
        // 每当课程为&amp;quot;DataBase&amp;quot;时，累加器的值加1
        dbCount.add(1)
      }
    }
    println(&amp;quot;DataBase count: &amp;quot; + dbCount.value)
    //累加器实现查找选择了DataBase课的学生

    sc.stop()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/2.png&#34;
	width=&#34;1920&#34;
	height=&#34;1030&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/2_hu4940220256607226227.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E7%B4%AF%E5%8A%A0%E5%99%A8/2_hu5074419408996378584.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;原理简介&#34;&gt;原理简介
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Create and register a long accumulator, which starts with 0 and accumulates inputs by `add`.
   */
  def longAccumulator: LongAccumulator = {
    val acc = new LongAccumulator
    register(acc)
    acc
  }

  /**
   * Create and register a long accumulator, which starts with 0 and accumulates inputs by `add`.
   */
  def longAccumulator(name: String): LongAccumulator = {
    val acc = new LongAccumulator
    register(acc, name)
    acc
  }

  /**
   * Create and register a double accumulator, which starts with 0 and accumulates inputs by `add`.
   */
  def doubleAccumulator: DoubleAccumulator = {
    val acc = new DoubleAccumulator
    register(acc)
    acc
  }

  /**
   * Create and register a double accumulator, which starts with 0 and accumulates inputs by `add`.
   */
  def doubleAccumulator(name: String): DoubleAccumulator = {
    val acc = new DoubleAccumulator
    register(acc, name)
    acc
  }

  /**
   * Create and register a `CollectionAccumulator`, which starts with empty list and accumulates
   * inputs by adding them into the list.
   */
  def collectionAccumulator[T]: CollectionAccumulator[T] = {
    val acc = new CollectionAccumulator[T]
    register(acc)
    acc
  }

  /**
   * Create and register a `CollectionAccumulator`, which starts with empty list and accumulates
   * inputs by adding them into the list.
   */
  def collectionAccumulator[T](name: String): CollectionAccumulator[T] = {
    val acc = new CollectionAccumulator[T]
    register(acc, name)
    acc
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spark中的累加器有三种&lt;code&gt;doubleAccumulator&lt;/code&gt;、&lt;code&gt;longAccumulator&lt;/code&gt;、&lt;code&gt;collectionAccumulator&lt;/code&gt;。分别有传入累加器名字和不穿名字的函数。
累加器会新建一个对应的累加器类，然后在driver注册，传不传名字的区别是注册的时候会不会传入名字，最后返回已注册的累加器。&lt;/p&gt;
&lt;p&gt;源码中对注册的解释如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Registers an AccumulatorV2 created on the driver such that it can be used on the executors.
All accumulators registered here can later be used as a container for accumulating partial values across multiple tasks. This is what org.apache.spark.scheduler.DAGScheduler does. Note: if an accumulator is registered here, it should also be registered with the active context cleaner for cleanup so as to avoid memory leaks.
If an AccumulatorV2 with the same ID was already registered, this does nothing instead of overwriting it. We will never register same accumulator twice, this is just a sanity check.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; 注册在driver上创建的 AccumulatorV2，以便在executor上使用。 在此注册的所有累加器以后都可用作容器，用于累加多个任务中的部分值。 这就是 org.apache.spark.scheduler.DAGScheduler 的作用。 注意：如果在这里注册了累加器，那么它也应注册到活动上下文清理器中进行清理，以避免内存泄漏。 如果已经注册了具有相同 ID 的 AccumulatorV2，则不会做任何操作，而会覆盖它。 我们永远不会注册同一个累加器两次，这只是为了进行合理性检查。&lt;/p&gt;
&lt;h2 id=&#34;累加器类&#34;&gt;累加器类
&lt;/h2&gt;&lt;h3 id=&#34;longaccumulator&#34;&gt;LongAccumulator
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;
/**
 * An [[AccumulatorV2 accumulator]] for computing sum, count, and average of 64-bit integers.
 *
 * @since 2.0.0
 */
class LongAccumulator extends AccumulatorV2[jl.Long, jl.Long] {
  private var _sum = 0L
  private var _count = 0L

  /**
   * Returns false if this accumulator has had any values added to it or the sum is non-zero.
   *
   * @since 2.0.0
   */
  override def isZero: Boolean = _sum == 0L &amp;amp;&amp;amp; _count == 0

  override def copy(): LongAccumulator = {
    val newAcc = new LongAccumulator
    newAcc._count = this._count
    newAcc._sum = this._sum
    newAcc
  }

  override def reset(): Unit = {
    _sum = 0L
    _count = 0L
  }

  /**
   * Adds v to the accumulator, i.e. increment sum by v and count by 1.
   * @since 2.0.0
   */
  override def add(v: jl.Long): Unit = {
    _sum += v
    _count += 1
  }

  /**
   * Adds v to the accumulator, i.e. increment sum by v and count by 1.
   * @since 2.0.0
   */
  def add(v: Long): Unit = {
    _sum += v
    _count += 1
  }

  /**
   * Returns the number of elements added to the accumulator.
   * @since 2.0.0
   */
  def count: Long = _count

  /**
   * Returns the sum of elements added to the accumulator.
   * @since 2.0.0
   */
  def sum: Long = _sum

  /**
   * Returns the average of elements added to the accumulator.
   * @since 2.0.0
   */
  def avg: Double = _sum.toDouble / _count

  override def merge(other: AccumulatorV2[jl.Long, jl.Long]): Unit = other match {
    case o: LongAccumulator =&amp;gt;
      _sum += o.sum
      _count += o.count
    case _ =&amp;gt;
      throw new UnsupportedOperationException(
        s&amp;quot;Cannot merge ${this.getClass.getName} with ${other.getClass.getName}&amp;quot;)
  }

  private[spark] def setValue(newValue: Long): Unit = _sum = newValue

  override def value: jl.Long = _sum
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;LongAccumulator类是一个自定义累加器，用于计算64位整数的总和、计数和平均值。它继承自AccumulatorV2。
私有变量_sum:(存储累加的总和)、_count(存储累加的元素个数)。
用于计算整型数据的总和、计数和平均值，并在driver中访问结果。&lt;/p&gt;
&lt;p&gt;isZero方法:检查累加器是否未添加任何值或总和为零。&lt;/p&gt;
&lt;p&gt;copy方法:创建累加器的副本，包括当前的_sum和_count。&lt;/p&gt;
&lt;p&gt;reset方法:将_sum和_count重置为零。&lt;/p&gt;
&lt;p&gt;add方法:增加一个值到累加器中，更新_sum和_count。有两个重载版本，接收jl.Long和Long类型。
(jl.Long是java.lang.Long的缩写。是Java的类类型，用于包装一个long的值。
提供了许多方法来处理long类型的数据，比如转换、比较等。用于与Java类进行交互时的包装器类型。
Long是Scala的基本数据类型。直接表示一个64位的整数。)&lt;/p&gt;
&lt;p&gt;count方法:返回添加到累加器中的元素个数。&lt;/p&gt;
&lt;p&gt;sum方法:返回累加器中的元素总和。&lt;/p&gt;
&lt;p&gt;avg方法:返回累加器中元素的平均值。&lt;/p&gt;
&lt;p&gt;merge方法:将另一个LongAccumulator的值合并到当前累加器。如果尝试与非LongAccumulator类型合并，会抛出异常。&lt;/p&gt;
&lt;p&gt;setValue方法:设置累加器的总和值（仅用于内部）。&lt;/p&gt;
&lt;p&gt;value方法:返回累加器的当前总和。&lt;/p&gt;
&lt;h3 id=&#34;doubleaccumulator&#34;&gt;DoubleAccumulator
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;
/**
 * An [[AccumulatorV2 accumulator]] for computing sum, count, and averages for double precision
 * floating numbers.
 *
 * @since 2.0.0
 */
class DoubleAccumulator extends AccumulatorV2[jl.Double, jl.Double] {
  private var _sum = 0.0
  private var _count = 0L

  /**
   * Returns false if this accumulator has had any values added to it or the sum is non-zero.
   */
  override def isZero: Boolean = _sum == 0.0 &amp;amp;&amp;amp; _count == 0

  override def copy(): DoubleAccumulator = {
    val newAcc = new DoubleAccumulator
    newAcc._count = this._count
    newAcc._sum = this._sum
    newAcc
  }

  override def reset(): Unit = {
    _sum = 0.0
    _count = 0L
  }

  /**
   * Adds v to the accumulator, i.e. increment sum by v and count by 1.
   * @since 2.0.0
   */
  override def add(v: jl.Double): Unit = {
    _sum += v
    _count += 1
  }

  /**
   * Adds v to the accumulator, i.e. increment sum by v and count by 1.
   * @since 2.0.0
   */
  def add(v: Double): Unit = {
    _sum += v
    _count += 1
  }

  /**
   * Returns the number of elements added to the accumulator.
   * @since 2.0.0
   */
  def count: Long = _count

  /**
   * Returns the sum of elements added to the accumulator.
   * @since 2.0.0
   */
  def sum: Double = _sum

  /**
   * Returns the average of elements added to the accumulator.
   * @since 2.0.0
   */
  def avg: Double = _sum / _count

  override def merge(other: AccumulatorV2[jl.Double, jl.Double]): Unit = other match {
    case o: DoubleAccumulator =&amp;gt;
      _sum += o.sum
      _count += o.count
    case _ =&amp;gt;
      throw new UnsupportedOperationException(
        s&amp;quot;Cannot merge ${this.getClass.getName} with ${other.getClass.getName}&amp;quot;)
  }

  private[spark] def setValue(newValue: Double): Unit = _sum = newValue

  override def value: jl.Double = _sum
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;DoubleAccumulator&lt;/code&gt;与&lt;code&gt;LongAccumulator&lt;/code&gt;区别不大，主要区别在&lt;code&gt;DoubleAccumulator&lt;/code&gt;的_sum为Double类型。&lt;/p&gt;
&lt;h3 id=&#34;collectionaccumulator&#34;&gt;CollectionAccumulator
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;
/**
 * An [[AccumulatorV2 accumulator]] for collecting a list of elements.
 *
 * @since 2.0.0
 */
class CollectionAccumulator[T] extends AccumulatorV2[T, java.util.List[T]] {
  private var _list: java.util.List[T] = _

  private def getOrCreate = {
    _list = Option(_list).getOrElse(new java.util.ArrayList[T]())
    _list
  }

  /**
   * Returns false if this accumulator instance has any values in it.
   */
  override def isZero: Boolean = this.synchronized(getOrCreate.isEmpty)

  override def copyAndReset(): CollectionAccumulator[T] = new CollectionAccumulator

  override def copy(): CollectionAccumulator[T] = {
    val newAcc = new CollectionAccumulator[T]
    this.synchronized {
      newAcc.getOrCreate.addAll(getOrCreate)
    }
    newAcc
  }

  override def reset(): Unit = this.synchronized {
    _list = null
  }

  override def add(v: T): Unit = this.synchronized(getOrCreate.add(v))

  override def merge(other: AccumulatorV2[T, java.util.List[T]]): Unit = other match {
    case o: CollectionAccumulator[T] =&amp;gt; this.synchronized(getOrCreate.addAll(o.value))
    case _ =&amp;gt; throw new UnsupportedOperationException(
      s&amp;quot;Cannot merge ${this.getClass.getName} with ${other.getClass.getName}&amp;quot;)
  }

  override def value: java.util.List[T] = this.synchronized {
    java.util.Collections.unmodifiableList(new ArrayList[T](getOrCreate))
  }

  private[spark] def setValue(newValue: java.util.List[T]): Unit = this.synchronized {
    _list = null
    getOrCreate.addAll(newValue)
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; CollectionAccumulator类是一个用于收集元素列表的自定义累加器。它继承自AccumulatorV2(在Spark中创建累加器的基类,自定义累加器也需要继承这个类)。具有私有变量 _list，用于存储累积的元素列表，初始为null。使用synchronized确保了对_list的操作是线程安全的。主要用途是在任务中收集元素并在driver上提供收集到的数据。 _list类型是java.util.List，所以java.util.List的方法都可以在这里正常使用（&lt;code&gt;setValue&lt;/code&gt;就是先情况_list，再调用List的&lt;code&gt;addAll&lt;/code&gt;添加一个&lt;code&gt;java.util.List&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;getOrCreate&lt;/code&gt;方法:确保_list已初始化，如果为null，则创建一个新的ArrayList(java.util.ArrayList)。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;isZero&lt;/code&gt;方法:检查累加器是否为空，如果为空则返回true。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;copyAndReset&lt;/code&gt;方法:创建一个没有累积值的新CollectionAccumulator。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;copy&lt;/code&gt;方法:创建一个新的CollectionAccumulator并复制当前元素。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reset&lt;/code&gt;方法:通过将_list设置为null来清空累加器。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;add&lt;/code&gt;方法:向累加器中添加一个元素。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;merge&lt;/code&gt;方法:将另一个累加器的值合并到这个累加器中，仅支持与另一个CollectionAccumulator合并。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;value&lt;/code&gt;方法:返回累积列表的不可修改视图。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;setValue&lt;/code&gt;方法:重置累加器并设置为新的元素列表。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Spark源码学习 广播变量</title>
        <link>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/</link>
        <pubDate>Thu, 07 Nov 2024 14:51:19 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/</guid>
        <description>&lt;h2 id=&#34;简介&#34;&gt;简介
&lt;/h2&gt;&lt;p&gt;广播变量允许程序员在每台机器上缓存只读变量，而不是随任务一起发送副本。 例如，它们可以用来以高效的方式为每个节点提供一个大型输入数据集的副本。 Spark 还尝试使用高效的广播算法分发广播变量，以降低通信成本。 广播变量是通过调用 broadcast 从变量 v 中创建的。 广播变量是 v 的包装器，其值可通过调用 value 方法访问。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/1.png&#34;
	width=&#34;1249&#34;
	height=&#34;889&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/1_hu9234698187790083378.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/1_hu17366738427305287415.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;337px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/2.png&#34;
	width=&#34;1763&#34;
	height=&#34;952&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/2_hu1508007316500837288.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/2_hu13925634685911099771.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;444px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;快速上手&#34;&gt;快速上手
&lt;/h2&gt;&lt;p&gt;广播变量使用如简介中所说，使用&lt;code&gt;sc.broadcast()&lt;/code&gt;包装一个变量，就创建了一个广播变量。访问广播变量的值可以通过调用其value方法，即&lt;code&gt;broadV.value()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import org.apache.spark.broadcast.Broadcast
import org.apache.spark.{SparkConf, SparkContext}

object BroadCastTry {
  def main(args: Array[String]): Unit = {
    val sparkConf: SparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;广播变量练习&amp;quot;)
    val sc = new SparkContext(sparkConf)

    val v = Array(1,2,3,4,5,6)
    // 创建广播变量
    val broadV:Broadcast[Array[Int]] = sc.broadcast(v)

    //打印广播变量
    println(broadV.value.mkString(&amp;quot;Array(&amp;quot;, &amp;quot;, &amp;quot;, &amp;quot;)&amp;quot;))

    //销毁广播变量
    broadV.destroy()

    sc.stop()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/3.png&#34;
	width=&#34;1920&#34;
	height=&#34;1030&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/3_hu12592535932714623619.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/3_hu13777497629336887710.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;原理简介&#34;&gt;原理简介
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://cloud.tencent.com/developer/article/1484260&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spark Core源码精读计划11 | Spark广播机制的实现&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注：本次源码阅读使用的是Spark_2.12-3.3.2(scala2.12版本写的Spark3.3.2)&lt;/p&gt;
&lt;p&gt;简单地说，广播变量的流程如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;广播变量由Application的Driver使用&lt;code&gt;BroadcastManager&lt;/code&gt;创建，并存储在&lt;code&gt;BlockManager&lt;/code&gt;中&lt;/li&gt;
&lt;li&gt;Driver将广播变量的值写到Block中，这样在driver上执行的tasks不会再创建一份新的广播变量副本&lt;/li&gt;
&lt;li&gt;Executor需要使用这个变量时，先从本地&lt;code&gt;BlockManager&lt;/code&gt;中查找有无该变量，没有的话从Driver的&lt;code&gt;BlockManager&lt;/code&gt;远程读取该变量&lt;/li&gt;
&lt;li&gt;Executor获取到这个广播变量后就将它缓存到本地的&lt;code&gt;BlockManager&lt;/code&gt;中，避免重复地远程获取，提高性能。
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/4.png&#34;
	width=&#34;1830&#34;
	height=&#34;872&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/4_hu6247838819089611269.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/4_hu5942886300715633446.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用广播变量能提高性能的原因是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少数据传输：广播变量将数据从Driver节点传输到每个Executor，只进行一次网络传输，而不是在每个任务中重复传输。&lt;/li&gt;
&lt;li&gt;本地缓存：一旦Executor接收到广播变量，它会将其缓存本地，供后续任务使用，避免重复的远程获取。&lt;/li&gt;
&lt;li&gt;内存效率：通过共享相同的数据副本，广播变量减少了Executor内存中的数据冗余。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些特性一起显著减少了网络I/O和内存开销，提升了分布式计算的性能和效率。但是广播变量只能用在只读变量上，而且只适合用在比较大的变量上。&lt;/p&gt;
&lt;p&gt;因为对于比较小的变量，直接传递给每个任务的开销很低，而且广播机制增大了任务复杂性。不能用于可变变量的原因也很明显，广播变量是由Driver创建，并由Executor远程读取。Driver或者Executor修改后都会导致计算结果错误。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;补充：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;BroadcastManager&lt;/code&gt;是位于&lt;code&gt;org.apache.spark.broadcast&lt;/code&gt;下的类，用于创建和管理广播变量，&lt;code&gt;BlockManager&lt;/code&gt;是位于&lt;code&gt;org.apache.spark.storage&lt;/code&gt;下的类，用于在每个节点（Driver和Executor）上运行的管理器，为本地和远程向各种存储（内存、磁盘和堆外）放入和检索数据块提供接口。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Broadcast&lt;/code&gt;是位于&lt;code&gt;org.apache.spark.broadcast&lt;/code&gt;下的抽象类，只有&lt;code&gt;TorrentBroadcast&lt;/code&gt;一个子类，早期还有一个&lt;code&gt;HttpBroadcast&lt;/code&gt;子类。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TorrentBroadcast&lt;/code&gt;是类似于 BitTorrent 的 Broadcast 实现。有同名类和对象。其机制如下： Driver将序列化对象分成小块，并将这些小块存储在Executor的 BlockManager 中。 在每个Executor上，Executor首先尝试从其 BlockManager 中获取对象。 如果对象不存在，Executor就会使用远程获取功能，从Driver和/或其他Executor（如果有的话）中获取小块对象。 获取小块后，它会将小块放入自己的 BlockManager 中，供其他执行器取用。 这样，驱动程序就不会成为发送多份广播数据（每个执行器一份）的瓶颈。 初始化时，TorrentBroadcast 对象会读取 SparkEnv.get.conf 文件。&lt;/p&gt;
&lt;h2 id=&#34;广播管理器broadcastmanager&#34;&gt;广播管理器BroadcastManager
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;
package org.apache.spark.broadcast

import java.util.Collections
import java.util.concurrent.atomic.AtomicLong

import scala.reflect.ClassTag

import org.apache.commons.collections4.map.AbstractReferenceMap.ReferenceStrength
import org.apache.commons.collections4.map.ReferenceMap

import org.apache.spark.SparkConf
import org.apache.spark.api.python.PythonBroadcast
import org.apache.spark.internal.Logging

private[spark] class BroadcastManager(
    val isDriver: Boolean, conf: SparkConf) extends Logging {

  private var initialized = false
  private var broadcastFactory: BroadcastFactory = null

  initialize()

  // Called by SparkContext or Executor before using Broadcast
  private def initialize(): Unit = {
    synchronized {
      if (!initialized) {
        broadcastFactory = new TorrentBroadcastFactory
        broadcastFactory.initialize(isDriver, conf)
        initialized = true
      }
    }
  }

  def stop(): Unit = {
    broadcastFactory.stop()
  }

  private val nextBroadcastId = new AtomicLong(0)

  private[broadcast] val cachedValues =
    Collections.synchronizedMap(
      new ReferenceMap(ReferenceStrength.HARD, ReferenceStrength.WEAK)
        .asInstanceOf[java.util.Map[Any, Any]]
    )

  def newBroadcast[T: ClassTag](value_ : T, isLocal: Boolean): Broadcast[T] = {
    val bid = nextBroadcastId.getAndIncrement()
    value_ match {
      case pb: PythonBroadcast =&amp;gt;
        // SPARK-28486: attach this new broadcast variable&#39;s id to the PythonBroadcast,
        // so that underlying data file of PythonBroadcast could be mapped to the
        // BroadcastBlockId according to this id. Please see the specific usage of the
        // id in PythonBroadcast.readObject().
        pb.setBroadcastId(bid)

      case _ =&amp;gt; // do nothing
    }
    broadcastFactory.newBroadcast[T](value_, isLocal, bid)
  }

  def unbroadcast(id: Long, removeFromDriver: Boolean, blocking: Boolean): Unit = {
    broadcastFactory.unbroadcast(id, removeFromDriver, blocking)
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;BroadcastManager创建时传入两个参数&lt;code&gt;isDriver(是否是Driver)&lt;/code&gt;、&lt;code&gt;conf(Spark配置文件)&lt;/code&gt;。早期版本还有第三个变量&lt;code&gt;securityManager（对应的SecurityManager）&lt;/code&gt;,这里我只是看参考资料中的源码知道的，第三个变量具体的作用不做了解。&lt;/p&gt;
&lt;h3 id=&#34;成员变量&#34;&gt;成员变量
&lt;/h3&gt;&lt;p&gt;BroadcastManager内有四个成员变量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;initialized&lt;/code&gt;表示BroadcastManager是否已经初始化完成。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;broadcastFactory&lt;/code&gt;持有广播工厂的实例（类型是BroadcastFactory特征的实现类）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nextBroadcastId&lt;/code&gt;表示下一个广播变量的唯一标识（AtomicLong类型的）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cachedValues&lt;/code&gt;用来缓存已广播出去的变量。它属于ReferenceMap类型，是apache-commons提供的一个弱引用映射数据结构。与我们常见的各种Map不同，它的键值对有可能会在GC过程中被回收。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;初始化逻辑&#34;&gt;初始化逻辑
&lt;/h3&gt;&lt;p&gt;initialize()方法做的事情也非常简单，它首先判断BroadcastManager是否已初始化。如果未初始化，就新建广播工厂TorrentBroadcastFactory，将其初始化，然后将初始化标记设为true。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  private def initialize(): Unit = {
    synchronized {
      if (!initialized) {
        broadcastFactory = new TorrentBroadcastFactory
        broadcastFactory.initialize(isDriver, conf)
        initialized = true
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;对外提供的方法&#34;&gt;对外提供的方法
&lt;/h3&gt;&lt;p&gt;BroadcastManager提供的方法有两个：newBroadcast()方法，用于创建一个新的广播变量；以及unbroadcast()方法，将已存在的广播变量取消广播。它们都是直接调用了&lt;code&gt;TorrentBroadcastFactory&lt;/code&gt;中的同名方法。因此我们必须通过阅读&lt;code&gt;TorrentBroadcastFactory&lt;/code&gt;的相关源码，才能了解Spark广播机制的细节。&lt;/p&gt;
&lt;h2 id=&#34;广播工厂类torrentbroadcastfactory&#34;&gt;广播工厂类TorrentBroadcastFactory
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package org.apache.spark.broadcast

import scala.reflect.ClassTag

import org.apache.spark.SparkConf

/**
 * A [[org.apache.spark.broadcast.Broadcast]] implementation that uses a BitTorrent-like
 * protocol to do a distributed transfer of the broadcasted data to the executors. Refer to
 * [[org.apache.spark.broadcast.TorrentBroadcast]] for more details.
 */
private[spark] class TorrentBroadcastFactory extends BroadcastFactory {

  override def initialize(isDriver: Boolean, conf: SparkConf): Unit = { }

  override def newBroadcast[T: ClassTag](value_ : T, isLocal: Boolean, id: Long): Broadcast[T] = {
    new TorrentBroadcast[T](value_, id)
  }

  override def stop(): Unit = { }

  /**
   * Remove all persisted state associated with the torrent broadcast with the given ID.
   * @param removeFromDriver Whether to remove state from the driver.
   * @param blocking Whether to block until unbroadcasted
   */
  override def unbroadcast(id: Long, removeFromDriver: Boolean, blocking: Boolean): Unit = {
    TorrentBroadcast.unpersist(id, removeFromDriver, blocking)
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由源码可知，&lt;code&gt;TorrentBroadcastFactory&lt;/code&gt;的&lt;code&gt;newBroadcast()&lt;/code&gt;方法实际是新建了一个&lt;code&gt;TorrentBroadcast&lt;/code&gt;类，并传入了这个类的id和值。
&lt;code&gt;TorrentBroadcast&lt;/code&gt;类的详情参见下节。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TorrentBroadcastFactory&lt;/code&gt;的&lt;code&gt;unbroadcast()&lt;/code&gt;方法传入了TorrentBroadcast类的id、
removeFromDriver（是否从驱动程序中移除状态）、blocking （是否直到未广播仍然在堵塞）。
然后删除与给定 ID 的 torrent 广播相关的所有持久化状态。这个删除持久化状态实际是&lt;code&gt;SparkEnv.get.blockManager.master.removeBroadcast(id, removeFromDriver, blocking)&lt;/code&gt;。相关代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  def removeBroadcast(broadcastId: Long, removeFromMaster: Boolean, blocking: Boolean): Unit = {
    val future = driverEndpoint.askSync[Future[Seq[Int]]](
      RemoveBroadcast(broadcastId, removeFromMaster))
    future.failed.foreach(e =&amp;gt;
      logWarning(s&amp;quot;Failed to remove broadcast $broadcastId&amp;quot; +
        s&amp;quot; with removeFromMaster = $removeFromMaster - ${e.getMessage}&amp;quot;, e)
    )(ThreadUtils.sameThread)
    if (blocking) {
      // the underlying Futures will timeout anyway, so it&#39;s safe to use infinite timeout here
      RpcUtils.INFINITE_TIMEOUT.awaitResult(future)
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;torrentbroadcast类&#34;&gt;TorrentBroadcast类
&lt;/h2&gt;&lt;h3 id=&#34;成员变量-1&#34;&gt;成员变量
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;_value：广播块的具体数据。注意它由lazy关键字定义，因此是懒加载的，也就是在TorrentBroadcast构造时不会调用readBroadcastBlock()方法获取数据，而会推迟到第一次访问_value时。&lt;/li&gt;
&lt;li&gt;compressionCodec：广播块的压缩编解码逻辑。当配置项spark.broadcast.compress为true时，会启用压缩。&lt;/li&gt;
&lt;li&gt;blockSize：广播块的大小。由spark.broadcast.blockSize配置项来控制，默认值4MB。&lt;/li&gt;
&lt;li&gt;broadcastId：广播变量的ID。BroadcastBlockId是个结构非常简单的case class，每产生一个新的广播变量就会自增。&lt;/li&gt;
&lt;li&gt;numBlocks：该广播变量包含的块数量。它与_value不同，并没有lazy关键字定义，因此在TorrentBroadcast构造时就会直接调用writeBlocks()方法。&lt;/li&gt;
&lt;li&gt;checksumEnabled：是否允许对广播块计算校验值，由spark.broadcast.checksum配置项控制，默认值true。&lt;/li&gt;
&lt;li&gt;checksums：广播块的校验值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;writeblocks&#34;&gt;writeBlocks()
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  private def writeBlocks(value: T): Int = {
    import StorageLevel._
    // Store a copy of the broadcast variable in the driver so that tasks run on the driver
    // do not create a duplicate copy of the broadcast variable&#39;s value.
    val blockManager = SparkEnv.get.blockManager
    if (!blockManager.putSingle(broadcastId, value, MEMORY_AND_DISK, tellMaster = false)) {
      throw new SparkException(s&amp;quot;Failed to store $broadcastId in BlockManager&amp;quot;)
    }
    try {
      val blocks =
        TorrentBroadcast.blockifyObject(value, blockSize, SparkEnv.get.serializer, compressionCodec)
      if (checksumEnabled) {
        checksums = new Array[Int](blocks.length)
      }
      blocks.zipWithIndex.foreach { case (block, i) =&amp;gt;
        if (checksumEnabled) {
          checksums(i) = calcChecksum(block)
        }
        val pieceId = BroadcastBlockId(id, &amp;quot;piece&amp;quot; + i)
        val bytes = new ChunkedByteBuffer(block.duplicate())
        if (!blockManager.putBytes(pieceId, bytes, MEMORY_AND_DISK_SER, tellMaster = true)) {
          throw new SparkException(s&amp;quot;Failed to store $pieceId of $broadcastId &amp;quot; +
            s&amp;quot;in local BlockManager&amp;quot;)
        }
      }
      blocks.length
    } catch {
      case t: Throwable =&amp;gt;
        logError(s&amp;quot;Store broadcast $broadcastId fail, remove all pieces of the broadcast&amp;quot;)
        blockManager.removeBroadcast(id, tellMaster = true)
        throw t
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;获取BlockManager实例，调用其putSingle()方法将广播数据作为单个对象写入本地存储。注意StorageLevel为MEMORY_AND_DISK，亦即在内存不足时会溢写到磁盘，且副本数为1，不会进行复制。&lt;/li&gt;
&lt;li&gt;调用blockifyObject()方法将广播数据转化为块(block)，即Spark存储的基本单元。
使用的序列化器为SparkEnv中指定的序列化器（默认Java自带的序列化，另外Spark实现了kryo序列化，可以在SparkEnv中指定）。
如果校验值开关有效，就用calcChecksum()方法为每个块计算校验值。&lt;/li&gt;
&lt;li&gt;为广播数据切分成的每个块（称为piece）都生成一个带&amp;quot;piece&amp;quot;的广播ID，调用BlockManager.putBytes()方法将各个块写入MemoryStore（内存）或DiskStore（磁盘）。StorageLevel为MEMORY_AND_DISK_SER，写入的数据会序列化。&lt;/li&gt;
&lt;li&gt;最终返回块的计数值。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;readbroadcastblock&#34;&gt;readBroadcastBlock()
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  private def readBroadcastBlock(): T = Utils.tryOrIOException {
    TorrentBroadcast.torrentBroadcastLock.withLock(broadcastId) {
      // As we only lock based on `broadcastId`, whenever using `broadcastCache`, we should only
      // touch `broadcastId`.
      val broadcastCache = SparkEnv.get.broadcastManager.cachedValues

      Option(broadcastCache.get(broadcastId)).map(_.asInstanceOf[T]).getOrElse {
        setConf(SparkEnv.get.conf)
        val blockManager = SparkEnv.get.blockManager
        blockManager.getLocalValues(broadcastId) match {
          case Some(blockResult) =&amp;gt;
            if (blockResult.data.hasNext) {
              val x = blockResult.data.next().asInstanceOf[T]
              releaseBlockManagerLock(broadcastId)

              if (x != null) {
                broadcastCache.put(broadcastId, x)
              }

              x
            } else {
              throw new SparkException(s&amp;quot;Failed to get locally stored broadcast data: $broadcastId&amp;quot;)
            }
          case None =&amp;gt;
            val estimatedTotalSize = Utils.bytesToString(numBlocks * blockSize)
            logInfo(s&amp;quot;Started reading broadcast variable $id with $numBlocks pieces &amp;quot; +
              s&amp;quot;(estimated total size $estimatedTotalSize)&amp;quot;)
            val startTimeNs = System.nanoTime()
            val blocks = readBlocks()
            logInfo(s&amp;quot;Reading broadcast variable $id took ${Utils.getUsedTimeNs(startTimeNs)}&amp;quot;)

            try {
              val obj = TorrentBroadcast.unBlockifyObject[T](
                blocks.map(_.toInputStream()), SparkEnv.get.serializer, compressionCodec)
              // Store the merged copy in BlockManager so other tasks on this executor don&#39;t
              // need to re-fetch it.
              val storageLevel = StorageLevel.MEMORY_AND_DISK
              if (!blockManager.putSingle(broadcastId, obj, storageLevel, tellMaster = false)) {
                throw new SparkException(s&amp;quot;Failed to store $broadcastId in BlockManager&amp;quot;)
              }

              if (obj != null) {
                broadcastCache.put(broadcastId, obj)
              }

              obj
            } finally {
              blocks.foreach(_.dispose())
            }
        }
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;使用广播id对读取操作加锁，保证线程安全&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;broadcastManager.cacheedValues&lt;/code&gt;,根据广播id检查广播变量是否已在本地缓存中，如果存在，直接返回&lt;/li&gt;
&lt;li&gt;调用setConf()传入配置信息&lt;/li&gt;
&lt;li&gt;尝试从本地blockManager调用&lt;code&gt;getLocalValues&lt;/code&gt;获取指定广播id的数据，如果有就直接读取并缓存&lt;/li&gt;
&lt;li&gt;如果本地blockManager不存在，就调用&lt;code&gt;readBlocks()&lt;/code&gt;方法，从driver和其他executor读取指定广播id对应的piece（片）数据&lt;/li&gt;
&lt;li&gt;从其他节点获取到分块数据后，将其反序列化，重建对象并存储在BlockManager中,并将重建的对象缓存&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;补充readblocks&#34;&gt;补充：readBlocks()
&lt;/h3&gt;&lt;p&gt;readBlocks()是在本地缓存和BlockManager都读取不到数据后，从其他节点读取数据的方法。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  private def readBlocks(): Array[BlockData] = {
    // Fetch chunks of data. Note that all these chunks are stored in the BlockManager and reported
    // to the driver, so other executors can pull these chunks from this executor as well.
    val blocks = new Array[BlockData](numBlocks)
    val bm = SparkEnv.get.blockManager

    for (pid &amp;lt;- Random.shuffle(Seq.range(0, numBlocks))) {
      val pieceId = BroadcastBlockId(id, &amp;quot;piece&amp;quot; + pid)
      logDebug(s&amp;quot;Reading piece $pieceId of $broadcastId&amp;quot;)
      // First try getLocalBytes because there is a chance that previous attempts to fetch the
      // broadcast blocks have already fetched some of the blocks. In that case, some blocks
      // would be available locally (on this executor).
      bm.getLocalBytes(pieceId) match {
        case Some(block) =&amp;gt;
          blocks(pid) = block
          releaseBlockManagerLock(pieceId)
        case None =&amp;gt;
          bm.getRemoteBytes(pieceId) match {
            case Some(b) =&amp;gt;
              if (checksumEnabled) {
                val sum = calcChecksum(b.chunks(0))
                if (sum != checksums(pid)) {
                  throw new SparkException(s&amp;quot;corrupt remote block $pieceId of $broadcastId:&amp;quot; +
                    s&amp;quot; $sum != ${checksums(pid)}&amp;quot;)
                }
              }
              // We found the block from remote executors/driver&#39;s BlockManager, so put the block
              // in this executor&#39;s BlockManager.
              if (!bm.putBytes(pieceId, b, StorageLevel.MEMORY_AND_DISK_SER, tellMaster = true)) {
                throw new SparkException(
                  s&amp;quot;Failed to store $pieceId of $broadcastId in local BlockManager&amp;quot;)
              }
              blocks(pid) = new ByteBufferBlockData(b, true)
            case None =&amp;gt;
              throw new SparkException(s&amp;quot;Failed to get $pieceId of $broadcastId&amp;quot;)
          }
      }
    }
    blocks
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;初始化一个&lt;code&gt;BlockData&lt;/code&gt;数组，长度为广播id对应piece数，获取&lt;code&gt;BlockManager&lt;/code&gt;实例&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;Random.shuffle()&lt;/code&gt;随机顺序遍历每个块的id，确保负载均衡&lt;/li&gt;
&lt;li&gt;如果本地&lt;code&gt;BlockManager&lt;/code&gt;存在块id对应数据块，直接获取并存储&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;这里好像有点冗余，因为readBlocks()本来就是在本地缓存和BlockManager中找不到，才远程访问其他节点时调用的方法。但代码中这么写的原因已在注释中给出:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;First try getLocalBytes because there is a chance that previous attempts to fetch the broadcast blocks have already fetched some of the blocks. In that case, some blocks would be available locally (on this executor).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;首先尝试 getLocalBytes，因为之前获取广播数据块的尝试有可能已经获取了部分数据块。在这种情况下，一些区块将在本地（在此executor上）可用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;如果本地没有，调用&lt;code&gt;blockManager.getRemoteBytes(pieceId)&lt;/code&gt;从远程节点获取。若开启了校验和，则调用&lt;code&gt;calChecksum()&lt;/code&gt;计算校验和并比较，来验证数据完整性&lt;/li&gt;
&lt;li&gt;将从远端获取的数据块存储到本地&lt;code&gt;BlcokManager&lt;/code&gt;中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;获取远端数据封装了很多层，大体读取顺序如下图
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/5.png&#34;
	width=&#34;829&#34;
	height=&#34;573&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/5_hu7419393722578630441.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/5_hu8869478636972443548.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;347px&#34;
	
&gt;
获取远端数据的最后一步，从其他节点读取数据属于BlockManager的部分，下次有机会再读一读&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;广播变量的底层机制总结如下图：
&lt;img src=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/6.png&#34;
	width=&#34;742&#34;
	height=&#34;733&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/6_hu9127105277565457001.png 480w, https://rusthx.github.io/p/spark%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/6_hu14277366887381701722.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;101&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Spark面经</title>
        <link>https://rusthx.github.io/p/spark%E9%9D%A2%E7%BB%8F/</link>
        <pubDate>Sun, 27 Oct 2024 23:18:18 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E9%9D%A2%E7%BB%8F/</guid>
        <description>&lt;h2 id=&#34;saprk定义&#34;&gt;Saprk定义
&lt;/h2&gt;&lt;p&gt;Apache Spark 是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习。&lt;/p&gt;
&lt;!-- 图片居中 --&gt;
&lt;div align=center &gt;
	&lt;img src=&#34;1.png&#34;/&gt;
&lt;/div&gt;
&lt;!-- ![](1.png) --&gt;
## Spark组件
&lt;h2 id=&#34;spark三大抽象数据结构&#34;&gt;Spark三大抽象数据结构
&lt;/h2&gt;&lt;p&gt;RDD:弹性分布式数据集，是 Spark 中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行
计算的集合。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;弹性
&lt;ul&gt;
&lt;li&gt;存储的弹性：内存与磁盘的自动切换；&lt;/li&gt;
&lt;li&gt;容错的弹性：数据丢失可以自动恢复；&lt;/li&gt;
&lt;li&gt;计算的弹性：计算出错重试机制；&lt;/li&gt;
&lt;li&gt;分片的弹性：可根据需要重新分片。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分布式：数据存储在大数据集群不同节点上&lt;/li&gt;
&lt;li&gt;数据集：RDD 封装了计算逻辑，并不保存数据&lt;/li&gt;
&lt;li&gt;数据抽象：RDD 是一个抽象类，需要子类具体实现&lt;/li&gt;
&lt;li&gt;不可变：RDD 封装了计算逻辑，是不可以改变的，想要改变，只能产生新的 RDD，在新的 RDD 里面封装计算逻辑&lt;/li&gt;
&lt;li&gt;可分区、并行计算&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;累加器：累加器用来把 Executor 端变量信息聚合到 Driver 端。在 Driver 程序中定义的变量，在
Executor 端的每个 Task 都会得到这个变量的一份新的副本，每个 task 更新这些副本的值后，
传回 Driver 端进行 merge。&lt;/p&gt;
&lt;p&gt;广播变量：广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个
或多个 Spark 操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，
广播变量用起来都很顺手。在多个并行操作中使用同一个变量，但是 Spark 会为每个任务
分别发送&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package RDD1

import org.apache.spark.util.LongAccumulator
import org.apache.spark.{SparkConf, SparkContext}

object task1 {
  def main(args: Array[String]): Unit = {
    val sparkConf: SparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;job3task1&amp;quot;)
    val sc = new SparkContext(sparkConf)

    //通过文件生成RDD
    val data = sc.textFile(&amp;quot;hdfs://hadoop1:8020/Data01.txt&amp;quot;)

     println(data.map(
      x =&amp;gt; {
        val student = x.split(&amp;quot;,&amp;quot;)(0)
        student
      }
    ).distinct().count())//学生数量
    println(data.map(_.split(&amp;quot;,&amp;quot;)(1)).distinct().count())//课程数量

    val value = data.map(
      x =&amp;gt; {
        val student = x.split(&amp;quot;,&amp;quot;)(0)
        val grade = Integer.parseInt(x.split(&amp;quot;,&amp;quot;)(2))
        (student, grade)
      }).filter(_._1==&amp;quot;Tom&amp;quot;)
      .groupByKey().map{
      y=&amp;gt;{
      y._2.sum/y._2.size.toDouble
    }}
    value.foreach(println) //Tom的课程平均分

    val studentCourse = data.map(
      x=&amp;gt;{
        val student = x.split(&amp;quot;,&amp;quot;)(0)

        (student,1)
      }
    ).groupByKey().mapValues(_.size)
    studentCourse.foreach(println)//学生选课数

    val database = data.map(
      x=&amp;gt;{
        val course = x.split(&amp;quot;,&amp;quot;)(1)
        (course,1)
      }
    ).filter(_._1==&amp;quot;DataBase&amp;quot;).groupByKey().map(y=&amp;gt;y._2.size)
    database.foreach(println)//选择了DataBase课的学生

    val avgGrade = data.map(
      x=&amp;gt;{
        val course = x.split(&amp;quot;,&amp;quot;)(1)
        val grade = Integer.parseInt(x.split(&amp;quot;,&amp;quot;)(2))
        (course,grade)
      }
    ).groupByKey().mapValues(y=&amp;gt;{y.sum/y.size.toDouble})
    avgGrade.foreach(println)//每门课的平均分


    val dbCount:LongAccumulator =  sc.longAccumulator(&amp;quot;dbCount&amp;quot;)
    data.foreach { line =&amp;gt;
      val course = line.split(&amp;quot;,&amp;quot;)(1)
      if (course == &amp;quot;DataBase&amp;quot;) {
        // 每当课程为&amp;quot;DataBase&amp;quot;时，累加器的值加1
        dbCount.add(1)
      }
    }
    println(&amp;quot;DataBase count: &amp;quot; + dbCount.value)
    //累加器实现查找选择了DataBase课的学生

    sc.stop()
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SprakReview

import org.apache.spark.broadcast.Broadcast
import org.apache.spark.{SparkConf, SparkContext}

object BroadCastTry {
  def main(args: Array[String]): Unit = {
    val sparkConf: SparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;广播变量练习&amp;quot;)
    val sc = new SparkContext(sparkConf)

    val v = Array(1,2,3,4,5,6)
    // 创建广播变量
    val broadV:Broadcast[Array[Int]] = sc.broadcast(v)

    //打印广播变量
    println(broadV.value.mkString(&amp;quot;Array(&amp;quot;, &amp;quot;, &amp;quot;, &amp;quot;)&amp;quot;))

    //销毁广播变量
    broadV.destroy()

    sc.stop()
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spark行动算子&#34;&gt;Spark行动算子
&lt;/h2&gt;&lt;div align=center &gt;
	&lt;img src=&#34;2.png&#34;/&gt;
&lt;/div&gt;
&lt;h2 id=&#34;spark转换算子&#34;&gt;Spark转换算子
&lt;/h2&gt;&lt;div align=center &gt;
	&lt;img src=&#34;3.png&#34;/&gt;
&lt;/div&gt;
&lt;h2 id=&#34;map-mappartitions-flatmap-区别&#34;&gt;map mapPartitions flatMap 区别
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;code&gt;map&lt;/code&gt;
将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Return a new RDD by applying a function to all elements of this RDD.
   */
  def map[U: ClassTag](f: T =&amp;gt; U): RDD[U] = withScope {
    val cleanF = sc.clean(f)
    new MapPartitionsRDD[U, T](this, (_, _, iter) =&amp;gt; iter.map(cleanF))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;code&gt;mapPartitions&lt;/code&gt; 将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处
理，哪怕是过滤数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Return a new RDD by applying a function to each partition of this RDD.
   *
   * `preservesPartitioning` indicates whether the input function preserves the partitioner, which
   * should be `false` unless this is a pair RDD and the input function doesn&#39;t modify the keys.
   */
  def mapPartitions[U: ClassTag](
      f: Iterator[T] =&amp;gt; Iterator[U],
      preservesPartitioning: Boolean = false): RDD[U] = withScope {
    val cleanedF = sc.clean(f)
    new MapPartitionsRDD(
      this,
      (_: TaskContext, _: Int, iter: Iterator[T]) =&amp;gt; cleanedF(iter),
      preservesPartitioning)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;map 和 mapPartitions 的区别？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;数据处理角度
Map 算子是分区内一个数据一个数据的执行，类似于串行操作。而 mapPartitions 算子是以分区为单位进行批处理操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;功能的角度
Map 算子主要目的将数据源中的数据进行转换和改变。但是不会减少或增多数据。
MapPartitions 算子需要传递一个迭代器，返回一个迭代器，没有要求的元素的个数保持不变，
所以可以增加或减少数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性能的角度
Map 算子因为类似于串行操作，所以性能比较低，而是 mapPartitions 算子类似于批处理，所以性能较高。但是 mapPartitions 算子会长时间占用内存，那么这样会导致内存可能不够用，出现内存溢出的错误。所以在内存有限的情况下，不推荐使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;code&gt;flatMap&lt;/code&gt;
将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   *  Return a new RDD by first applying a function to all elements of this
   *  RDD, and then flattening the results.
   */
  def flatMap[U: ClassTag](f: T =&amp;gt; TraversableOnce[U]): RDD[U] = withScope {
    val cleanF = sc.clean(f)
    new MapPartitionsRDD[U, T](this, (_, _, iter) =&amp;gt; iter.flatMap(cleanF))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;补充：&lt;code&gt;mapPartitionsWithIndex&lt;/code&gt; 将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处
理，哪怕是过滤数据，在处理时同时可以获取当前分区索引。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Return a new RDD by applying a function to each partition of this RDD, while tracking the index
   * of the original partition.
   *
   * `preservesPartitioning` indicates whether the input function preserves the partitioner, which
   * should be `false` unless this is a pair RDD and the input function doesn&#39;t modify the keys.
   */
  def mapPartitionsWithIndex[U: ClassTag](
      f: (Int, Iterator[T]) =&amp;gt; Iterator[U],
      preservesPartitioning: Boolean = false): RDD[U] = withScope {
    val cleanedF = sc.clean(f)
    new MapPartitionsRDD(
      this,
      (_: TaskContext, index: Int, iter: Iterator[T]) =&amp;gt; cleanedF(index, iter),
      preservesPartitioning)
  }
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Java面经备忘录</title>
        <link>https://rusthx.github.io/p/java%E9%9D%A2%E7%BB%8F%E5%A4%87%E5%BF%98%E5%BD%95/</link>
        <pubDate>Fri, 25 Oct 2024 21:13:16 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/java%E9%9D%A2%E7%BB%8F%E5%A4%87%E5%BF%98%E5%BD%95/</guid>
        <description>&lt;h2 id=&#34;各类型编程语言对比&#34;&gt;各类型编程语言对比
&lt;/h2&gt;&lt;p&gt;面向对象式编程(Java、C++)：面向对象编程，是一种程序设计范式，也是一种编程语言的分类。它以对象作为程序的基本单元，将算法和数据封装其中，程序可以访问和修改对象关联的数据。在面向对象编程中，我们可以操作对象，而不需要关心对象的内部结构和实现。&lt;/p&gt;
&lt;p&gt;面向过程式编程(C)：是一种以过程为中心的编程思想, 分析出解决问题的所需要的步骤,然后用函数把这些步骤一步一步实现,然后依次调用;&lt;/p&gt;
&lt;p&gt;面向函数式编程(scala)：函数式编程（Functional Programming, FP）是一种编程范式，它将计算视为数学中函数的求值过程，并避免使用程序状态及可变数据。在函数式编程中，函数被视为&amp;quot;第一等公民&amp;quot;，这意味着函数可以作为参数传递、作为返回值，甚至可以赋值给变量。函数式编程强调使用一系列的函数来处理数据，而不是依赖于数据的状态变化。&lt;/p&gt;
&lt;h2 id=&#34;封装继承与多态&#34;&gt;封装、继承与多态
&lt;/h2&gt;&lt;h3 id=&#34;封装&#34;&gt;封装
&lt;/h3&gt;&lt;p&gt;概念：
  将一些属性和相关方法封装在一个对象中，对外隐藏内部具体实现细节。内部实现，外界不需要关心，外界只需要根据“内部提供的接口”去使用就可以。&lt;/p&gt;
&lt;p&gt;好处：
使用起来更加方便：因为已经把很多相关的功能，封装成一个整体，类似于像外界提供一个工具箱，针对于不同的场景，使用不同的工具箱就可以；&lt;/p&gt;
&lt;p&gt;保证数据的安全：针对于安全级别高的数据，可以设置成”私有“，可以控制数据为只读（外界无法修改），也可以拦截数据的写操作（进行数据校验和过滤）；&lt;/p&gt;
&lt;p&gt;利于代码维护：如果后期，功能代码需要维护，则直接修改这个类内部代码即可；只要保证接口名称不变，外界不需要做任何代码修改。&lt;/p&gt;
&lt;h3 id=&#34;继承&#34;&gt;继承
&lt;/h3&gt;&lt;p&gt;概念：
  通过必要的说明能够实现某个类无需重新定义就能拥有另一个类的某些属性和方法，这种关系就称为继承，并且允许多层的继承关系。先定义的类称为父类（基类、超类），后定义的类称为子类（派生类）。&lt;/p&gt;
&lt;p&gt;注：Java中只能单继承（一个子类继承一个父类），而Python、C++中则支持多继承&lt;/p&gt;
&lt;h3 id=&#34;多态&#34;&gt;多态
&lt;/h3&gt;&lt;p&gt;多态是指父类的变量可以指向子类对象。允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用）。&lt;/p&gt;
&lt;h2 id=&#34;重写与重载&#34;&gt;重写与重载
&lt;/h2&gt;&lt;p&gt;方法的重写(Overriding)和重载(Overloading)是Java多态性的不同表现。&lt;/p&gt;
&lt;p&gt;重写是父类与子类之间多态性的一种表现，重载是一个类中多态性的一种表现。&lt;/p&gt;
&lt;p&gt;如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写。子类的对象使用这个方法时将调用子类的定义，对它而言，父类中的定义如果被覆盖了。&lt;/p&gt;
&lt;p&gt;如果一个类中定义了多个同名的方法，它们或有不同的参数个数，或有不同的参数类型，则称为方法的重载。重载的方法可以修改返回值的类型。&lt;/p&gt;
&lt;h2 id=&#34;构造方法的特殊之处&#34;&gt;构造方法的特殊之处
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;构造方法必须比类目相同&lt;/li&gt;
&lt;li&gt;构造方法没有返回值，但不用&lt;code&gt;void&lt;/code&gt;声明&lt;/li&gt;
&lt;li&gt;构造方法不能使用&lt;code&gt;static&lt;/code&gt;、&lt;code&gt;final&lt;/code&gt;、&lt;code&gt;abstract&lt;/code&gt;、&lt;code&gt;synchonized&lt;/code&gt;和&lt;code&gt;native&lt;/code&gt;等修饰符&lt;/li&gt;
&lt;li&gt;构造方法不能像一般方法那样用&lt;code&gt;对象.构造方法()&lt;/code&gt;显示地直接调用，应用new关键字调用构造方法，给新对象初始化&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实例方法与类方法&#34;&gt;实例方法与类方法
&lt;/h2&gt;&lt;p&gt; &lt;code&gt;static&lt;/code&gt;修饰地方法称为类方法（或静态方法），而没用static修饰地方法称为是实例方法，二者调用方式不同。
实例方法属于实例，必须通过实例调用；类方法属于类，一般通过类名调用，也可以通过实例调用。二者访问地成员不同。实例方法可以直接访问该类地实例变量和实例方法，也可以访问类变量和类方法；类方法只能访问该类地类变量和类方法，不同直接访问实例变量和实例方法。&lt;/p&gt;
&lt;p&gt;类方法要访问实例变量或调用实例方法，必须首先获得该实例，然后通过该实例访问相关地实例变量或调用实例方法。&lt;/p&gt;
&lt;h2 id=&#34;抽象类与接口&#34;&gt;抽象类与接口
&lt;/h2&gt;&lt;p&gt;相同点：抽象类和接口都可以有抽象方法，都不可以被实例化&lt;/p&gt;
&lt;p&gt;不同点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建类关键字不同：抽象类用关键字&lt;code&gt;abstract&lt;/code&gt;，接口用关键字&lt;code&gt;interface&lt;/code&gt;创建&lt;/li&gt;
&lt;li&gt;成员变量不同：抽象类可以包含普通的变量，接口内的变量只能是&lt;code&gt;final&lt;/code&gt;的&lt;/li&gt;
&lt;li&gt;方法不同：抽象类可以包含普通的方法，接口内只能有抽象的方法，且都是&lt;code&gt;public&lt;/code&gt;的&lt;/li&gt;
&lt;li&gt;继承/实现不同：接口可以被多实现，抽象类只能被单继承&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;java权限修饰符&#34;&gt;Java权限修饰符
&lt;/h2&gt;&lt;p&gt;在Java编程语言中，权限修饰符用于控制类、变量、方法和构造器的访问级别。Java中有四种主要的权限修饰符：public、protected、default（不写）和private。&lt;/p&gt;
&lt;h3 id=&#34;public修饰符&#34;&gt;public修饰符
&lt;/h3&gt;&lt;p&gt;public修饰符提供了最广泛的访问权限，可以应用于类、成员变量、成员方法和构造方法。使用public修饰的元素可以在任何其他类中访问，无论这些类是否在同一个包中，或者甚至在不同的包中。&lt;/p&gt;
&lt;h3 id=&#34;private修饰符&#34;&gt;private修饰符
&lt;/h3&gt;&lt;p&gt;private修饰符是最严格的访问控制级别，只能用于成员变量、成员方法和构造方法，但不能用于修饰类（指外部类，内部类除外）。private修饰的元素只能在其所在的类内部访问。尽管如此，可以通过set和get方法向外界提供访问这些私有成员的方式。&lt;/p&gt;
&lt;h3 id=&#34;default修饰符&#34;&gt;default修饰符
&lt;/h3&gt;&lt;p&gt;default修饰符不需要写出任何关键字，它是当没有指定任何访问修饰符时的默认访问级别。default修饰的元素只能被同一个包中的类访问。&lt;/p&gt;
&lt;h3 id=&#34;protected修饰符&#34;&gt;protected修饰符
&lt;/h3&gt;&lt;p&gt;protected修饰符提供的访问权限介于public和default之间。它可以用于成员变量、成员方法和构造方法，但同样不能用于修饰类（外部类，内部类除外）。protected修饰的元素可以被同一个包中的其他类访问，以及不同包中的子类访问。但是，如果不同包中的类想要访问protected修饰的成员，这个类必须是其子类。&lt;/p&gt;
&lt;h3 id=&#34;使用原则&#34;&gt;使用原则
&lt;/h3&gt;&lt;p&gt;在实际开发中，通常遵循最小权限原则，即尽可能使用最严格的访问级别。属性通常使用private封装起来，方法一般使用public以供调用。如果方法需要被子类继承，通常使用protected。default修饰符使用得较少，通常是新手在不了解修饰符的情况下使用。&lt;/p&gt;
&lt;p&gt;通过以上的访问修饰符，Java允许我们在设计类时对信息进行封装，并控制对于类成员的访问级别，这是实现面向对象编程中封装特性的重要手段。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hive启动参数</title>
        <link>https://rusthx.github.io/p/hive%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0/</link>
        <pubDate>Fri, 25 Oct 2024 21:12:09 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/hive%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0/</guid>
        <description>&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;usage: hive
 -d,--define &amp;lt;key=value&amp;gt;          Variable substitution to apply to Hive
                                  commands. e.g. -d A=B or --define A=B
    --database &amp;lt;databasename&amp;gt;     Specify the database to use
 -e &amp;lt;quoted-query-string&amp;gt;         SQL from command line    (SQL来自命令行)
 -f &amp;lt;filename&amp;gt;                    SQL from files   (SQL来自文件)
 -H,--help                        Print help information
    --hiveconf &amp;lt;property=value&amp;gt;   Use value for given property   (通过命令行参数的方式进行配置信息的设置)
    --hivevar &amp;lt;key=value&amp;gt;         Variable substitution to apply to Hive
                                  commands. e.g. --hivevar A=B
 -i &amp;lt;filename&amp;gt;                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the console)   (详细模式,在控制台输出SQL执行)

&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>数据库死锁</title>
        <link>https://rusthx.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AD%BB%E9%94%81/</link>
        <pubDate>Sun, 13 Oct 2024 21:32:40 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AD%BB%E9%94%81/</guid>
        <description>&lt;h2 id=&#34;定义&#34;&gt;定义
&lt;/h2&gt;&lt;p&gt; 数据库死锁是在多个事务执行过程中发生的一种状态，其中每个事务都在等待其他事务释放它们需要的资源，而这些资源又被其他事务占用。这种相互等待的情况导致事务无法继续执行，因为没有任何事务能够获取它们所需的全部资源来完成操作。&lt;/p&gt;
&lt;h2 id=&#34;死锁死循环四要素&#34;&gt;死锁死循环四要素
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。&lt;/li&gt;
&lt;li&gt;请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。&lt;/li&gt;
&lt;li&gt;不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。&lt;/li&gt;
&lt;li&gt;环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;死锁避免方案&#34;&gt;死锁避免方案
&lt;/h2&gt;&lt;p&gt;数据库管理系统通常会实现死锁检测和解决机制。当检测到死锁时，系统会选择一个事务进行回滚，以解除死锁状态。选择回滚哪个事务通常基于事务的复杂度，系统会尽量选择代价最小的事务进行回滚。&lt;/p&gt;
&lt;p&gt;为了避免死锁，可以采取以下措施：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;保持一致的加锁顺序：确保所有事务都以相同的顺序请求锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少锁的持有时间：尽快完成事务操作并释放锁，避免长时间持有锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用锁超时：设置锁的超时时间，超时后事务自动回滚，释放锁。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;检测死锁并重试：在应用程序中捕获死锁异常，并实现重试机制。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>数仓(Hive)数据倾斜产生原因及处理方式</title>
        <link>https://rusthx.github.io/p/%E6%95%B0%E4%BB%93hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/</link>
        <pubDate>Thu, 19 Sep 2024 08:54:12 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/%E6%95%B0%E4%BB%93hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1TC4y1n7sx/?spm_id_from=333.999.0.0&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;B站@左美美_ 相关视频&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;数据倾斜定义&#34;&gt;数据倾斜定义
&lt;/h2&gt;&lt;p&gt; 任务进度长时间维持在99%，查看任务监异页面，发现只有少量1个或几个reduce子任务未完成。因为其处理的数据量和其他reduce差异过大。单一reduce的记录数与平均记录数差异过大，通常可能达到3倍甚至更多，最长时长远大于平均时长。&lt;/p&gt;
&lt;h2 id=&#34;数据倾斜产生原因&#34;&gt;数据倾斜产生原因
&lt;/h2&gt;&lt;p&gt; map输出数据按keyHash的分配到reduce中，由于key分布不均匀、业务数据本身的特性、建表时考虑不周、某些SQL语句本身就有数据倾斜等原因，造成的reduce上的数据量差异过大，所以如何将数据均匀的分配到各个reduce中，就是解决数据倾斜的根本所在。&lt;/p&gt;
&lt;h3 id=&#34;key为空引起数据倾斜&#34;&gt;Key为空引起数据倾斜
&lt;/h3&gt;&lt;h4 id=&#34;倾斜原因&#34;&gt;倾斜原因
&lt;/h4&gt;&lt;p&gt;join的key值发生倾斜，key值包含很多空值或是异常值。&lt;/p&gt;
&lt;h4 id=&#34;解决方案&#34;&gt;解决方案
&lt;/h4&gt;&lt;p&gt;对值为空的key进行打散，为空key赋一个随机的值，使得key值为空的数据随机均匀地分布到不同的reducer上。&lt;/p&gt;
&lt;h4 id=&#34;测试案例&#34;&gt;测试案例
&lt;/h4&gt;&lt;p&gt;设置多个reduce任务&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set mapreduce.job.reduces = 5;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;两张大表join，做全连接&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;select t.id
       ,t.year
       ,t.temperature
       ,s.state
  from temperature t 
    full join station s on nvl(t.id,rand())=s.id
  limit 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;备注：&lt;code&gt;nvl()&lt;/code&gt;为空值转换函数，&lt;code&gt;rand()&lt;/code&gt;为随机函数。也可以使用&lt;code&gt;ifnull()&lt;/code&gt;、&lt;code&gt;coalesce()&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;group-by-引起数据倾斜&#34;&gt;group by 引起数据倾斜
&lt;/h3&gt;&lt;h4 id=&#34;倾斜原因-1&#34;&gt;倾斜原因
&lt;/h4&gt;&lt;p&gt;默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。&lt;/p&gt;
&lt;h4 id=&#34;解决方案-1&#34;&gt;解决方案
&lt;/h4&gt;&lt;p&gt;并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。
&lt;img src=&#34;https://rusthx.github.io/p/%E6%95%B0%E4%BB%93hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/1.png&#34;
	width=&#34;820&#34;
	height=&#34;371&#34;
	srcset=&#34;https://rusthx.github.io/p/%E6%95%B0%E4%BB%93hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/1_hu16475614890463934495.png 480w, https://rusthx.github.io/p/%E6%95%B0%E4%BB%93hive%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/1_hu11470359486358445655.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;221&#34;
		data-flex-basis=&#34;530px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;实现方式1&lt;/p&gt;
&lt;p&gt;1）是否在Map端进行聚合，默认为True（使用Combiner局部合并）&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set hive.map.aggr = true;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2）设置map端预聚合的行数阈值&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set hive.groupby.mapaggr.checkinterval=100000;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;实现方式2&lt;/p&gt;
&lt;p&gt;有数据倾斜的时候进行负载均衡（默认是false）&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set hive.groupby.skelindata= true;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt; 当遇到数据倾斜时，groupby会启动两个MR job。第一个job会将map端数据随机输入reducer，每个reducer做部分聚合，相同的key就会分布在不同的reducer中。第二个job再将前面预处理过的数据按key聚合并输出结果，这样就起到了均衡的效果。&lt;/p&gt;
&lt;h4 id=&#34;测试案例-1&#34;&gt;测试案例
&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;set hive.map.aggr =true;
set hive.groupby.mapaggr.checkinterval= 100000;
set hive.groupby.skewindata= true;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;select id,count(*)
  from temperature 
  group by id;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;count-distinct引起数据倾斜&#34;&gt;count distinct引起数据倾斜
&lt;/h3&gt;&lt;h4 id=&#34;倾斜原因-2&#34;&gt;倾斜原因
&lt;/h4&gt;&lt;p&gt;count distinct聚合时存在大量特殊值，比如存在大量值为NULL或空的记录。&lt;/p&gt;
&lt;h4 id=&#34;解决方案-2&#34;&gt;解决方案
&lt;/h4&gt;&lt;p&gt;做count distinct时，将值为空的情况单独处理。&lt;/p&gt;
&lt;p&gt;1）如果只是统计去重后的记录数，可以不用处理空值，先把空值过滤掉，然后在最后结果中加1即可&lt;/p&gt;
&lt;p&gt;2）如果还包含其他计算，需要进行groupby操作，先将值为空的记录单独处理，然后再跟其他计算结果union操作。&lt;/p&gt;
&lt;h3 id=&#34;join操作引起数据倾斜&#34;&gt;join操作引起数据倾斜
&lt;/h3&gt;&lt;h4 id=&#34;大表join小表hive旧版本&#34;&gt;大表join小表(hive旧版本)
&lt;/h4&gt;&lt;p&gt;新版本(Hive3)已经自动自动优化&lt;/p&gt;
&lt;p&gt;1）产生原因&lt;/p&gt;
&lt;p&gt;业务数据本身就存在key分布不均匀的情况，一般情况会产生数据倾斜&lt;/p&gt;
&lt;p&gt;2）解决方式&lt;/p&gt;
&lt;p&gt;使用map join让小的维度表先进内存，在map端完成join&lt;/p&gt;
&lt;p&gt;3）实现原理&lt;/p&gt;
&lt;p&gt;使用map join，直接在map端就完成表的join操作，进入map端的数据都是经过split得到的，没有根据key分区这一操作，所以数据都是相对均匀地分布在每个maptask中的，所以就不会产生数据倾斜。&lt;/p&gt;
&lt;h4 id=&#34;大表join大表&#34;&gt;大表join大表
&lt;/h4&gt;&lt;p&gt;1）产生原因&lt;/p&gt;
&lt;p&gt;业务数据本身的特性，导致两个表都是大表。&lt;/p&gt;
&lt;p&gt;2）解决方式&lt;/p&gt;
&lt;p&gt;业务消减&lt;/p&gt;
&lt;p&gt;3）实现原理&lt;/p&gt;
&lt;p&gt; 业务数据有数据倾斜的风险，但是这些导致数据倾斜风险的key一般都是无效的，如uid为空，因为uid为空的记录是没有意义的。&lt;/p&gt;
&lt;p&gt; 所以当业务数据很大，但是数据中的大部分（一般都是80%）可能都是无效数据，那么就可以在join时过滤掉空值uid，没有了这些无效数据，自然就不存在这么大量集中的key，数据倾斜的风险就会消失。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据库实现树状（层级）结构</title>
        <link>https://rusthx.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E7%8E%B0%E6%A0%91%E7%8A%B6%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84/</link>
        <pubDate>Sat, 14 Sep 2024 17:49:28 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E7%8E%B0%E6%A0%91%E7%8A%B6%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84/</guid>
        <description>&lt;h2 id=&#34;问题&#34;&gt;问题
&lt;/h2&gt;&lt;p&gt;有一张交易流水表（transaction），主键为账号，每个账号有所属公司。有一张公司信息表（company_info），主键为公司id，表中有上级公司id。&lt;/p&gt;
&lt;p&gt;需要得到每个公司的交易信息（资金流入流出余额），但是每个公司的数据都应该是该公司及下属公司的汇总。
但是数据库并不支持树形结构也不支持层级结构。&lt;/p&gt;
&lt;h2 id=&#34;方案&#34;&gt;方案
&lt;/h2&gt;&lt;p&gt;主要难题在于公司信息表，公司只有上面一级的信息，没有更上面的信息，也没有下属公司信息。&lt;/p&gt;
&lt;p&gt;所以需要做一张公司树表（company_tree），记录上下关系和层级信息，加工方案如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;设置字段为公司id，公司id树（从最顶层公司到当前公司，类似&#39;0011-0022&amp;rsquo;），公司层级,上级公司id(sup_comp_id)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;插入最顶层公司信息（&amp;lsquo;0011&amp;rsquo;）,设置该公司层级为1级。id树为&#39;0011&amp;rsquo;
然后查询company_info表，插入上级为（&amp;lsquo;0011&amp;rsquo;）的公司信息，设置层级为2级，拼接上级公司id树(&amp;lsquo;0011&amp;rsquo;)和当前公司id作为当前公司的id树。
然后插入三级公司、四级公司，直到最底层公司。不知道到底有多少层可以插入一层后观察company_tree表有无新增数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：三级及更下级的公司需要冗余多行，每行的上级公司id不同（分别为顶级到当前公司的父级公司的公司id）&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;关联company_tree表和transaction,group by sup_comp_id,再对资金流入流出余额进行sum()聚合。
这里加一个按层级的过滤条件，一层一层给地查，然后再union查询结果即可得到所有公司的信息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;观察上面的方案不难发现，这张加工的company_tree不好用，公司信息比较少变（除了股市），一般都是作为数仓的维度表。
但是每次需要关联查询company_tree时写的查询语句都很复杂，那么怎样才能不用union各层公司信息呢？&lt;/p&gt;
&lt;p&gt;设计company_tree的时候再加一个up_comp_tree字段。这样聚合的时候group by up_comp_tree就能拿到所有公司的汇总信息。
（因为公司的下属公司的所有下一级公司的up_comp_tree都是当前公司的id树）&lt;/p&gt;
</description>
        </item>
        <item>
        <title>通过DataX同步数据仓库数据</title>
        <link>https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/</link>
        <pubDate>Sat, 14 Sep 2024 16:58:47 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/</guid>
        <description>&lt;h2 id=&#34;datax介绍&#34;&gt;DataX介绍
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/alibaba/DataX/tree/datax_v202309&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DataX的Github&lt;/a&gt;介绍如下：&lt;/p&gt;
&lt;p&gt;DataX 是阿里云 DataWorks数据集成 的开源版本，在阿里巴巴集团内被广泛使用的离线数据同步工具/平台。DataX 实现了包括 MySQL、Oracle、OceanBase、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、Hologres、DRDS, databend 等各种异构数据源之间高效的数据同步功能。&lt;/p&gt;
&lt;p&gt;DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/1.png&#34;
	width=&#34;1334&#34;
	height=&#34;751&#34;
	srcset=&#34;https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/1_hu16606306282830110616.png 480w, https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/1_hu11140095319987742579.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/2.png&#34;
	width=&#34;1305&#34;
	height=&#34;441&#34;
	srcset=&#34;https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/2_hu9070646682327868429.png 480w, https://rusthx.github.io/p/%E9%80%9A%E8%BF%87datax%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE/2_hu682000736333306540.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;710px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;问题&#34;&gt;问题
&lt;/h2&gt;&lt;p&gt; 数仓开发时需要从异构数据源获取数据作为ODS层（原始数据层），同时还需要在数仓间进行ETL(数据抽取、转换、加载)。通过DataX来实现数据同步。&lt;/p&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现
&lt;/h2&gt;&lt;h3 id=&#34;方案1-shell实现&#34;&gt;方案1 shell实现
&lt;/h3&gt;&lt;p&gt;1.写通过DataX将数据同步到ODS层的配置文件（reader、writter）&lt;/p&gt;
&lt;p&gt;2.通过shell脚本传入传入target_dir(数据库表名，判断是否是需要全量同步的表，若是，则进行全量同步)和datax_config(即步骤1的配置文件)&lt;/p&gt;
&lt;p&gt;3.将数仓间ETL的SQL脚本也封装成shell脚本&lt;/p&gt;
&lt;p&gt;4.通过dolphinscheduler调度步骤2和步骤3的shell脚本实现数据同步到数仓ODS层并在数仓间ETL&lt;/p&gt;
&lt;p&gt;缺点：系统复杂度高，不易维护&lt;/p&gt;
&lt;p&gt;优点：更加灵活，在部分自定义函数功能支持不是很友好的框架（Hive）里也能很好地发挥作用&lt;/p&gt;
&lt;h3 id=&#34;方案2-python实现&#34;&gt;方案2 python实现
&lt;/h3&gt;&lt;p&gt;1.写通过DataX将数据同步到ODS层的配置文件（reader、writter）&lt;/p&gt;
&lt;p&gt;2.将异构数据源配置信息写成文件，然后在python脚本中调用配置信息，拼接成完整的DataX同步命令。&lt;/p&gt;
&lt;p&gt;3.将数仓间ETL的SQL脚本封装成自定义函数，再在步骤2的python脚本中连接数仓执行自定义函数&lt;/p&gt;
&lt;p&gt;4.在服务器上通过&lt;code&gt;contrab&lt;/code&gt;设置定时任务实现自动执行&lt;/p&gt;
&lt;p&gt;缺点：Hive的自定义函数支持不是特别友好，部分功能可能没法实现。通用性差&lt;/p&gt;
&lt;p&gt;优点：系统复杂度低，DataX和python脚本都不用一直在线，定时调度任务开始执行时才会启动python脚本，降低了服务器负担&lt;/p&gt;
&lt;h2 id=&#34;补充datax的增量同步&#34;&gt;补充：DataX的增量同步
&lt;/h2&gt;&lt;p&gt;数仓的增量同步一般都是用消息队列+数据库监听框架+数据同步框架（kafka+Maxwell+Flume）。
但是在离线数仓实时性要求不高的场景下也可以用DataX来实现增量同步。
实现原理：配置文件中reader部分支持column和querySQL,可以在querySQL中加入过滤条件来获取较新的数据。&lt;/p&gt;
&lt;p&gt;比如如果需要获取最新的每日交易数据，就可以加一个时间为最新日期或者传入日期参数的过滤条件。&lt;/p&gt;
&lt;p&gt;如果表中没有时间这种自然增长的字段也可以使用单调递增的id之类的。总之就是获取最新的一批数据就可以。&lt;/p&gt;
&lt;p&gt;然后为了保证数据一致性，还需要在wrritter的preSQL中删除符合reader的querySQL的数据。&lt;/p&gt;
&lt;h2 id=&#34;补充crontab命令&#34;&gt;补充：crontab命令
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：https://cloud.tencent.com/developer/article/2359335&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;（1）语　　法：
crontab [-u &amp;lt;用户名称&amp;gt;][配置文件] 或 crontab { -l | -r | -e }
-u   #&amp;lt;用户名称&amp;gt; 是指设定指定&amp;lt;用户名称&amp;gt;的定时任务，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的定时任务。
-l 　#列出该用户的定时任务设置。
-r 　#删除该用户的定时任务设置。
-e 　#编辑该用户的定时任务设置。

（2）命令时间格式 :
*     * 　  *　  *　  *　　command
分　  时　  日　  月　 周　  命令
第1列表示分钟1～59 每分钟用*或者 */1表示
第2列表示小时1～23（0表示0点）
第3列表示日期1～31
第4列表示月份1～12
第5列标识号星期0～6（0表示星期天）
第6列要运行的命令

（3）一些Crontab定时任务例子：
30 21 * * * /usr/local/etc/rc.d/lighttpd restart  #每晚的21:30 重启apache
45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart  #每月1、10、22日的4 : 45重启apache
10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart  #每周六、周日的1 : 10重启apache
0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart  #每天18 : 00至23 : 00之间每隔30分钟重启apache
0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart  #每星期六的11 : 00 pm重启apache
* 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart  #晚上11点到早上7点之间，每隔一小时重启apache
* */1 * * * /usr/local/etc/rc.d/lighttpd restart  #每一小时重启apache
0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart  #每月的4号与每周一到周三的11点重启apache
0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart  #一月一号的4点重启apache

*/30 * * * * /usr/sbin/ntpdate cn.pool.ntp.org  #每半小时同步一下时间
0 */2 * * * /sbin/service httpd restart  #每两个小时重启一次apache 
50 7 * * * /sbin/service sshd start  #每天7：50开启ssh服务 
50 22 * * * /sbin/service sshd stop  #每天22：50关闭ssh服务 
0 0 1,15 * * fsck /home  #每月1号和15号检查/home 磁盘 
1 * * * * /home/bruce/backup  #每小时的第一分执行 /home/bruce/backup这个文件 
00 03 * * 1-5 find /home &amp;quot;*.xxx&amp;quot; -mtime +4 -exec rm {} \;  #每周一至周五3点钟，在目录/home中，查找文件名为*.xxx的文件，并删除4天前的文件。
30 6 */10 * * ls  #每月的1、11、21、31日是的6：30执行一次ls命令

&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>MySQL Join介绍与优化</title>
        <link>https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/</link>
        <pubDate>Thu, 12 Sep 2024 23:32:36 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/</guid>
        <description>&lt;h2 id=&#34;分类&#34;&gt;分类
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;join&lt;/code&gt;有如下种类&lt;/p&gt;
&lt;p&gt;(inner) join&lt;/p&gt;
&lt;p&gt;left (outer) join&lt;/p&gt;
&lt;p&gt;right (outer) join&lt;/p&gt;
&lt;p&gt;cross join :笛卡尔积，与inner join不指定on等效&lt;/p&gt;
&lt;p&gt;straight_join :效果等同于inner join，只是指定左表为驱动表&lt;/p&gt;
&lt;p&gt;full (outer) join :全外连接，MySQL中不支持。可用left join union right join 实现。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;select t1.*
  from t1 full join t2 
    on t1.id =t2.id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在MySQL中可以用下列方式实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;select t1.*
  from t1 left join t2 
    on t1.id =t2.id
union
select t1.*
  from t1 right join t2 
    on t1.id =t2.id
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;驱动表与被驱动表&#34;&gt;驱动表与被驱动表
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;inner join&lt;/code&gt; :由驱动器决定&lt;/p&gt;
&lt;p&gt;&lt;code&gt;left join&lt;/code&gt; :左表为驱动表，右表为被驱动表&lt;/p&gt;
&lt;p&gt;&lt;code&gt;right join&lt;/code&gt; :左表为驱动表，右表为被驱动表&lt;/p&gt;
&lt;p&gt;&lt;code&gt;straight_join&lt;/code&gt; :固定左表为驱动表，右表为被驱动表&lt;/p&gt;
&lt;h2 id=&#34;join执行流程&#34;&gt;join执行流程
&lt;/h2&gt;&lt;p&gt;每次取驱动表一行数据，去和被驱动表匹配，即双重for循环&lt;/p&gt;
&lt;h2 id=&#34;join执行的实现方式&#34;&gt;join执行的实现方式
&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Nest Loop Join(NLJ)&lt;/code&gt;:单纯的双层循环&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Block Nest Loop Join(BNLJ)&lt;/code&gt;:在NLJ的基础上，利用Join Buffer，一次取出一批驱动表数据，可以减少循环匹配次数&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Index Nest Loop Join(INLJ)&lt;/code&gt;:在NLJ的基础上，利用被驱动表连接字段的索引直接找到匹配数据，可以减少循环次数&lt;/p&gt;
&lt;h2 id=&#34;小表驱动大表&#34;&gt;小表驱动大表
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1ms4y177mr/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1ms4y177mr/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;小表驱动大表是一种常见的SQL优化手段，其原因如下：
 两表关联时会产生一个&lt;code&gt;Join Buffer(关联缓存区)&lt;/code&gt;。&lt;code&gt;Join Buffer&lt;/code&gt;是优化器用于处理连接查询操作时的临时缓冲区，简单来说当需要比较两个或多个表的数据进行Join操作时，&lt;code&gt;JOin Buffer&lt;/code&gt;可以帮助MySQL临时存储结果，以减少磁盘读取和CPU负担，提高查询效率。需要注意的是每个join都有一个单独的缓冲区。&lt;/p&gt;
&lt;p&gt; BNLJ会将驱动表数据加载到Join Buffer里，然后再批量与被驱动表进行匹配，如果驱动表数据流量较大，Join Buffer无法一次性装载驱动表的结果集，将会分阶段与被驱动表进行批量数据匹配，然后记录结果并将结果返回。如果数据量过大，Join Buffer无法一次性加载完成就会分阶段匹配，增大了磁盘读取，降低了效率&lt;/p&gt;
&lt;p&gt;所以总结如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;小表可以被完全加载到内存（Join Buffer）中：
小表的数据量相对较少，可以被完整加载到内存中，减少了磁盘IO的开销。而大表的数据量较大，可能无法完全加载到内存，需要进行磁盘IO操作，会导致性能下降。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少了数据传输量：
将小表作为驱动表可以先获取小表的结果集，再根据小表的结果集进行大表的关联查询。这样可以减少传输到被驱动表的数据量，减少网络传输的开销。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;利用索引优化(INLJ)：
MySQL的查询优化器通常会选择使用索引来优化关联查询。将小表作为驱动表可以更好地利用索引，因为小表的索引更容易被缓存并快速定位。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;join-on&#34;&gt;join on
&lt;/h2&gt;&lt;p&gt;on后跟连接条件，一般必须指定，且只对被驱动表有效，即使对驱动表加了过滤条件，该条件也无效。&lt;/p&gt;
&lt;p&gt;所以，在join on之后，驱动表包含全部数据，被驱动表只包含on条件过滤后的数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：inner join 后的数据只会是下面两个椭圆的交集&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/1.png&#34;
	width=&#34;348&#34;
	height=&#34;221&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/1_hu17217040643776161663.png 480w, https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/1_hu12072442993451356462.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;on和where&#34;&gt;on和where
&lt;/h2&gt;&lt;p&gt;on 在join时就会过滤数据，而where是join完成后再对数据进行过滤，所以on比where先作用。&lt;/p&gt;
&lt;p&gt;所以，理论上过滤条件放在on后比放在where后性能更好，因为这样可以有更少的数据进入&lt;code&gt;磁盘IO&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;但是，由于on后的条件只对被驱动表有效，过滤条件放在on后和where后的结果可能会不一致，所以谨慎在on后加驱动表的过滤条件。&lt;/p&gt;
&lt;p&gt;对于inner join，on和where就没有区别了&lt;/p&gt;
&lt;h2 id=&#34;多表关联查询优化&#34;&gt;多表关联查询优化
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;加过滤条件要想清楚，先对被驱动表过滤还是join完后再一起过滤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;尽量小表驱动大表，这是针对left join和right join的情况，inner join会由优化器自行选择&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;explain分析SQL语句得到的执行计划的第一行即是驱动表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化join思路：一切为了减少join 时驱动表匹配被驱动表时的循环次数。如果join后的数据量很大，并且还要进行聚合操作，在不影响查询结果的情况下可以考虑先聚合出临时表再进行join&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少单表数据量，如水平分表、垂直分表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;静态的数据可以在后端进行缓存&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;补充分表设计&#34;&gt;补充：分表设计
&lt;/h2&gt;&lt;p&gt;分表原理：一个大表按照一定的规则分解成多张具有独立存储空间的实体表。这些表可以分布在同一块磁盘上，也可以在不同的磁盘上。&lt;/p&gt;
&lt;p&gt;通过分表实现用户在访问数据时，因不同的条件而访问不同的表，将数据分散在各个实体表中，减少单表的访问压力，提升数据查询效率&lt;/p&gt;
&lt;h3 id=&#34;水平分表&#34;&gt;水平分表
&lt;/h3&gt;&lt;p&gt; 以字段为依据，按照一定的策略，使用hash、range、list等方式将一个表的数据拆分成多个相同结构的表中。
水平分表是为了降低单表的数据量，解决单表的热点问题。&lt;/p&gt;
&lt;p&gt; 比如按时间特性进行划分，将表数据分成历年数据表或者历史数据表（已完成）+在线数据表（正在进行）。
水平分表后的表通过union能还原回原来的表。
&lt;img src=&#34;https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/2.png&#34;
	width=&#34;691&#34;
	height=&#34;481&#34;
	srcset=&#34;https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/2_hu10095678336687076858.png 480w, https://rusthx.github.io/p/mysql-join%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BC%98%E5%8C%96/2_hu18269138479022757295.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;垂直分表&#34;&gt;垂直分表
&lt;/h3&gt;&lt;p&gt; 根据字段查询频率将表中数据拆分为不同结构的表（主表和扩展表）。
例如将热点数据和非热点数据分块存储，这样在查询热点数据时就能将数据缓存起来，减少了随机读取&lt;code&gt;IO&lt;/code&gt;，提高了命中率。
适用于由于字段较多引起数据量和访问量较大的情况，且每个业务场景只访问部分字段。&lt;/p&gt;
&lt;p&gt; 例如：用户对商品感兴趣才会查看详细描述，而详细描述占用存储较多（Text）,可以将该字段垂直分割
垂直分表后的表通过join可以还原回原来的表&lt;/p&gt;
&lt;p&gt;垂直分表的优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不同的业务场景访问不同的内容，数据量小，提升性能&lt;/li&gt;
&lt;li&gt;集成中数据传输量小&lt;/li&gt;
&lt;li&gt;不同业务场景业务量访问频率不一样，表的操作更新可以更加灵活地控制&lt;/li&gt;
&lt;li&gt;降低业务耦合度&lt;/li&gt;
&lt;li&gt;垂直分割可使行数据变小，一个数据块就能存更多数据，在查询时可以有效减少&lt;code&gt;IO&lt;/code&gt;次数。垂直分表可以有效利用Cache&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;分区分表对比&#34;&gt;分区分表对比
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;定义：分区是在一张表中，根据某种规则将数据分散到不同的物理存储区域。分表则是将一张大表拆分成多张小表。&lt;/li&gt;
&lt;li&gt;数据访问：在分区中，用户无需知道数据在哪个分区，可以像访问普通的表一样访问数据，但在分表中，用户必须先知道数据在哪张表中才能访问到所需数据&lt;/li&gt;
&lt;li&gt;适用场景：分区适用于数据量大，但查询范围有限的场景，而分表适用于数据量大，查询范围广的场景。&lt;/li&gt;
&lt;li&gt;性能：分区可以提高查询性能，因为查询只需要在一个分区内进行（过滤条件使用了分区字段），而不是在整张表中。分表可以提高整体性能，因为每个表的数据量都变少了&lt;/li&gt;
&lt;li&gt;管理：分区可以减少数据的恢复。分表可以使每个表的大小更容易得到控制&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;广播表与分布式表&#34;&gt;广播表与分布式表
&lt;/h2&gt;&lt;p&gt;广播表：小表广播功能能提高跨库场景的性能和简化跨库场景的开发。
将需要广播的数据推送到目标库，冗余了表数据，方便在库内关联查询。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create table config(
    id int primary key,
    config_key varchar(255),
    config_value varchar(255)
)broadcast;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分布式表：分布式表是指其数据根据某种分片策略在分布式数据库系统的不同节点上。
数据被分成多个分段，每个分段存储在不同的节点上。
分布式表的分布策略可以基于hash、range、list等方式。
分布式表适用于数据量大且需要水平扩展的场景.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create table users(
    user_id int primary key,
    uname varchar(255),
    email varchar(255)
)distributed by hash(user_id);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;反范式&#34;&gt;反范式
&lt;/h2&gt;&lt;p&gt;属性冗余：在一个表中除了存储关联表的主键外，将关联表的非键字段也存储到此表的处理方式。
有点像垂直分表的反向操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(user_id check_date score),(user_id user_name telephone)
-&amp;gt;
(user_id check_date score user_name telephone)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;级联属性冗余：多表关联时，A关联B,B关联C。在查询时需要同时获取A、B、C三个表的属性或以它们的属性进行条件过滤
，为了减少表关联以提高性能，可以考虑在B表中冗余需要访问的C表字段，减少频繁的表关联操作。&lt;/p&gt;
&lt;p&gt;例如：在员工表中冗余部门表的信息（部门id 部门名称 部门负责人）&lt;/p&gt;
&lt;p&gt;表冗余：针对数据记录进行冗余，即A表的数据复制多份，或者多表关联的结果数据存储成一张表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直接复制：“广播表模式”，可以提高跨库访问的性能&lt;/li&gt;
&lt;li&gt;加工派生：冗余的数据是源表加工后的数据或多表关联的结果&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>MySQL 索引</title>
        <link>https://rusthx.github.io/p/mysql-%E7%B4%A2%E5%BC%95/</link>
        <pubDate>Thu, 12 Sep 2024 23:05:47 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/mysql-%E7%B4%A2%E5%BC%95/</guid>
        <description>&lt;p&gt;我写的这篇博客只是我学习的一点总结，并不系统，也不全面。想要学习较为全面的知识可以看 &lt;a class=&#34;link&#34; href=&#34;https://xiaolincoding.com/mysql/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;小林coding的图解MySQL&lt;/a&gt;相关部分&lt;/p&gt;
&lt;h2 id=&#34;密集列索引&#34;&gt;密集列索引
&lt;/h2&gt;&lt;p&gt;密集列，是指一张表上列的数据没有离散度，列的取值范围较小，高度集中在少数几个值中（如性别）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一般来说，密集列由于没有离散度，不适合作为索引列。使用这类密集索引的实际效率可能会低于全表扫描。但是，假如密集列的倾斜度很高时，例如有一个状态列表示是否停用，大部分对象都为停用，那么就可用使用密集列作为索引&lt;/li&gt;
&lt;li&gt;需要保证要查询的数据分布较少，（低于总数据量的5%）。同时还要确定是否有为这一个查询单独优化的需要，因为索引也会占用空间，建太多索引反而会降低查询效率，甚至会出现加了索引，查询效率反而变慢的情况。优化并不是将每个查询都单独优化到1s内，而是衡量损失后在妥协中得到一个平衡，让慢查询只占很少比例，优先保证查询次数多的语句。&lt;/li&gt;
&lt;li&gt;可能会频繁变更的列不宜作为索引列，因为索引列变更会导致索引重排，也即是B+树的树结构变更。这会导致修改效率大幅下降&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;索引合并index_merge&#34;&gt;索引合并(index_merge)
&lt;/h2&gt;&lt;p&gt;当数据过滤条件分布在多个索引列上时（无论是&lt;code&gt;and&lt;/code&gt;还是&lt;code&gt;or&lt;/code&gt;），MySQL为了提升数据访问效率会使用多个索引合并的方式过滤数据。、&lt;/p&gt;
&lt;p&gt;索引合并会导致单个索引过滤的数据量越大，查询效率下降越明显&lt;/p&gt;
&lt;h2 id=&#34;锁&#34;&gt;锁
&lt;/h2&gt;&lt;p&gt;MySQL的行锁是通过对索引加锁来实现的。数据修改时会根据过滤条件匹配对应的索引，在对应的索引上加锁。如果语句中修改了索引的值，就还会在修改后的值上加锁。其他事务使用相同的索引值修改数据不管是否是相同的行均会被阻塞。&lt;/p&gt;
&lt;p&gt;多线程下应该使用主键来修改数据降低阻塞的概率。&lt;/p&gt;
&lt;p&gt;如果&lt;code&gt;update/delete&lt;/code&gt;的where条件没有使用索引或者没有where条件，就会全表扫描，会对所有记录加上next-key锁（&lt;code&gt;record锁+gap锁&lt;/code&gt;）,相当于把整张表锁住了&lt;/p&gt;
</description>
        </item>
        <item>
        <title>MySQL删除修改数据优化</title>
        <link>https://rusthx.github.io/p/mysql%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96/</link>
        <pubDate>Thu, 12 Sep 2024 22:15:33 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/mysql%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96/</guid>
        <description>&lt;h2 id=&#34;删除&#34;&gt;删除
&lt;/h2&gt;&lt;h3 id=&#34;删除未在他表出现的数据&#34;&gt;删除未在他表出现的数据
&lt;/h3&gt;&lt;p&gt;下面有一条效率较差的删除语句，主要功能是将t1表中id未出现在t2表的记录删除。效率差的原因是in中用了子查询，导致删除语句不会走索引，从而导致锁全表，继而导致删除效率差。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;delete from t1 
  where id not in 
  (
    select id from t2
  )

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;优化方法:取消子查询，改用关联删除，这样就可以使用建在id列上的索引。关联删除/更新在建立索引的情况下效率远高于&lt;code&gt;in/exists&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;优化后的SQL语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;delete t1 
  from t1 left join t2 on t1.id=t2.id
  where t2.id is null
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注：上面这条是MySQL独有的优化，达梦数据库和Oracle中可用如下语句。（拾人牙慧，未经验证，用这两个数据库的朋友可以自行验证一下）&lt;code&gt;(+)&lt;/code&gt;表示单侧关联，该符号在哪边哪边就是副表。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQl&#34;&gt;delete from t1
  where rowid in(
    select t1.rowid 
      from t1,t2
      where t2.id(+)=t1.id and t2.id is null
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;删除多表相同数据&#34;&gt;删除多表相同数据
&lt;/h3&gt;&lt;p&gt;好的删除语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQl&#34;&gt;delete t1,t2
  from t1,t2
  where t1.id=t2.id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样可以同时删除从主从表删除。比如一条记录记录在多张表中，删除这条记录需要同时删除两张表的记录。这样可以保证要么全部删除，要么全部不删，间接满足了事务一致性。（数据库只会从一个状态转移至另外一个状态，即拥有这条记录和没有这条记录的两个状态。这一条记录可以看成是一个入库记录、一张支票）&lt;/p&gt;
&lt;h3 id=&#34;删除全表数据&#34;&gt;删除全表数据
&lt;/h3&gt;&lt;p&gt;用truncate替代delete。这里涉及delete的机制，delete并不是直接在磁盘中删除记录，而是将记录加一个标记，并设置为不可见，然后在数据库压力小时异步删除磁盘中的数据。但是这样有一个问题，虽然标记为删除后，查询表记录不可见。但是记录仍然占有着磁盘空间，这会拖慢查询数据库的速度。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;truncate table t1;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;更新&#34;&gt;更新
&lt;/h2&gt;&lt;p&gt;差的更新语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;update t1
  set c1=&#39;&#39;
  where id in (...)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如删除篇中所说，由于in中属性过多，in不会再走索引（当属性值大于4个后就不会再走索引，in中是子查询的话就不会走索引）。所以这里的更新效率慢，并且还会锁住整表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于为什么全表扫描会锁住整张表可以看小林的教程：&lt;a class=&#34;link&#34; href=&#34;https://xiaolincoding.com/mysql/lock/update_index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;update 没加索引会锁全表？&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;优化方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建id临时表，临时表只有id一个字段&lt;/li&gt;
&lt;li&gt;批量插入临时表，记录为上面差的更新语句中的记录，也即是需要更新的记录的id&lt;/li&gt;
&lt;li&gt;将临时表于原表关联更新&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;补充插入更新&#34;&gt;补充：插入更新
&lt;/h2&gt;&lt;p&gt;插入一条数据，如果存在主键或唯一键冲突，则更新记录&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：使用此语句时，必须在表中定义主键或唯一约束&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;insert into [table_name] (column1,column2,column3...)
  values (values1,values2,values3...)
  on duplicate key update
  column1 = values(column1),
  column2 = values(column2),...

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;insert into users (id,`name`)
  values (1,&#39;Alice&#39;)
  on duplicate key update
  name = values(`name`)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PostgreSQL中用法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;insert into users (id,`name`)
  values (1,&#39;Alice&#39;)
  on conflicate (id) do 
  update set name = excluded.name
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果想同时修改多个字段也可用下面的写法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;insert into users (id,`name`，age)
  values (1,&#39;Alice&#39;,18)
  on conflicate (id) do 
  update set (`name`,age) = excluded.(`name`,age)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果想遇见冲突主键不做处理可用如下语句&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;insert into users (id,`name`)
  values (1,&#39;Alice&#39;)
  on conflicate (id) do 
  nothing
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Java随机交换(洗牌)</title>
        <link>https://rusthx.github.io/p/java%E9%9A%8F%E6%9C%BA%E4%BA%A4%E6%8D%A2%E6%B4%97%E7%89%8C/</link>
        <pubDate>Wed, 11 Sep 2024 14:43:00 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/java%E9%9A%8F%E6%9C%BA%E4%BA%A4%E6%8D%A2%E6%B4%97%E7%89%8C/</guid>
        <description>&lt;h2 id=&#34;题目&#34;&gt;题目
&lt;/h2&gt;&lt;p&gt;给定一个整数数组，进行随机交换，要求交换后的数组中每个元素都不在其原来的位置上&lt;/p&gt;
&lt;h2 id=&#34;思路&#34;&gt;思路
&lt;/h2&gt;&lt;p&gt;1.遍历数组，随机一个不为当前下标的下标，将两个位置的元素交换位置&lt;/p&gt;
&lt;p&gt;2.可能会出现某个元素交换多次后又回到原位置的情况，所有需要再遍历一遍数组，如果出现此情况就将交换过的数组再递归交换，直到没有这种情况&lt;/p&gt;
&lt;h2 id=&#34;答案&#34;&gt;答案
&lt;/h2&gt;&lt;p&gt;注意：数组在交换前需要先拷贝一份，这样才能验证每个元素是否在原位置上&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-Java&#34;&gt;    public static int[] randomSwap(int[] nums){
        int[] arr = nums.clone();
        Random random = new Random();
        for (int i = 0; i &amp;lt; nums.length; i++) {
            int j=i;
            while(j==i){
                j=random.nextInt(nums.length-1);
            }
            int temp =arr[j];
            arr[j]=arr[i];
            arr[i]=temp;
        }
        for (int i = 0; i &amp;lt; nums.length; i++) {
            if (arr[i] == nums[i]) {
                return randomSwap(nums);
            }
        }
        return arr;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;import random

def derange_array(array):
    n = len(array)
    result = array[:]
    
    for i in range(n):
        j = i
        while j == i:
            j = random.randint(0, n - 1)
        # 交换元素
        result[i], result[j] = result[j], result[i]
    
    # 确保没有元素在其原来的位置上
    for i in range(n):
        if result[i] == array[i]:
            return derange_array(array)  # 如果有元素在原来位置上就递归交换
    
    return result

# 验证测试
array = [1, 2, 3, 4, 5]
result = derange_array(array)
print(result)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-Scala&#34;&gt;import scala.util.Random

object Derangement {
  def main(args: Array[String]): Unit = {
    val array = Array(1, 2, 3, 4, 5)
    val result = derangeArray(array)
    println(result.mkString(&amp;quot;, &amp;quot;))
  }

  def derangeArray(array: Array[Int]): Array[Int] = {
    val n = array.length
    val result = array.clone()
    val rand = new Random()

    for (i &amp;lt;- 0 until n) {
      var j = i
      while (j == i) {
        j = rand.nextInt(n)
      }
      // 交换元素
      val temp = result(i)
      result(i) = result(j)
      result(j) = temp
    }

    // 确保没有元素在其原来的位置上
    for (i &amp;lt;- 0 until n) {
      if (result(i) == array(i)) {
        return derangeArray(array) // 如果有元素在原来位置上就递归交换
      }
    }

    result
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>SQL计算时间交集</title>
        <link>https://rusthx.github.io/p/sql%E8%AE%A1%E7%AE%97%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86/</link>
        <pubDate>Sun, 08 Sep 2024 10:15:20 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/sql%E8%AE%A1%E7%AE%97%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考资料：《SQL进阶》P106 (鹿书)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;关系表结构&#34;&gt;关系（表）结构
&lt;/h2&gt;&lt;p&gt;现有一张住宿表(&lt;code&gt;stay_people&lt;/code&gt;)如下&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;guest(入住客人)&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;start_date(入住时间)&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;end_date(退房时间)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;阿良良木历&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-26&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-27&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;阿良良木月火&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-28&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-31&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;阿良良木火怜&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-31&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-11-01&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;忍野忍&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-29&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-11-01&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;忍野扇&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-28&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-11-02&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;战场原黑仪&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-28&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-30&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;千石抚子&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-10-30&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2006-11-02&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;问题：判断这些客人住店时间存在重叠，如果存在重叠，则展示客人的名字、入住时间和退房时间&lt;/p&gt;
&lt;h2 id=&#34;问题分析&#34;&gt;问题分析
&lt;/h2&gt;&lt;p&gt;很明显这道题的重点是判断两个时间段是否相交，那么时间相交有如下三种情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/sql%E8%AE%A1%E7%AE%97%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86/1.png&#34;
	width=&#34;721&#34;
	height=&#34;497&#34;
	srcset=&#34;https://rusthx.github.io/p/sql%E8%AE%A1%E7%AE%97%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86/1_hu17515716768174378448.png 480w, https://rusthx.github.io/p/sql%E8%AE%A1%E7%AE%97%E6%97%B6%E9%97%B4%E4%BA%A4%E9%9B%86/1_hu11644942538632735057.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;答案&#34;&gt;答案
&lt;/h2&gt;&lt;p&gt;1.自关联然后判断是否为三种情况之一，如果符合一种，那么时间相交&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select t1.guest
       ,t1.start_date
       ,t2.start_date
  from stay_people t1,stay_people t2
  where (t1.start_date&amp;lt;=t2.end_date and t1.start_date&amp;gt;=t2.start_date)
        or (t1.end_date&amp;gt;=t2.start_date and t1.start_date&amp;lt;=t2.start_date)
        or (t1.start_date&amp;gt;=t2.start_date and t1.end_date&amp;lt;=t2.end_date)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2.比较自关联后一行的最小的end_date和最大的start_date来判断两个时间段是否相交。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select t1.guest
       ,t1.start_date
       ,t2.start_date
  from stay_people t1,stay_people t2
  where greatest(t1.start_date,t2.start_date)&amp;lt;=least(t1.end_date,t2.end_date)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3 使用数据库的内置函数判断时间段是否相交&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select t1.guest
       ,t1.start_date
       ,t2.start_date
  from stay_people t1,stay_people t2
  where (t1.start_date,t1.end_date) overlaps (t2.start_date,t2.end_date)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是，这种判断默认的时间段是左闭右开的，即认为住宿时间为&lt;code&gt;[start_date,end_date)&lt;/code&gt;,并且这个函数只有SQL Server、PostgreSQL、Oracle支持，MySQL并不支持这种写法。未列举的数据库不一定不支持，可以查一下相关文档&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://www.postgres.cn/docs/9.3/functions-datetime.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PostgreSQL时间函数文档&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我写的只是三种类型的处理方法，除了我的写法，还有许多别的写法，我只是做一个简单总结&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Kubernetes（K8s）Pod部署</title>
        <link>https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/</link>
        <pubDate>Sat, 07 Sep 2024 12:50:40 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/</guid>
        <description>&lt;p&gt;这里以老师的指导文档为例，实现一个基于flask和redis的web网页，用户每输入网址浏览一次就加一次浏览量并显示在网页上。&lt;/p&gt;
&lt;h2 id=&#34;docker拉取镜像&#34;&gt;Docker拉取镜像
&lt;/h2&gt;&lt;p&gt;拉取Python镜像&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker pull python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/1.png&#34;
	width=&#34;692&#34;
	height=&#34;344&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/1_hu17224850590113109081.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/1_hu15208621949751305477.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;482px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;拉取redis镜像&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker pull redis
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/2.png&#34;
	width=&#34;692&#34;
	height=&#34;286&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/2_hu9224429356178765712.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/2_hu6767615337067811911.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;580px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;查看镜像&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker images
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/3.png&#34;
	width=&#34;692&#34;
	height=&#34;92&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/3_hu6709404302406711039.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/3_hu8687149729500338510.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;752&#34;
		data-flex-basis=&#34;1805px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;编辑所需文件&#34;&gt;编辑所需文件
&lt;/h2&gt;&lt;p&gt;编辑Python程序，实现一个基于flask的web应用，在redis中存一个数值，初值为0，每访问一次网站，计数加1。
代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
import redis
from flask import Flask

app = Flask(__name__)
cache = redis.Redis(host=&#39;127.0.0.1&#39;, port=6379)


def get_hit_count():
    retries = 5
while True:
    try:
        return cache.incr(&#39;hits&#39;)
except redis.exceptions.ConnectionError as exc:
if retries == 0:
    raise exc
retries -= 1
time.sleep(0.5)


@app.route(&#39;/&#39;)
def hello():
    count = get_hit_count()
return &#39;Hello rust! Hello hx! I have been seen {} times.\n&#39;.format(count)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/4.png&#34;
	width=&#34;692&#34;
	height=&#34;458&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/4_hu16207471149684100048.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/4_hu12052938835273320261.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;362px&#34;
	
&gt;
编写dockerfile&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-dockerfile&#34;&gt;FROM python:latest
WORKDIR /code
ENV FLASK_APP hxapp.py
ENV FLASK_RUN_HOST 0.0.0.0
RUN pip install redis flask -i https://mirror.baidu.com/pypi/simple
COPY hxapp.py hxapp.py
EXPOSE 5000
CMD [&amp;quot;flask&amp;quot;,&amp;quot;run&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/5.png&#34;
	width=&#34;693&#34;
	height=&#34;278&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/5_hu7681217620921068937.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/5_hu14004743042782580699.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;249&#34;
		data-flex-basis=&#34;598px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;豆瓣源下redis和flask会报错如下，根据Windows下载这两个包的经验，猜测应该是镜像源的问题，换成百度源，解决问题。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/6.png&#34;
	width=&#34;692&#34;
	height=&#34;140&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/6_hu5411144568993752425.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/6_hu4379847252476198197.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;494&#34;
		data-flex-basis=&#34;1186px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;生成新的镜像&#34;&gt;生成新的镜像
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker build -t onccn/myflask:v2 -f ./dockerfile .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/7.png&#34;
	width=&#34;692&#34;
	height=&#34;282&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/7_hu5912724497788295465.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/7_hu9583242097064753180.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;588px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/8.png&#34;
	width=&#34;692&#34;
	height=&#34;105&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/8_hu17360230486091296248.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/8_hu7582679619456201950.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;659&#34;
		data-flex-basis=&#34;1581px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从kubernetes拉取docker本地镜像
编辑flaskredisdeploy.yaml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: flaskredis
spec:
  selector:
    matchLabels:
      app: flaskredis
  template:
    metadata:
      labels:
        app: flaskredis
    spec:
      containers:
      - name: flaskredis
        image: onccn/myflask:v2
        imagePullPolicy: Never
        resources:
          limits:
            memory: &amp;quot;1500Mi&amp;quot;
            cpu: &amp;quot;1000m&amp;quot;
      - name: redis
        image: redis:latest
        imagePullPolicy: Never
        resources:
          limits:
            memory: &amp;quot;500Mi&amp;quot;
            cpu: &amp;quot;500m&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/9.png&#34;
	width=&#34;692&#34;
	height=&#34;392&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/9_hu14383955263462350083.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/9_hu17025110178141396458.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl apply -f flaskredisdeploy.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/10.png&#34;
	width=&#34;692&#34;
	height=&#34;255&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/10_hu5098089526256298034.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/10_hu5465120606443743012.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;271&#34;
		data-flex-basis=&#34;651px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;访问web和windows访问&#34;&gt;访问Web和Windows访问
&lt;/h2&gt;&lt;p&gt;虚拟器中浏览器输入上面查看日志得到的链接
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/11.png&#34;
	width=&#34;692&#34;
	height=&#34;534&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/11_hu13490876160934854608.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/11_hu6728508559744647383.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;编辑service.yaml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;gedit myflaskservice.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Service
metadata:
  name: myflaskservice
spec:
  selector:
    app: flaskredis
  ports:
    - protocol: TCP
      port: 8080   #Service的端口号
      targetPort: 5000 #容器暴露的真实端口号
      nodePort: 30081  #node的真实端口号
  type: NodePort

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/12.png&#34;
	width=&#34;692&#34;
	height=&#34;549&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/12_hu2051749534844109783.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/12_hu5751389474008024197.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;302px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;创建service&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl apply -f myflaskservice.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;遇见报错,这个报错的意思是该端口已经被占用，修改端口号
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/13.png&#34;
	width=&#34;692&#34;
	height=&#34;46&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/13_hu15141129520309466701.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/13_hu3747531981868506793.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1504&#34;
		data-flex-basis=&#34;3610px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/14.png&#34;
	width=&#34;693&#34;
	height=&#34;504&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/14_hu4333105231732906338.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/14_hu5895843929917376880.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;330px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;成功创建service,查看service&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl get svc -o wide
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/15.png&#34;
	width=&#34;692&#34;
	height=&#34;179&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/15_hu3938549974556256663.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/15_hu4075962535945262445.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;386&#34;
		data-flex-basis=&#34;927px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Windows访问k8s集群的service，进而访问相应的pod
ip地址为node的地址（k8s集群中应用service的节点）
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/16.png&#34;
	width=&#34;691&#34;
	height=&#34;390&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/16_hu10257806483227558820.png 480w, https://rusthx.github.io/p/kubernetesk8spod%E9%83%A8%E7%BD%B2/16_hu16836289900823866095.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Kubernetes(K8s)使用本地Docker镜像</title>
        <link>https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/</link>
        <pubDate>Sat, 07 Sep 2024 12:48:13 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=3mdCiFu52XA&amp;amp;t=8s&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=3mdCiFu52XA&amp;amp;t=8s&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;vscode安装k8s插件&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/1.png&#34;
	width=&#34;1326&#34;
	height=&#34;561&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/1_hu17254079545382046222.png 480w, https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/1_hu465123155462970852.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;236&#34;
		data-flex-basis=&#34;567px&#34;
	
&gt;
值得一提的是安装k8s插件后编辑k8s所需yaml文件会非常简单。比如需要一个deploy，那只需要输入deploy再按一下TAB键就可以使用自动补全，得到一份模板代码。同时这个插件还能检查k8s语法，比如container是否限制资源。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/2.png&#34;
	width=&#34;816&#34;
	height=&#34;476&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/2_hu11413131759954440195.png 480w, https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/2_hu12545210145465346645.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;411px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;在yaml文件中加入参数&lt;code&gt;imagePullPolicy: Never&lt;/code&gt;，这个参数的意思是禁用docker注册表和docker hub，从本地的docker拉取镜像。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/3.png&#34;
	width=&#34;910&#34;
	height=&#34;785&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/3_hu17779761024865858577.png 480w, https://rusthx.github.io/p/kubernetesk8s%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F/3_hu9184074557727702588.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;115&#34;
		data-flex-basis=&#34;278px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Kubernetes（K8s）集群安装</title>
        <link>https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</link>
        <pubDate>Sat, 07 Sep 2024 12:35:29 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考资料:&lt;a class=&#34;link&#34; href=&#34;https://cloud.tencent.com/developer/article/2347138&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cloud.tencent.com/developer/article/2347138&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;禁用ubuntu-swap&#34;&gt;禁用Ubuntu Swap
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo gedit /etc/fatab
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/1.png&#34;
	width=&#34;692&#34;
	height=&#34;260&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/1_hu960321138255286551.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/1_hu13096675886114765677.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;266&#34;
		data-flex-basis=&#34;638px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ubuntu安装网桥工具&#34;&gt;Ubuntu安装网桥工具
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install bridge-utils -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/2.png&#34;
	width=&#34;542&#34;
	height=&#34;210&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/2_hu4363660471933497727.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/2_hu1379285999777841885.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;258&#34;
		data-flex-basis=&#34;619px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;添加k8s镜像源&#34;&gt;添加k8s镜像源
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 
sudo add-apt-repository &amp;quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&amp;quot;

sudo curl -fsSL https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;配置containerd&#34;&gt;配置containerd
&lt;/h3&gt;&lt;p&gt;这里需要安装containerd，但是我在docker安装的时候已经装好了，相关命令为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（1）Containerd安装完成后，其自带的配置文件/etc/containerd/config.toml中的内容，需要用打印出的containerd默认配置替换。
（2）Containerd的Cgroup设为systemd，以和k8s默认的Cgroup保持一致。
（3）pause镜像路径改为国内源registry.aliyuncs.com/google_containers/pause:3.9。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo cp /etc/containerd/config.toml /etc/containerd/config.toml.ori

sudo chmod 777 /etc/containerd/config.toml

sudo containerd config default &amp;gt; /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/3.png&#34;
	width=&#34;692&#34;
	height=&#34;110&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/3_hu5948125076381310860.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/3_hu12071304055539246676.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;629&#34;
		data-flex-basis=&#34;1509px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo gedit /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/4.png&#34;
	width=&#34;693&#34;
	height=&#34;422&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/4_hu4342215343925311415.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/4_hu10284808613042401377.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;164&#34;
		data-flex-basis=&#34;394px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/5.png&#34;
	width=&#34;692&#34;
	height=&#34;620&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/5_hu11986231435685122992.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/5_hu10475957572216008991.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;111&#34;
		data-flex-basis=&#34;267px&#34;
	
&gt;
配置后，重启containerd服务，并保证containerd状态正确&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo systemctl restart containerd.service
sudo systemctl status containerd.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/6.png&#34;
	width=&#34;692&#34;
	height=&#34;240&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/6_hu10178921285458368139.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/6_hu1283971055959109204.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;288&#34;
		data-flex-basis=&#34;692px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装kubernetes&#34;&gt;安装Kubernetes
&lt;/h3&gt;&lt;p&gt;安装k8s软件，这里会默认下载最新的kubernetes（阿里云镜像源上的），后面指定版本时需要根据自己的版本进行修改。这里也可以手动指定kubernetes版本。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt install kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/7.png&#34;
	width=&#34;681&#34;
	height=&#34;309&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/7_hu133096450219194195.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/7_hu943012349230082445.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;528px&#34;
	
&gt;
此时k8s没有启动成功是正常的，因为kubelet服务成功启动的先决条件，需要kubelet的配置文件，所在目录/var/lib/kubelet还没有建立。&lt;/p&gt;
&lt;h3 id=&#34;k8s配置单机节点&#34;&gt;k8s配置单机节点
&lt;/h3&gt;&lt;p&gt;查看k8s版本&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubeadm config images list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/8.png&#34;
	width=&#34;692&#34;
	height=&#34;155&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/8_hu16011733915408332467.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/8_hu11774022554876676733.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;446&#34;
		data-flex-basis=&#34;1071px&#34;
	
&gt;
将kubernetes的控制面的几个镜像拉到本地，为了保证镜像和安装的k8s软件版本严格一致，这里的镜像拉取时，显性指定版本。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo kubeadm config images pull --kubernetes-version v1.28.10 --image-repository registry.aliyuncs.com/google_containers
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/9.png&#34;
	width=&#34;692&#34;
	height=&#34;126&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/9_hu17903787922349183279.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/9_hu2508715440186311029.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;549&#34;
		data-flex-basis=&#34;1318px&#34;
	
&gt;
kubernetes初始化
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/10.png&#34;
	width=&#34;507&#34;
	height=&#34;334&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/10_hu7421036121421247490.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/10_hu16235620790240800738.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;364px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo kubeadm init --control-plane-endpoint=192.168.146.111 --kubernetes-version v1.28.10 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/11.png&#34;
	width=&#34;691&#34;
	height=&#34;311&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/11_hu16605176183490767431.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/11_hu18240599072829478421.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;533px&#34;
	
&gt;
初始化成功如下图
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/12.png&#34;
	width=&#34;692&#34;
	height=&#34;386&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/12_hu16838431105869466247.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/12_hu6364867492287816270.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;克隆虚拟机作为从节点&#34;&gt;克隆虚拟机作为从节点
&lt;/h3&gt;&lt;p&gt;关闭虚拟机，克隆虚拟机作为从节点。
右键虚拟机，克隆虚拟机。选择当前状态，创建完整克隆，完成克隆。
克隆完成后修改从节点的hosts、hostname和ip。
为了便于管理，修改主节点的hosts为k8s1,从节点分别取名k8s2和k8s3。对应ip指定为192.168.146.112和192.168.146.113。（这里的ip和host要根据自己的情况进行修改，主节点的名字也可以通过修改hotsname来改变）
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/13.png&#34;
	width=&#34;692&#34;
	height=&#34;534&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/13_hu14189279694118436634.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/13_hu9913160935703706050.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/14.png&#34;
	width=&#34;608&#34;
	height=&#34;156&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/14_hu321734123107274844.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/14_hu9585166996908139743.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;389&#34;
		data-flex-basis=&#34;935px&#34;
	
&gt;
创建hosts映射。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/15.png&#34;
	width=&#34;510&#34;
	height=&#34;340&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/15_hu12810204235265587781.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/15_hu13611371464930010137.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;配置kubernetes集群&#34;&gt;配置Kubernetes集群
&lt;/h3&gt;&lt;p&gt;在主节点上跟着初始化成功后的提示继续后续工作&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/16.png&#34;
	width=&#34;693&#34;
	height=&#34;75&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/16_hu18369258952975439918.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/16_hu2228434490561084348.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;924&#34;
		data-flex-basis=&#34;2217px&#34;
	
&gt;
查看集群状态&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl cluster-info
kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/17.png&#34;
	width=&#34;692&#34;
	height=&#34;144&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/17_hu13183444003692171499.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/17_hu8659039121958339604.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;480&#34;
		data-flex-basis=&#34;1153px&#34;
	
&gt;
在k8s1上创建永久token&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubeadm token create --print-join-command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/18.png&#34;
	width=&#34;683&#34;
	height=&#34;102&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/18_hu15068319352070513315.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/18_hu3237205269493155798.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;669&#34;
		data-flex-basis=&#34;1607px&#34;
	
&gt;
如果在克隆虚拟机作为从节点之前就已经跟着k8s提示完成了上面几步，那么在从节点上执行提示的join命令，会遇见报错。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/19.png&#34;
	width=&#34;693&#34;
	height=&#34;316&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/19_hu14009124978563814946.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/19_hu6623220064737110740.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;526px&#34;
	
&gt;
原因：拷贝虚拟机时已完成k8s集群配置文件创建，应该在初始化后，配置文件创建前进行克隆。
解决办法：在虚拟机重置节点后加入集群。这个重置节点的命令也可以在后续k8s出现问题时恢复默认设置重做时使用。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo rm -rf /etc/kubernetes/kubelet.conf /etc/kubernetes/pki/ca.crt
sudo kubeadm reset
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/20.png&#34;
	width=&#34;692&#34;
	height=&#34;446&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/20_hu8412896920310934657.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/20_hu2418707555263233963.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;372px&#34;
	
&gt;
重新加入集群（join命令为主节点创建永久token时回显的命令）
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/21.png&#34;
	width=&#34;693&#34;
	height=&#34;471&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/21_hu17139227368995327261.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/21_hu15603479485285512845.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;353px&#34;
	
&gt;
在k8s3上进行相同步骤。
在k8s1上查看集群节点，集群搭建成功。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/22.png&#34;
	width=&#34;485&#34;
	height=&#34;132&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/22_hu368952748449532977.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/22_hu1220343681401226332.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;367&#34;
		data-flex-basis=&#34;881px&#34;
	
&gt;
细心的读者可能发现了我的1号机之前交VirtualClass，但是现在却叫k8s1，这是因为我在1号机初始化之前没有修改一号机的名字，导致集群建立后节点名字如下，但是这个看着不太舒服，我就把三台机都使用上面的重置命令重置后再重做了一遍上述步骤。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/23.png&#34;
	width=&#34;553&#34;
	height=&#34;129&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/23_hu55150491114112732.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/23_hu6990032150254370507.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;428&#34;
		data-flex-basis=&#34;1028px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;配置kubernetes网络插件calico&#34;&gt;配置Kubernetes网络插件Calico
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl https://projectcalico.docs.tigera.io/manifests/calico.yaml -O
kubectl apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;成功截图如下（我这里因为网络问题没有成功，姑且偷一张图），如果失败可以使用另外一种手动方法如下（我的办法）。
&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/24.png&#34;
	width=&#34;874&#34;
	height=&#34;547&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/24_hu3070271793074078642.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/24_hu1289070989174613719.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;
手动解决办法：
打开链接(可能需要借助某些上网工具)
&lt;a class=&#34;link&#34; href=&#34;https://projectcalico.docs.tigera.io/manifests/calico.yaml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://projectcalico.docs.tigera.io/manifests/calico.yaml&lt;/a&gt;
全选复制，粘贴到&lt;code&gt;~/calico.yaml&lt;/code&gt;
重新执行&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/25.png&#34;
	width=&#34;692&#34;
	height=&#34;482&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/25_hu15229060625230529289.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/25_hu13953004651531133457.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;
成功截图，这里要看见所有的pod状态都为Running才是成功，如果是ContainerCreating则表明正在制作容器，需要稍等一会（可能会很慢，但也不会超过十分钟）。如果过了很久还没Running，可以通过&lt;code&gt;kubectl describe pods &amp;lt;pod-name&amp;gt; -n kube-system&lt;/code&gt; 查看pod进度。 -n的意思是指定命名空间（namespace），默认的pod命名空间是default，所以使用&lt;code&gt;kubectl get pods&lt;/code&gt;会得到defalut下的pods。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl get pods -n kube-system
kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/26.png&#34;
	width=&#34;692&#34;
	height=&#34;485&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/26_hu11831354582053368319.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/26_hu379460734182305715.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;342px&#34;
	
&gt;
k8s命名空间查看，更多命令及参数可以通过&lt;code&gt;kubectl --help&lt;/code&gt;查看&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl get namespace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/27.png&#34;
	width=&#34;325&#34;
	height=&#34;203&#34;
	srcset=&#34;https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/27_hu7219520315083393518.png 480w, https://rusthx.github.io/p/kubernetesk8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/27_hu1706513173492984095.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Docker安装与基本操作</title>
        <link>https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</link>
        <pubDate>Sat, 07 Sep 2024 12:27:13 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</guid>
        <description>&lt;p&gt;我的docker是安装在Ubuntu22.04虚拟机上的，不同的操作系统细微差别，请自行必应搜索。&lt;/p&gt;
&lt;h2 id=&#34;docker安装&#34;&gt;Docker安装
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;更新apt数据源&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/1.png&#34;
	width=&#34;389&#34;
	height=&#34;23&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/1_hu425725312286712068.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/1_hu4291545464884543959.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1691&#34;
		data-flex-basis=&#34;4059px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;下载依赖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install  apt-transport-https  ca-certificates  curl  gnupg-agent     software-properties-common -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/2.png&#34;
	width=&#34;692&#34;
	height=&#34;96&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/2_hu10673934334995286129.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/2_hu4219430154631582924.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;720&#34;
		data-flex-basis=&#34;1730px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;添加Docker的官方GPG密钥&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从这里开始可以选择docker官方的密钥和仓库，也可以选择国内镜像（阿里云）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# 阿里云密钥
curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/3.png&#34;
	width=&#34;692&#34;
	height=&#34;122&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/3_hu17898359711786520562.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/3_hu886681935071170072.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;567&#34;
		data-flex-basis=&#34;1361px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;设置稳定仓库&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo add-apt-repository  &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu  $(lsb_release -cs)  stable&amp;quot;

# 阿里云仓库
sudo add-apt-repository  &amp;quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu  $(lsb_release -cs)  stable&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/4.png&#34;
	width=&#34;692&#34;
	height=&#34;233&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/4_hu14511445311029983206.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/4_hu12382934142844553162.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;712px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;安装docker&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/5.png&#34;
	width=&#34;693&#34;
	height=&#34;169&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/5_hu15152051979590742588.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/5_hu16611656839906662909.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;410&#34;
		data-flex-basis=&#34;984px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;添加docker用户组，将登陆用户加入到docker用户组中，更新用户组&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo groupadd docker
sudo gpasswd -a $USER docker
newgrp docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/6.png&#34;
	width=&#34;495&#34;
	height=&#34;153&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/6_hu14317173853516641762.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/6_hu13349515511261993022.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;776px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;docker测试&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt; sudo docker run hello-world
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/7.png&#34;
	width=&#34;692&#34;
	height=&#34;337&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/7_hu11017709187321121399.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/7_hu17038669967287080759.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;205&#34;
		data-flex-basis=&#34;492px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;配置加速镜像和Cgroup，后面再docker使用过程中遇见了拉取镜像缓慢的问题，于是我又多加了几个镜像源。不过事后想想，可能是那几天校园网太卡的问题&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo gedit /etc/docker/daemon.json
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://registry.docker-cn.com&amp;quot;,
    &amp;quot;http://hub-mirror.c.163.com&amp;quot;,
    &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,
    &amp;quot;https://kfwkfulq.mirror.aliyuncs.com&amp;quot;
  ],
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;],
  &amp;quot;log-driver&amp;quot;: &amp;quot;json-file&amp;quot;,
  &amp;quot;log-opts&amp;quot;: {
    &amp;quot;max-size&amp;quot;: &amp;quot;100m&amp;quot;
  },
  &amp;quot;storage-driver&amp;quot;: &amp;quot;overlay2&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/8.png&#34;
	width=&#34;692&#34;
	height=&#34;272&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/8_hu17928817988609409487.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/8_hu11456323896780144434.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;610px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;docker简单使用&#34;&gt;Docker简单使用
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;拉取nginx和tomcat的镜像&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker pull nginx
sudo docker pull tomee
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/9.png&#34;
	width=&#34;692&#34;
	height=&#34;545&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/9_hu16394361241044064654.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/9_hu17563668103609443718.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;304px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker network create testnet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/10.png&#34;
	width=&#34;667&#34;
	height=&#34;209&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/10_hu4205689229213762903.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/10_hu3530470621172221698.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;319&#34;
		data-flex-basis=&#34;765px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;启动 两个tomcat&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;创建两个目录，分别挂载到tomcat的跟目录上，内容可以调整，主要区分是哪个服务上的文件。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd ~
sudo mkdir tomcatone
echo &amp;quot;tomcat onet&amp;quot; &amp;gt; index.html
sudo mkdir tomcattwo
sudo cp index.html tomcatone/
echo &amp;quot;tomcat two&amp;quot; &amp;gt; index.html
sudo cp index.html tomcattwo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/11.png&#34;
	width=&#34;492&#34;
	height=&#34;73&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/11_hu5400655431153457201.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/11_hu17841913676930410570.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;673&#34;
		data-flex-basis=&#34;1617px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/12.png&#34;
	width=&#34;487&#34;
	height=&#34;76&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/12_hu1041478500326628263.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/12_hu12619417905837852860.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;640&#34;
		data-flex-basis=&#34;1537px&#34;
	
&gt;
运行容器&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker run -id --name tomcatone -p 8088:8080 --network testnet --network-alias tomcatone  -v    $PWD/tomcatone:/usr/local/tomee/webapps/a  tomee
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/13.png&#34;
	width=&#34;693&#34;
	height=&#34;102&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/13_hu17925473049801938811.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/13_hu8286832613981995074.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;679&#34;
		data-flex-basis=&#34;1630px&#34;
	
&gt;
查看网页显示如下
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/14.png&#34;
	width=&#34;551&#34;
	height=&#34;207&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/14_hu15599884068257417395.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/14_hu14111170243493055945.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;266&#34;
		data-flex-basis=&#34;638px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/15.png&#34;
	width=&#34;565&#34;
	height=&#34;213&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/15_hu15474901154570787651.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/15_hu8194151677560036054.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;265&#34;
		data-flex-basis=&#34;636px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;启动nginx，命令使用两次&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker run -it -d -p 8080:80 --name web -v ~/nginx:/etc/nginx/conf.d -v ~/nginxweb:/usr/share/nginx/html --network testnet --network-alias nginxs nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/16.png&#34;
	width=&#34;692&#34;
	height=&#34;95&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/16_hu5137126053147675804.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/16_hu1373987954554245603.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;728&#34;
		data-flex-basis=&#34;1748px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/17.png&#34;
	width=&#34;692&#34;
	height=&#34;98&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/17_hu16942578295596291992.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/17_hu4326285681270193923.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;706&#34;
		data-flex-basis=&#34;1694px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/18.png&#34;
	width=&#34;692&#34;
	height=&#34;196&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/18_hu15546986035579076224.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/18_hu17960052005797732032.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;353&#34;
		data-flex-basis=&#34;847px&#34;
	
&gt;
刷新后网页显示如下
&lt;img src=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/19.png&#34;
	width=&#34;692&#34;
	height=&#34;250&#34;
	srcset=&#34;https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/19_hu2449090012888787070.png 480w, https://rusthx.github.io/p/docker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/19_hu6723265067796360096.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;276&#34;
		data-flex-basis=&#34;664px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>SparkStreaming使用socket</title>
        <link>https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/</link>
        <pubDate>Sat, 07 Sep 2024 11:55:09 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV11A411L7CK?p=188&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV11A411L7CK?p=188&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;终端打印大量日志影响结果查看可以看我首页的博客解决。
踩坑如下：
1.socket编程不会，写socket发送数据查了很多资料才写出来
2.Windows没有netcat命令，但是MACOS和Ubuntu有,所以理所当然的想到用虚拟机的端口来收集数据和输入数据，事实上这个想法确实没有问题，分别做的话是能正常实现的，但是这也为后续的错误埋下了大坑。想当然的把socket当成kafka用（producer和consumer），是我踩坑的一大原因。
3.被教程误导，socket发送数据到端口，但是不知道socket有服务器和客户端之分，发送数据和处理数据的都是客户端，导致发送端可以和nc -lk &lt;Port&gt;结合使用，能正常监听到数据；接收端也能和nc -lk &lt;Port&gt;结合使用，在监听的端口出输入数据可以正常计算；但是两者结合就没办法计算了&lt;/p&gt;
&lt;h2 id=&#34;windows安装netcat&#34;&gt;Windows安装netcat
&lt;/h2&gt;&lt;p&gt;下载链接： &lt;a class=&#34;link&#34; href=&#34;https://nmap.org/download.html#windows&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://nmap.org/download.html#windows&lt;/a&gt;
下载的是一个exe包，点击exe包一路next即可完成安装。&lt;/p&gt;
&lt;p&gt;端口同时接收数据和计算数据时使用命令监听会无法访问，即启动socket数据发送程序和SparkStreaming数据计算程序后无法监听。但是监听命令可以用来分别调试两个程序。&lt;/p&gt;
&lt;p&gt;注意：Windows的netcat命令与Ubuntu和MacOS都不一样。Windows的命令是 &lt;code&gt;ncat -lk &amp;lt;Port&amp;gt;&lt;/code&gt;，参数的意思可以通过&lt;code&gt;ncat -h&lt;/code&gt;查看。
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1.png&#34;
	width=&#34;960&#34;
	height=&#34;634&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1_hu3612333662547381058.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1_hu16466038784867921191.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;363px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2.png&#34;
	width=&#34;1481&#34;
	height=&#34;760&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2_hu3790405143218445351.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2_hu11535289130947449563.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;sparkstreaming-socket编程&#34;&gt;SparkStreaming socket编程
&lt;/h2&gt;&lt;p&gt;题目：1）写一个应用程序利用套接字每隔2秒生成20条大学主页用户访问日志（可以自定义内容），数据形式如下：“系统时间戳，位置城市，用户ID+姓名，访问大学主页”。其中城市自定义 9个，用户ID 10个，大学主页 7个。
2）写第二个程序每隔2秒不断获取套接字产生的数据，并将词频统计结果打印出来。
导入依赖&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spark-streaming_2.12&amp;lt;/artifactId&amp;gt;
   &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SparkStreaming1

import java.io.{BufferedWriter, IOException, OutputStreamWriter}
import java.net.ServerSocket
import scala.util.Random

object task11 {
  def main(args: Array[String]): Unit = {

    // 定义城市和用户ID
    val cities = Seq(&amp;quot;杭州&amp;quot;, &amp;quot;南京&amp;quot;, &amp;quot;长沙&amp;quot;, &amp;quot;天津&amp;quot;, &amp;quot;北京&amp;quot;, &amp;quot;上海&amp;quot;, &amp;quot;成都&amp;quot;, &amp;quot;广州&amp;quot;, &amp;quot;深圳&amp;quot;)
    val userIds = Seq(&amp;quot;0:阿良良木历&amp;quot;, &amp;quot;1:忍野忍&amp;quot;, &amp;quot;2:战场原黑仪&amp;quot;, &amp;quot;3:羽川翼&amp;quot;, &amp;quot;4:八九寺真宵&amp;quot;,
      &amp;quot;5:神原骏河&amp;quot;, &amp;quot;6:千石抚子&amp;quot;, &amp;quot;7:阿良良木火怜&amp;quot;, &amp;quot;8:阿良良木月火&amp;quot;, &amp;quot;9:姬丝秀忒·雅赛劳拉莉昂·刃下心&amp;quot;)
    val universityUrls = Seq(&amp;quot;www.nju.edu.cn&amp;quot;, &amp;quot;www.ustc.edu.cn&amp;quot;,
      &amp;quot;www.zju.edu.cn&amp;quot;, &amp;quot;www.fudan.edu.cn&amp;quot;, &amp;quot;www.tsinghua.edu.cn&amp;quot;, &amp;quot;www.pku.edu.cn&amp;quot;, &amp;quot;www.scu.edu.cn&amp;quot;)

    try {
      // 创建一个 socket 连接
//      val socket = new Socket(&amp;quot;hadoop3&amp;quot;, 9765)
      val socketServer = new ServerSocket(9765)
      val client = socketServer.accept()
      println(&amp;quot;连接！&amp;quot;)
      val out = new BufferedWriter(new OutputStreamWriter(client.getOutputStream))
//val in = new BufferedReader(new InputStreamReader(client.getInputStream))
      while (true){
        for (_ &amp;lt;- 1 to 20) {
          // 发送多条数据
          val currentTime = System.currentTimeMillis()
          val city = cities(Random.nextInt(cities.length))
          val userId = userIds(Random.nextInt(userIds.length))
          val universityUrl = universityUrls(Random.nextInt(universityUrls.length))
          val logLine = s&amp;quot;$currentTime $city $userId $universityUrl&amp;quot;

          out.write(logLine + &amp;quot;\n&amp;quot;) // 添加换行符以区分消息
          out.flush() // 确保数据被发送出去
          println(logLine)
        }
        Thread.sleep(2000) // 休眠2秒，模拟连续发送
      }

      // 关闭 socket
      out.close()
//      socket.close()
      client.close()
    } catch {
      case e: IOException =&amp;gt;
        e.printStackTrace()
    }

  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SparkStreaming1

import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession
import org.apache.spark.streaming.{Seconds, StreamingContext}


object task12{
  def main(args: Array[String]): Unit = {
    val sparkConf: SparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;job7task12&amp;quot;)
    val spark = SparkSession.builder().config(sparkConf).getOrCreate()
    val ssc = new StreamingContext(spark.sparkContext, Seconds(2))

    // 从套接字获取数据流
    val lines = ssc.socketTextStream(&amp;quot;localhost&amp;quot;, 9765)
    
    lines.map(_.split(&amp;quot; &amp;quot;)(2))
      .map((_, 1))
      .reduceByKey(_ + _)
      .print()
    
    ssc.start()

    ssc.awaitTermination()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启动时需要先启动数据计算程序，再启动数据发送程序。
成功运行截图：
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3.png&#34;
	width=&#34;692&#34;
	height=&#34;371&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3_hu4369904911137244949.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3_hu4522820763415712476.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Scala连接MySQL和Hive</title>
        <link>https://rusthx.github.io/p/scala%E8%BF%9E%E6%8E%A5mysql%E5%92%8Chive/</link>
        <pubDate>Sat, 07 Sep 2024 11:47:55 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/scala%E8%BF%9E%E6%8E%A5mysql%E5%92%8Chive/</guid>
        <description>&lt;h2 id=&#34;连接mysql&#34;&gt;连接MySQL
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考链接：&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/Jaryer/p/13671449.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/Jaryer/p/13671449.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;maven添加依赖&#34;&gt;maven添加依赖
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.mysql&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;mysql-connector-j&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;8.0.33&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;连接数据库&#34;&gt;连接数据库
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val host = &amp;quot;localhost&amp;quot;
val port = 3306
val database = &amp;quot;sparktest&amp;quot;
val jdbcUrl = s&amp;quot;jdbc:mysql://$host:$port/$database?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;quot;
val mysqlConn: Connection = DriverManager.getConnection(jdbcUrl, &amp;quot;root&amp;quot;, &amp;quot;123456&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;执行查询&#34;&gt;执行查询
&lt;/h3&gt;&lt;p&gt;SQL语句在执行时有三种：&lt;code&gt;executeQuery&lt;/code&gt;,&lt;code&gt;executeUpdate&lt;/code&gt;,&lt;code&gt;execute&lt;/code&gt;。具体细节可查看此节开头的参考资料。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;    val statement: Statement = mysqlConn.createStatement()
    //插入数据
    statement.executeUpdate(&amp;quot;insert into employee values (3,&#39;Mary&#39;,&#39;F&#39;,26)&amp;quot;)
    statement.executeUpdate(&amp;quot;insert into employee values (4,&#39;Tom&#39;,&#39;M&#39;,23)&amp;quot;)

    val result: ResultSet = statement.executeQuery(&amp;quot;select max(age) as max_age,avg(age) as avg_age from employee&amp;quot;)
    while (result.next()) {
      println(result.getString(&amp;quot;max_age&amp;quot;),result.getString(&amp;quot;avg_age&amp;quot;))
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;完整代码&#34;&gt;完整代码
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package sparkjob5

import java.sql.{Connection, DriverManager, ResultSet, Statement}

object task3 {
  def main(args: Array[String]): Unit = {
    //连接mysql
    val host = &amp;quot;localhost&amp;quot;
    val port = 3306
    val database = &amp;quot;sparktest&amp;quot;
    val jdbcUrl = s&amp;quot;jdbc:mysql://$host:$port/$database?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;quot;
    val mysqlConn: Connection = DriverManager.getConnection(jdbcUrl, &amp;quot;root&amp;quot;, &amp;quot;123456&amp;quot;)

    val statement: Statement = mysqlConn.createStatement()
    //插入数据
    statement.executeUpdate(&amp;quot;insert into employee values (3,&#39;Mary&#39;,&#39;F&#39;,26)&amp;quot;)
    statement.executeUpdate(&amp;quot;insert into employee values (4,&#39;Tom&#39;,&#39;M&#39;,23)&amp;quot;)

    val result: ResultSet = statement.executeQuery(&amp;quot;select max(age) as max_age,avg(age) as avg_age from employee&amp;quot;)
    while (result.next()) {
      println(result.getString(&amp;quot;max_age&amp;quot;),result.getString(&amp;quot;avg_age&amp;quot;))
    }

    result.close()
    statement.close()
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;连接hive&#34;&gt;连接Hive
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考链接：&lt;a class=&#34;link&#34; href=&#34;https://www.jianshu.com/p/27a798013990&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.jianshu.com/p/27a798013990&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;连接Hive前需要开启Hive的metastore和hiverserver2。开启命令如下。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开启Hadoop集群&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;start-all.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;开启Hive,第二三行的启动命令需要分别开一个终端启动，输出的日志在&lt;code&gt;/usr/local/hive/logs&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /usr/local/hive
hive --service metastore &amp;gt;logs/metastore.log 2&amp;gt;&amp;amp;1
hive --service hiveserver2 &amp;gt;logs/hiveServer2.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;添加依赖&#34;&gt;添加依赖
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spark-hive_2.12&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.3.4&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;hive-jdbc&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.1.3&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;完整依赖如下（包含了Scala连接MySQL的依赖）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot;
         xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
         xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;artifactId&amp;gt;Spark&amp;lt;/artifactId&amp;gt;
        &amp;lt;groupId&amp;gt;org.example&amp;lt;/groupId&amp;gt;
        &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;/parent&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;

    &amp;lt;artifactId&amp;gt;sparkCore&amp;lt;/artifactId&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spark-core_2.12&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spark-sql_2.12&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.mysql&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mysql-connector-j&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;8.0.33&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spark-hive_2.12&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.3.4&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;hive-jdbc&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.1.3&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

    &amp;lt;/dependencies&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;maven.compiler.source&amp;gt;17&amp;lt;/maven.compiler.source&amp;gt;
        &amp;lt;maven.compiler.target&amp;gt;17&amp;lt;/maven.compiler.target&amp;gt;
        &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
    &amp;lt;/properties&amp;gt;
    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;!-- 该插件用于将 Scala 代码编译成 class 文件 --&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;net.alchim31.maven&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;scala-maven-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;3.2.2&amp;lt;/version&amp;gt;
                &amp;lt;executions&amp;gt;
                    &amp;lt;execution&amp;gt;
                        &amp;lt;!-- 声明绑定到 maven 的 compile 阶段 --&amp;gt;
                        &amp;lt;goals&amp;gt;
                            &amp;lt;goal&amp;gt;testCompile&amp;lt;/goal&amp;gt;
                        &amp;lt;/goals&amp;gt;
                    &amp;lt;/execution&amp;gt;
                &amp;lt;/executions&amp;gt;
            &amp;lt;/plugin&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;3.1.0&amp;lt;/version&amp;gt;
                &amp;lt;configuration&amp;gt;
                    &amp;lt;descriptorRefs&amp;gt;
                        &amp;lt;descriptorRef&amp;gt;jar-with-dependencies&amp;lt;/descriptorRef&amp;gt;
                    &amp;lt;/descriptorRefs&amp;gt;
                &amp;lt;/configuration&amp;gt;
                &amp;lt;executions&amp;gt;
                    &amp;lt;execution&amp;gt;
                        &amp;lt;id&amp;gt;make-assembly&amp;lt;/id&amp;gt;
                        &amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
                        &amp;lt;goals&amp;gt;
                            &amp;lt;goal&amp;gt;single&amp;lt;/goal&amp;gt;
                        &amp;lt;/goals&amp;gt;
                    &amp;lt;/execution&amp;gt;
                &amp;lt;/executions&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;修改配置文件hive-sitexml&#34;&gt;修改配置文件hive-site.xml
&lt;/h3&gt;&lt;p&gt;在resource下新建一个&lt;code&gt;hive-site.xml&lt;/code&gt;，填入下列内容。注意：要把&lt;code&gt;hadoop1&lt;/code&gt;修改成自己的Hadoop集群主节点名字或者ip。
&lt;img src=&#34;https://rusthx.github.io/p/scala%E8%BF%9E%E6%8E%A5mysql%E5%92%8Chive/1.png&#34;
	width=&#34;1261&#34;
	height=&#34;798&#34;
	srcset=&#34;https://rusthx.github.io/p/scala%E8%BF%9E%E6%8E%A5mysql%E5%92%8Chive/1_hu6304836396205212170.png 480w, https://rusthx.github.io/p/scala%E8%BF%9E%E6%8E%A5mysql%E5%92%8Chive/1_hu6195403910822788867.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;379px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;

&amp;lt;configuration&amp;gt;
    &amp;lt;!-- 添加文件调用 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.exec.scratchdir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://hadoop1:8020/user/hive/tmp&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://hadoop1:8020/user/hive/warehouse&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.querylog.location&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://hadoop1:8020/user/hive/log&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 指定存储元数据要连接的地址 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;thrift://hadoop1:9083&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- jdbc连接的URL --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;jdbc:mysql://hadoop1:3306/metastore?useUnicode=true&amp;amp;amp;characterEncodeing=UTF-8&amp;amp;amp;allowPublicKeyRetrieval=true&amp;amp;amp;useSSL=false&amp;amp;amp;serverTimezone=GMT&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- jdbc连接的Driver--&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- jdbc连接的username--&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hive&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- jdbc连接的password --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;123456&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;


    &amp;lt;!-- 指定hiveserver2连接的host --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.server2.thrift.bind.host&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 指定hiveserver2连接的端口号 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.server2.thrift.port&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;10000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- hiveserver2的高可用参数，开启此参数可以提高hiveserver2的启动速度 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.server2.active.passive.ha.enable&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;scala代码&#34;&gt;Scala代码
&lt;/h3&gt;&lt;p&gt;在&lt;code&gt;spark.sql()&lt;/code&gt;里写上正常的SQL语句即可完成查询。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package sparkjob5


import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession


object task4 {
  val driverName = &amp;quot;org.apache.hive.jdbc.HiveDriver&amp;quot;
  try {
    Class.forName(driverName)
  } catch {
    case e: ClassNotFoundException =&amp;gt;
    println(&amp;quot;Missing Class&amp;quot;, e)
  }

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setMaster(&amp;quot;local[3]&amp;quot;).setAppName(&amp;quot;hive&amp;quot;)
    val spark = SparkSession.builder().config(conf).enableHiveSupport().getOrCreate()

    spark.sql(&amp;quot;use spark_test&amp;quot;)
    spark.sql(&amp;quot;show tables&amp;quot;).show()
    spark.close()
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;补充：将查询结果保存到hdfs上，如果想保存到本地，则可以将save的路径改成本地路径。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;    val dataFrame = spark.sql(&amp;quot;select uid,keyword from sougou_records where keyword like &#39;%仙剑奇侠传%&#39;&amp;quot;)

    dataFrame.write
      .format(&amp;quot;csv&amp;quot;)
      .option(&amp;quot;header&amp;quot;, &amp;quot;false&amp;quot;)
      .option(&amp;quot;sep&amp;quot;, &amp;quot;\t&amp;quot;)
      .save(&amp;quot;hdfs://hadoop1:8020/xianJianTest&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果想以表格保存到MySQL或者Hive,可以使用&lt;code&gt;saveAsTable()&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val host = &amp;quot;localhost&amp;quot;
val port = 3306
val database = &amp;quot;sparktest&amp;quot;
val jdbcUrl = s&amp;quot;jdbc:mysql://$host:$port/$database?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;quot;
val connectionProperties = new java.util.Properties()
connectionProperties.put(&amp;quot;user&amp;quot;, &amp;quot;root&amp;quot;)
connectionProperties.put(&amp;quot;password&amp;quot;, &amp;quot;123456&amp;quot;)

df.write.mode(SaveMode.Overwrite).jdbc(jdbcUrl,&amp;quot;company&amp;quot;,connectionProperties)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;df.write.mode(SaveMode.Overwrite).saveAsTable(&amp;quot;spark_test.company&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Scala中函数与Spark的算子的区别</title>
        <link>https://rusthx.github.io/p/scala%E4%B8%AD%E5%87%BD%E6%95%B0%E4%B8%8Espark%E7%9A%84%E7%AE%97%E5%AD%90%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
        <pubDate>Sat, 07 Sep 2024 11:46:08 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/scala%E4%B8%AD%E5%87%BD%E6%95%B0%E4%B8%8Espark%E7%9A%84%E7%AE%97%E5%AD%90%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
        <description>&lt;p&gt;Scala中的部分函数和RDD中的部分算子名字一样，功能一样，用起来也差不多。但是为什么一个叫函数，一个却要叫算子，函数和算子的区别在哪，这让我有些好奇。于是查看了源码，对函数和算子进行了比较。下面以&lt;code&gt;map&lt;/code&gt;为例。&lt;/p&gt;
&lt;h2 id=&#34;scala中的map函数&#34;&gt;Scala中的map函数
&lt;/h2&gt;&lt;p&gt;Scala中的map通常定义在集合类中，例如&lt;code&gt;Map&lt;/code&gt;、&lt;code&gt;List&lt;/code&gt;、&lt;code&gt;Seq&lt;/code&gt;、&lt;code&gt;Set&lt;/code&gt;。作用是对该可迭代集合的所有元素应用一个函数，从而建立一个新的可迭代集合。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Builds a new iterable collection by applying a function to all elements of this iterable collection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;code&gt;List&lt;/code&gt;属于&lt;code&gt;scala.collection.immutable&lt;/code&gt;的子类，而&lt;code&gt;Map、Seq、Set&lt;/code&gt;属于&lt;code&gt;scala.collection&lt;/code&gt;的子类
&lt;code&gt;map&lt;/code&gt;函数最底层的源码应该是&lt;code&gt;scala.collection&lt;/code&gt;里的如下代码
&lt;img src=&#34;https://img2024.cnblogs.com/blog/3289663/202404/3289663-20240414125942145-277602576.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image.png&#34;
	
	
&gt;
具体实现以&lt;code&gt;List&lt;/code&gt;中的&lt;code&gt;map&lt;/code&gt;举例
源码为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  final override def map[B](f: A =&amp;gt; B): List[B] = {
    if (this eq Nil) Nil else {
      val h = new ::[B](f(head), Nil)
      var t: ::[B] = h
      var rest = tail
      while (rest ne Nil) {
        val nx = new ::(f(rest.head), Nil)
        t.next = nx
        t = nx
        rest = rest.tail
      }
      releaseFence()
      h
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;List&lt;/code&gt;中的&lt;code&gt;map&lt;/code&gt;重写了其父类&lt;code&gt;collection.IterableOnce&lt;/code&gt;的&lt;code&gt;map&lt;/code&gt;函数，定义了一个匿名函数&lt;code&gt;(f:A=&amp;gt;B)&lt;/code&gt;,对List中的每个元素A处理后输出B类型的&lt;code&gt;List&lt;/code&gt;。比如&lt;code&gt;List[String]&lt;/code&gt;经过&lt;code&gt;map&lt;/code&gt;处理后可以变成&lt;code&gt;List[Interger]&lt;/code&gt;
其他collection的代码可以自行查看，也可以查看Scala的官方文档&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.scala-lang.org/api/current/scala/collection&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.scala-lang.org/api/current/scala/collection&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;spark中的map算子&#34;&gt;Spark中的map算子
&lt;/h2&gt;&lt;p&gt;Spark中的算子分为转换算子（Transformations (return a new RDD)）和行动算子（Actions (launch a job to return a value to the user program)）， 转换算子根据数据处理方式的不同将算子整体上分为 Value 类型、双 Value 类型和 Key-Value 类型  。具体不再细讲，可以自行查询。
RDD中的&lt;code&gt;map&lt;/code&gt;代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;  /**
   * Return a new RDD by applying a function to all elements of this RDD.
   */
  def map[U: ClassTag](f: T =&amp;gt; U): RDD[U] = withScope {
    val cleanF = sc.clean(f)
    new MapPartitionsRDD[U, T](this, (_, _, iter) =&amp;gt; iter.map(cleanF))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看出，这里的&lt;code&gt;map&lt;/code&gt;首先创建了一个&lt;code&gt;MapPartitionsRDD&lt;/code&gt;并生成可迭代对象&lt;code&gt;iter&lt;/code&gt;,然后调用了Scala的&lt;code&gt;map&lt;/code&gt;函数处理&lt;code&gt;iter&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论
&lt;/h2&gt;&lt;p&gt;Scala里的&lt;code&gt;map&lt;/code&gt;函数首先定义在&lt;code&gt;scala.collection&lt;/code&gt;里，然后子类（&lt;code&gt;List&lt;/code&gt;、&lt;code&gt;Set&lt;/code&gt;）重写父类的函数。因为Scala里的类型是隐式的，并且查看源代码在一个子类里也只发现了一个&lt;code&gt;map&lt;/code&gt;函数，所以Scala里的&lt;code&gt;map&lt;/code&gt;并没有重载，而是通过定义父类，子类重写父类函数的方法实现对不同数据结构的操作。
Spark里的&lt;code&gt;map&lt;/code&gt;是对RDD进行操作的算子，实际使用了可迭代对象来调用Scala中的&lt;code&gt;map&lt;/code&gt;函数。算子本身的定义就是对RDD操作的函数，所以算子应该也可以被称为是函数，但是为了区分Scala中的函数，所以使用了不同的名字。&lt;/p&gt;
&lt;h2 id=&#34;补充&#34;&gt;补充
&lt;/h2&gt;&lt;p&gt;Spark中的算子并非全都有同名函数，原因可以从RDD的原理上分析。
行动算子需要进行&lt;code&gt;shuffle&lt;/code&gt;操作，在&lt;code&gt;shuffle&lt;/code&gt;时需要按键分区，对每个分区进行操作后输出。Scala中并没有&lt;code&gt;Shuffle&lt;/code&gt;操作，所以行动算子没有同名函数。
而转换算子是生成RDD或者将RDD转换成另外的RDD，Scala本身也有将&lt;code&gt;collection&lt;/code&gt;转换为&lt;code&gt;collection&lt;/code&gt;的函数，并且转换算子本身就调用了Scala的函数，所以有同名的也正常。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Spark程序大量Info日志问题解决</title>
        <link>https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</link>
        <pubDate>Sat, 07 Sep 2024 11:39:08 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</guid>
        <description>&lt;p&gt;Spark程序在启动后会在控制台打印大量日志，找了很多教程也没有解决，本来一直可以忍受的。但是学SparkStreaming时实在受不了了，日志已经严重影响到我查看计算结果。遂痛下决心，解决这个一直困扰我的问题。如果使用方法1没有解决的可以直接去看第三步，第二步是解决日志依赖冲突的问题的&lt;/p&gt;
&lt;h2 id=&#34;常规解决办法&#34;&gt;常规解决办法
&lt;/h2&gt;&lt;p&gt;在resource下建立一个log4j.properties，填入下列内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;log4j.rootCategory=ERROR, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/ddHH:mm:ss} %p %c{1}: %m%n
# Set the default spark-shell log level to ERROR. When running the spark-shell,the
# log level for this class is used to overwrite the root logger&#39;s log level, so that
# the user can have different defaults for the shell and regular Spark apps.
log4j.logger.org.apache.spark.repl.Main=ERROR
# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark_project.jetty=ERROR
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/1.png&#34;
	width=&#34;1587&#34;
	height=&#34;603&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/1_hu5431730765514624941.png 480w, https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/1_hu12252453515852226048.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;263&#34;
		data-flex-basis=&#34;631px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;查看日志寻求解决办法&#34;&gt;查看日志寻求解决办法
&lt;/h2&gt;&lt;p&gt;常规解决办法没有正常解决，遂查看日志寻求解决办法，查看日志可以明显看出有日志依赖冲突&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/D:/maven-3.8.6/respository/org/apache/logging/log4j/log4j-slf4j-impl/2.17.2/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/D:/maven-3.8.6/respository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;怀疑是日志冲突的问题（事实证明不是），分析日志依赖
&lt;img src=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/2.png&#34;
	width=&#34;632&#34;
	height=&#34;906&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/2_hu1458278568563639439.png 480w, https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/2_hu3302884581586329615.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;69&#34;
		data-flex-basis=&#34;167px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在SparkCore下面发现了slf4j的依赖，在spark-core的dependency里加入下列内容以屏蔽日志包。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;exclusions&amp;gt;
  &amp;lt;exclusion&amp;gt;
    &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;slf4j-reload4j&amp;lt;/artifactId&amp;gt;
  &amp;lt;/exclusion&amp;gt;
&amp;lt;/exclusions&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/3.png&#34;
	width=&#34;811&#34;
	height=&#34;446&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/3_hu2070361217706267611.png 480w, https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/3_hu5119317489834807306.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;
还是日志冲突，把所有dependency下面都加了排除日志依赖的标签
还是不起作用，观察日志可知冲突是因为reload4hj，干脆把仓库里的reload4j删掉，成功解决日志冲突
&lt;img src=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/4.png&#34;
	width=&#34;899&#34;
	height=&#34;375&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/4_hu3281290504749333552.png 480w, https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/4_hu6512393018722807227.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;
但是但是，日志依赖冲突的问题解决了，大量info日志的问题却还在&lt;/p&gt;
&lt;h2 id=&#34;最终解决办法&#34;&gt;最终解决办法
&lt;/h2&gt;&lt;p&gt;在resource下新建一个&lt;code&gt;log4j2.xml&lt;/code&gt;文件，填入下面内容即可解决。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;Configuration status=&amp;quot;WARN&amp;quot;&amp;gt;
    &amp;lt;Appenders&amp;gt;
        &amp;lt;Console name=&amp;quot;Console&amp;quot; target=&amp;quot;SYSTEM_OUT&amp;quot;&amp;gt;
            &amp;lt;PatternLayout&amp;gt;
                &amp;lt;Pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&amp;lt;/Pattern&amp;gt;
            &amp;lt;/PatternLayout&amp;gt;
        &amp;lt;/Console&amp;gt;
    &amp;lt;/Appenders&amp;gt;
    &amp;lt;Loggers&amp;gt;
        &amp;lt;Root level=&amp;quot;error&amp;quot;&amp;gt;
            &amp;lt;AppenderRef ref=&amp;quot;Console&amp;quot; /&amp;gt;
        &amp;lt;/Root&amp;gt;
    &amp;lt;/Loggers&amp;gt;
&amp;lt;/Configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/5.png&#34;
	width=&#34;1210&#34;
	height=&#34;624&#34;
	srcset=&#34;https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/5_hu14369273875121618743.png 480w, https://rusthx.github.io/p/spark%E7%A8%8B%E5%BA%8F%E5%A4%A7%E9%87%8Finfo%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/5_hu15208406693693291075.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;465px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Ubuntu22.04配置Spark3.3.1集群</title>
        <link>https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/</link>
        <pubDate>Sat, 07 Sep 2024 11:22:39 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/</guid>
        <description>&lt;p&gt;Spark启动方式有：local模式、standalone模式、Yarn模式、K8S和Mesos模式，本教程只涉及前三种模式，另外两种可以自行查找资料。&lt;/p&gt;
&lt;h2 id=&#34;local模式&#34;&gt;Local模式
&lt;/h2&gt;&lt;h3 id=&#34;1下载spark&#34;&gt;1.下载Spark
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://archive.apache.org/dist/spark/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://archive.apache.org/dist/spark/&lt;/a&gt;
由于我的Hadoop版本是3.1.3，所以下载的Spark版本也是Spark3,这里下的是Spark3.3.1，只要是Spark3都可以和Hadoop3兼容。&lt;/p&gt;
&lt;h3 id=&#34;2解压spark压缩包&#34;&gt;2.解压Spark压缩包
&lt;/h3&gt;&lt;p&gt;解压Spark的压缩包，移动到&lt;code&gt;/usr/local/&lt;/code&gt;下，修改文件夹的名字为spark&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd ~/Downloads
sudo tar -zxvf spark-3.3.1-bin-hadoop3.tgz -C /usr/local/
cd /usr/local/
mv spark-3.3.1-bin-hadoop3.2 spark
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3local模式启动spark&#34;&gt;3.Local模式启动Spark
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bin/spark-shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启动成功后，可以输入网址&lt;code&gt;主机名：4040&lt;/code&gt;进行 Web UI 监控页面访问
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/1.png&#34;
	width=&#34;692&#34;
	height=&#34;542&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/1_hu13411659414447418761.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/1_hu15091209146063601315.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;306px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/2.png&#34;
	width=&#34;692&#34;
	height=&#34;256&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/2_hu10899964117634986959.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/2_hu13561336368744297822.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;270&#34;
		data-flex-basis=&#34;648px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;standalone模式&#34;&gt;Standalone模式
&lt;/h2&gt;&lt;h3 id=&#34;1进入spark文件夹下的conf目录修改workerstemplate文件名为workers&#34;&gt;1.进入spark文件夹下的conf目录，修改workers.template文件名为workers
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd conf/
mv workers.template workers
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2修改workers文件添加worker节点&#34;&gt;2.修改workers文件，添加worker节点
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt; vim workers 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/3.png&#34;
	width=&#34;586&#34;
	height=&#34;75&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/3_hu9370041268607244147.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/3_hu3025662213800880645.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;781&#34;
		data-flex-basis=&#34;1875px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/4.png&#34;
	width=&#34;1111&#34;
	height=&#34;428&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/4_hu17370934111469867891.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/4_hu4728401156525235443.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;259&#34;
		data-flex-basis=&#34;622px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;3修改spark-envshtemplate文件名为spark-envsh&#34;&gt;3.修改spark-env.sh.template文件名为spark-env.sh
&lt;/h3&gt;&lt;h3 id=&#34;4修改spark-envsh文件添加java_home环境变量和集群对应的master节点&#34;&gt;4.修改spark-env.sh文件，添加&lt;code&gt;JAVA_HOME&lt;/code&gt;环境变量和集群对应的master节点
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/5.png&#34;
	width=&#34;664&#34;
	height=&#34;44&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/5_hu18412699254950233080.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/5_hu15348095363903452333.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1509&#34;
		data-flex-basis=&#34;3621px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/6.png&#34;
	width=&#34;517&#34;
	height=&#34;151&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/6_hu11511121656198141294.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/6_hu15755966112917960182.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;342&#34;
		data-flex-basis=&#34;821px&#34;
	
&gt;
Java默认安装路径如下，手动安装的Java可以指定自己的Java路径
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/7.png&#34;
	width=&#34;692&#34;
	height=&#34;166&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/7_hu8520661546659697823.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/7_hu282144205048903332.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;416&#34;
		data-flex-basis=&#34;1000px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;5分发spark&#34;&gt;5.分发Spark
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/8.png&#34;
	width=&#34;451&#34;
	height=&#34;101&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/8_hu6963929853805175707.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/8_hu6241441082680902207.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;446&#34;
		data-flex-basis=&#34;1071px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;6standalone模式启动spark集群&#34;&gt;6.Standalone模式启动Spark集群
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd spark/
sbin/start-all.sh
xcall jps
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;7查看进程&#34;&gt;7.查看进程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/9.png&#34;
	width=&#34;692&#34;
	height=&#34;343&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/9_hu11366282666986785103.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/9_hu12612634464676384337.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;
Spark正常启动输入网址&lt;code&gt;主机名:8080&lt;/code&gt;进行监控
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/10.png&#34;
	width=&#34;692&#34;
	height=&#34;328&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/10_hu2060644001827612340.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/10_hu15856899553100142721.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;210&#34;
		data-flex-basis=&#34;506px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;8提交应用测试spark&#34;&gt;8.提交应用测试Spark
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bin/spark-submit 
--class org.apache.spark.examples.SparkPi 
--master spark://hadoop1:7077 
./examples/jars/spark-examples_2.12-3.3.1.jar 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&amp;ndash;master后面指定的主机名要改成自己的主机名（hadoop1改成自己的主机名）
指定的jar包要指定为自己的jar包，不同版本的示例jar包名字不同。
10是指当前应用的任务数量
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/11.png&#34;
	width=&#34;691&#34;
	height=&#34;121&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/11_hu5688388085362936308.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/11_hu7159536826896782106.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;571&#34;
		data-flex-basis=&#34;1370px&#34;
	
&gt;
提交任务时会有一个SparkSubmit进程，任务结束后进程停止
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/12.png&#34;
	width=&#34;547&#34;
	height=&#34;569&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/12_hu7418334220115483844.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/12_hu6016238825539299710.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;96&#34;
		data-flex-basis=&#34;230px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-模式&#34;&gt;Yarn 模式
&lt;/h2&gt;&lt;h3 id=&#34;1修改hadoop配置文件&#34;&gt;1.修改Hadoop配置文件
&lt;/h3&gt;&lt;p&gt;修改&lt;code&gt;/usr/local/hadoop/etc/hadoop/yarn-site.xml&lt;/code&gt;, 并分发&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim /usr/local/hadoop/etc/hadoop/yarn-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认
是true --&amp;gt; 
&amp;lt;property&amp;gt; 
&amp;lt;name&amp;gt;yarn.nodemanager.pmem-check-enabled&amp;lt;/name&amp;gt; 
&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt; 
&amp;lt;/property&amp;gt; 
&amp;lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认
是true --&amp;gt; 
&amp;lt;property&amp;gt; 
&amp;lt;name&amp;gt;yarn.nodemanager.vmem-check-enabled&amp;lt;/name&amp;gt; 
&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt; 
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/13.png&#34;
	width=&#34;692&#34;
	height=&#34;549&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/13_hu12271283889677969348.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/13_hu16736059404118154314.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;302px&#34;
	
&gt;
分发修改后的配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;xsync /usr/local/hadoop/etc/hadoop/yarn-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/14.png&#34;
	width=&#34;693&#34;
	height=&#34;176&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/14_hu6905782161851684135.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/14_hu1804595154733794608.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;393&#34;
		data-flex-basis=&#34;945px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-修改confspark-envsh添加-java_home-和-yarn_conf_dir-配置&#34;&gt;2. 修改conf/spark-env.sh，添加 &lt;code&gt;JAVA_HOME&lt;/code&gt; 和 &lt;code&gt;YARN_CONF_DIR &lt;/code&gt;配置
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim conf/spark-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/15.png&#34;
	width=&#34;692&#34;
	height=&#34;549&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/15_hu1429263151845228789.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/15_hu10707229636908163097.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;302px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;3分发更改后的spark-envsh&#34;&gt;3.分发更改后的Spark-env.sh
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;xsync conf/spark-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/16.png&#34;
	width=&#34;531&#34;
	height=&#34;213&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/16_hu14375517168970993541.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/16_hu10177607509824995458.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;249&#34;
		data-flex-basis=&#34;598px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;4yarn模式提交任务测试&#34;&gt;4.Yarn模式提交任务测试
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Client模式&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bin/spark-submit --class org.apache.spark.examples.SparkPi
--master yarn 
--deploy-mode client
./examples/jars/spark-examples_2.12-3.3.1.jar 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/17.png&#34;
	width=&#34;692&#34;
	height=&#34;83&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/17_hu9853654027330023775.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/17_hu14851843207891514165.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;833&#34;
		data-flex-basis=&#34;2000px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Cluster模式&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bin/spark-submit --class org.apache.spark.examples.SparkPi
--master yarn 
--deploy-mode cluster
./examples/jars/spark-examples_2.12-3.3.1.jar 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/18.png&#34;
	width=&#34;692&#34;
	height=&#34;111&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/18_hu14513159411837347509.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/18_hu5433995651513985956.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;623&#34;
		data-flex-basis=&#34;1496px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;5在hadoop18088查看程序运行成功&#34;&gt;5.在hadoop1:8088查看，程序运行成功
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/19.png&#34;
	width=&#34;692&#34;
	height=&#34;289&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/19_hu17058640190159608060.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEspark3.3.1%E9%9B%86%E7%BE%A4/19_hu1839875858801763919.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;574px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;补充提交参数说明&#34;&gt;补充：提交参数说明
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;参数&lt;/th&gt;
          &lt;th&gt;解释&lt;/th&gt;
          &lt;th&gt;可选值举例&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;ndash;class&lt;/td&gt;
          &lt;td&gt;Spark 程序中包含主函数的类&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;ndash;master&lt;/td&gt;
          &lt;td&gt;Spark 程序运行的模式(环境)&lt;/td&gt;
          &lt;td&gt;模式：local[*]、spark://hadoop1:7077、Yarn&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;ndash;executor-memory 1G&lt;/td&gt;
          &lt;td&gt;指定每个executor 可用内存为1G&lt;/td&gt;
          &lt;td&gt;符合集群内存配置即可，具体情况具体分析。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;ndash;total-executor-cores 2&lt;/td&gt;
          &lt;td&gt;指定所有executor使用的cpu核数析。为2个&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&amp;ndash;executor-cores&lt;/td&gt;
          &lt;td&gt;指定每个executor使用的cpu核数&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;application-jar&lt;/td&gt;
          &lt;td&gt;打包好的应用 jar，包含依赖。这个URL 在集群中全局可见。比如 hdfs:// 共享存储系统，如果是file:// path，那么所有的节点的&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;path 都包含同样的 jar&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;application-arguments&lt;/td&gt;
          &lt;td&gt;传给 main()方法的参数&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>Ubuntu22.04配置Hive及Hive on Spark</title>
        <link>https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/</link>
        <pubDate>Sat, 07 Sep 2024 11:15:48 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/</guid>
        <description>&lt;h2 id=&#34;前置准备配置hive的mysql连接用户&#34;&gt;前置准备：配置Hive的MySQL连接用户
&lt;/h2&gt;&lt;p&gt;MySQL的配置可参考我的教程 &lt;a class=&#34;link&#34; href=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MySQL安装教程&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建Hive元数据库&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create database metastore;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;创建用户hive，设置密码为123456&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create user &#39;hive&#39;@&#39;%&#39; identified by &#39;123456&#39;;
grant all privileges on metastore.* to &#39;hive&#39;@&#39;%&#39; with grant option;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;安装hive&#34;&gt;安装Hive
&lt;/h2&gt;&lt;p&gt;参考资料：B站尚硅谷
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1mG411o7Lt?p=62&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;062.Hive的安装部署_哔哩哔哩_bilibili&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载Hive安装包&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：apache原装的Hive只支持Spark2.3.0，不支持Spark3.3.0，需要重新编译Hive的源码，尚硅谷已经编译好了，这里我就直接使用了&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;修改配置文件（cd 到hive下的conf文件夹，这里我已经将Hive安装包改名为hive并移动到/usr/local/下）&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo mv hive-default.xml.template hive-default.xml
sudo vim hive-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将以下内容写入文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;

&amp;lt;configuration&amp;gt;
    &amp;lt;!-- jdbc连接的URL --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;jdbc:mysql://hadoop1:3306/metastore?useUnicode=true&amp;amp;amp;characterEncodeing=UTF-8&amp;amp;amp;allowPublicKeyRetrieval=true&amp;amp;amp;useSSL=false&amp;amp;amp;serverTimezone=GMT&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    
    &amp;lt;!-- jdbc连接的Driver--&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    
	&amp;lt;!-- jdbc连接的username--&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hive&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- jdbc连接的password --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;123456&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    
    &amp;lt;!-- Hive默认在HDFS的工作目录 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/user/hive/warehouse&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    
        &amp;lt;!-- 指定存储元数据要连接的地址 --&amp;gt;
    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;thrift://hadoop1:9083&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    
    &amp;lt;!-- 指定hiveserver2连接的host --&amp;gt;
    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.server2.thrift.bind.host&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;hadoop1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 指定hiveserver2连接的端口号 --&amp;gt;
    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.server2.thrift.port&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;10000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- hiveserver2的高可用参数，开启此参数可以提高hiveserver2的启动速度 --&amp;gt;
    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.server2.active.passive.ha.enable&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.cli.print.header&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.cli.print.current.db&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;配置环境变量&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo vim ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在下面添加&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;启动hive&#34;&gt;启动Hive
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;启动Hadoop&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;start-all.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;初始化Hive&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /usr/local/hive
./bin/schematool -dbType mysql -initSchema
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正常初始化会日志刷屏并出现大片空白，然后最后一行出现succeed或者complete的字样
如果没有正常初始化就复制最下面几行中的报错信息，粘贴到必应进行查找&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;启动Hive&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;启动Hive前需要先启动Hive的元数据库metastore和hiveserver2
注意：这里的metastore和hiveserver2每个都要单独开启一个终端，开启一个后再开一个新的终端进行命令
日志被重定向到了logs文件夹下，需要查看日志可以在这个文件夹下查看&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /usr/local/hive/
hive --service metastore &amp;gt;logs/metastore.log 2&amp;gt;&amp;amp;1
hive --service hiveserver2 &amp;gt;logs/hiveServer2.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bin/hive
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正常启动会出现一个交互界面如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hive(default)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;解决Hive shell中打印大量日志的问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当在Hive的命令行中查询时出现大量日志时，可以在conf下新建日志配置文件如下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /usr/local/conf/
vim log4j.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;粘贴如下内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;log4j.rootLogger=WARN, CA
log4j.appender.CA=org.apache.log4j.ConsoleAppender
log4j.appender.CA.layout=org.apache.log4j.PatternLayout
log4j.appender.CA.layout.ConversionPattern=%-4r [%t] %-5p %c %x - %m%n
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hive-on-spark配置&#34;&gt;Hive on Spark配置
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在官网下载纯净版Spark（不带Hadoop依赖的）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://spark.apache.org/downloads.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://spark.apache.org/downloads.html&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;解压Spark&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tar -zxvf spark-3.3.1-bin-without-hadoop.tgz -C /usr/local/
mv /usr/local/spark-3.3.1-bin-without-hadoop /usr/local/spark
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;修改spark-env.sh配置文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mv /usr/local/spark/conf/spark-env.sh.template /usr/local/spark/conf/spark-env.sh
vim /usr/local/spark/conf/spark-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;增添下面内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export SPARK_DIST_CLASSPATH=$(hadoop classpath)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;配置Spark环境变量&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo vim ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加下列内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;在Hive中创建spark配置文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim /usr/local/hive/conf/spark-defaults.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加如下内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;spark.master                               yarn
spark.eventLog.enabled                   true
spark.eventLog.dir                        hdfs://hadoop1:8020/spark-history
spark.executor.memory                    1g
spark.driver.memory					     1g
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在HDFS中创建如下路径，用于存储历史日志&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hadoop fs -mkdir /spark-history
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;向HDFS上传Spark纯净版jar包&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;说明1：采用Spark纯净版jar包，不包含hadoop和hive相关依赖，能避免依赖冲突。
说明2：Hive任务最终由Spark来执行，Spark任务资源分配由Yarn来调度，该任务有可能被分配到集群的任何一个节点。所以需要将Spark的依赖上传到HDFS集群路径，这样集群中任何一个节点都能获取到&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hadoop fs -mkdir /spark-jars
hadoop fs -put /usr/local/spark/jars/* /spark-jars
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;修改hive-site.xml文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim /usr/local/hive/conf/hive-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加如下内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;!--Spark依赖位置（注意：端口号8020必须和namenode的端口号一致）--&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;spark.yarn.jars&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hdfs://hadoop1:8020/spark-jars/*&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;!--Hive执行引擎--&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.execution.engine&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;spark&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;!--连接超时时间--&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.spark.client.connect.timeout&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;30000ms&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hive-on-spark测试&#34;&gt;Hive on Spark测试
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;启动hive客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd /usr/local/hive/
bin/hive
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;创建一张测试表&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;hive (default)&amp;gt; create table student(id int, name string);
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;通过insert测试效果&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;hive (default)&amp;gt; insert into table student values(1,&#39;abc&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;结果如下则配置成功
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/1.png&#34;
	width=&#34;1643&#34;
	height=&#34;686&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/1_hu18263344740042083967.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/1_hu11299025821609503695.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;574px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/2.png&#34;
	width=&#34;914&#34;
	height=&#34;659&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/2_hu13084986199049206096.png 480w, https://rusthx.github.io/p/ubuntu22.04%E9%85%8D%E7%BD%AEhive%E5%8F%8Ahive-on-spark/2_hu2576634140735695222.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn环境配置&#34;&gt;Yarn环境配置
&lt;/h2&gt;&lt;p&gt;增加ApplicationMaster资源比例
容量调度器对每个资源队列中同时运行的Application Master占用的资源进行了限制，该限制通过yarn.scheduler.capacity.maximum-am-resource-percent参数实现，其默认值是0.1，表示每个资源队列上Application Master最多可使用的资源为该队列总资源的10%，目的是防止大部分资源都被Application Master占用，而导致Map/Reduce Task无法执行。
生产环境该参数可使用默认值。但学习环境，集群资源总数很少，如果只分配10%的资源给Application Master，则可能出现，同一时刻只能运行一个Job的情况，因为一个Application Master使用的资源就可能已经达到10%的上限了。故此处可将该值适当调大。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在hadoop1的/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml文件中&lt;strong&gt;修改&lt;/strong&gt;如下参数值&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim capacity-scheduler.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;yarn.scheduler.capacity.maximum-am-resource-percent&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0.8&amp;lt;/value&amp;gt;
&amp;lt;/property
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;分发capacity-scheduler.xml配置文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;xsync capacity-scheduler.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;重启集群&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;stop-all.sh
start-all.sh
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Ubuntu 22.04部署Apache Superset</title>
        <link>https://rusthx.github.io/p/ubuntu-22.04%E9%83%A8%E7%BD%B2apache-superset/</link>
        <pubDate>Sat, 07 Sep 2024 11:09:06 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/ubuntu-22.04%E9%83%A8%E7%BD%B2apache-superset/</guid>
        <description>&lt;h2 id=&#34;安装依赖&#34;&gt;安装依赖
&lt;/h2&gt;&lt;p&gt;使用以下命令安装依赖&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install build-essential libssl-dev libffi-dev python3-dev python3-pip libsasl2-dev libldap2-dev default-libmysqlclient-dev 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;配置superset元数据库&#34;&gt;配置Superset元数据库
&lt;/h2&gt;&lt;p&gt;本教程使用MySQL数据库作为Superset的数据库（Superset支持MySQL和PostgreSQL)，安装完成后需进行以下配置。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在MySQL中创建Superset元数据库&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE DATABASE superset DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;创建Superset用户，用户名为superset,密码为superset。superset用户拥有所有数据库的全部权限。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create user superset@&#39;%&#39; identified WITH mysql_native_password BY &#39;superset&#39;;
grant all privileges on *.* to superset@&#39;%&#39; with grant option;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;为superset创建python虚拟环境&#34;&gt;为Superset创建Python虚拟环境
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;更新pip&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;下载必要的虚拟环境包&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo pip install virtualenv -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;创建虚拟环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv superset
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;激活虚拟环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source superset/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;安装Superset&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install apache-superset -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;安装其他Python依赖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install gunicorn pymysql mysqlclient -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;说明：gunicorn是一个Python Web Server，可以和java中的TomCat类比&lt;/p&gt;
&lt;h2 id=&#34;配置superset&#34;&gt;配置Superset
&lt;/h2&gt;&lt;p&gt;在~/superset/bin目录下创建superset配置文件superset_config.py，详细配置可参考官方文档（&lt;a class=&#34;link&#34; href=&#34;https://superset.apache.org/docs/installation/configuring-superset/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://superset.apache.org/docs/installation/configuring-superset/&lt;/a&gt;）或者GitHub（&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/superset/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/superset/&lt;/a&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Superset specific config
ROW_LIMIT = 5000

#SUPERSET_WEBSERVER_PORT = 8088

# Flask App Builder configuration
# Your App secret key will be used for securely signing the session cookie
# and encrypting sensitive information on the database
# Make sure you are changing this key for your deployment with a strong key.
# You can generate a strong key using `openssl rand -base64 42`

&#39;&#39;&#39;
使用命令“openssl rand -base64 42”创建SECRET_KEY填写到下面&#39;&#39;&#39;
SECRET_KEY = &#39;&#39;

# The SQLAlchemy connection string to your database backend
# This connection defines the path to the database that stores your
# superset metadata (slices, connections, tables, dashboards, ...).
# Note that the connection information to connect to the datasources
# you want to explore are managed directly in the web UI
&#39;&#39;&#39;
数据库连接，我是用的是MySQL数据库
链接字符串：mysql+pymysql://&amp;lt;数据库用户&amp;gt;:&amp;lt;密码&amp;gt;@&amp;lt;主机名/ip&amp;gt;/&amp;lt;数据库名&amp;gt;&#39;&#39;&#39;
SQLALCHEMY_DATABASE_URI = &#39;mysql+pymysql://superset:superset@hadoop01:3306/superset?charset=utf8&#39;
ENABLE_CSRF_PROTECTION = True
# Flask-WTF flag for CSRF

WTF_CSRF_ENABLED = True
WTF_CSRF_CHECK_DEFAULT = True
# Add endpoints that need to be exempt from CSRF protection
#WTF_CSRF_EXEMPT_LIST = []
# A CSRF token that expires in 1 year
#WTF_CSRF_TIME_LIMIT = 60 * 60 * 24 * 365

#不填这个会出现登录界面输入正确的用户名和密码后登录无反应的现象
#但是关掉这个可能会降低安全性，可能是superset版本太新（3.0.0），旧版本貌似没有这个问题
TALISMAN_ENABLED=False

# Set this API key to enable Mapbox visualizations
MAPBOX_API_KEY = &#39;&#39;

COMPRESS_REGISTER = False

#默认中文
BABEL_DEFAULT_LOCALE = &amp;quot;zh&amp;quot;
#superset支持的语言
LANGUAGES = {
    &amp;quot;en&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;us&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;English&amp;quot;},
    &amp;quot;es&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;es&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Spanish&amp;quot;},
    &amp;quot;it&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;it&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Italian&amp;quot;},
    &amp;quot;fr&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;fr&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;French&amp;quot;},
    &amp;quot;zh&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;cn&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Chinese&amp;quot;},
    &amp;quot;ja&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;jp&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Japanese&amp;quot;},
    &amp;quot;de&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;de&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;German&amp;quot;},
    &amp;quot;pt&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;pt&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Portuguese&amp;quot;},
    &amp;quot;pt_BR&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;br&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Brazilian Portuguese&amp;quot;},
    &amp;quot;ru&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;ru&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Russian&amp;quot;},
    &amp;quot;ko&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;kr&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Korean&amp;quot;},
    &amp;quot;sk&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;sk&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Slovak&amp;quot;},
    &amp;quot;sl&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;si&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Slovenian&amp;quot;},
    &amp;quot;nl&amp;quot;: {&amp;quot;flag&amp;quot;: &amp;quot;nl&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Dutch&amp;quot;},
}

SHOW_STACKTRACE = False

DEBUG = False

APP_NAME = &amp;quot;Superset&amp;quot;

#不填这个会导致报错如下
#ModuleNotFoundError: No module named &#39;MySQL_db&#39;
SQLALCHEMY_TRACK_MODIFICATIONS = False

import logging

LOG_LEVEL = &#39;DEBUG&#39;  # 设置日志级别为DEBUG可以获得最详细的日志信息
LOG_FILE = &#39;/home/rust/superset/superset_logfile.log&#39;  # 指定日志文件路径

logging.basicConfig(
    filename=LOG_FILE,
    level=LOG_LEVEL,
    format=&#39;%(asctime)s %(levelname)s %(name)s %(threadName)s : %(message)s&#39;,
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;初始化superset&#34;&gt;初始化Superset
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;初始化数据库&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(superset) rust@hadoop01:~$ export FLASK_APP=superset
(superset) rust@hadoop01:~$ superset db upgrade
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;在元数据库中创建一个superset管理员用户&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(superset) rust@hadoop01:~$ superset fab create-admin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;初始化superset&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(superset) rust@hadoop01:~$ superset init
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;启动superset&#34;&gt;启动Superset
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; (superset) rust@hadoop01:~$gunicorn --workers 5 --timeout 120 --bind hadoop01:8787  &amp;quot;superset.app:create_app()&amp;quot; --daemon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;说明：
&amp;ndash;workers：指定进程个数
&amp;ndash;timeout：worker进程超时时间，超时会自动重启
&amp;ndash;bind：绑定本机地址，即为Superset访问地址
&amp;ndash;daemon：后台运行&lt;/p&gt;
&lt;h2 id=&#34;登录supperset&#34;&gt;登录Supperset
&lt;/h2&gt;&lt;p&gt;访问&lt;a class=&#34;link&#34; href=&#34;http://hadoop102:8787&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://hadoop102:8787&lt;/a&gt;，并使用初始化Supperset中创建的管理员账户进行登录。&lt;/p&gt;
&lt;h2 id=&#34;停止superset&#34;&gt;停止Superset
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;停止gunicorn进程&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(superset) rust@hadoop01:~$ ps -ef | awk &#39;/superset/ &amp;amp;&amp;amp; !/awk/{print $2}&#39; | xargs kill -9
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;退出superset虚拟环境&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(superset) rust@hadoop01:~$ ps -ef |grep superst
#查到进程号后杀掉进程
(superset) rust@hadoop01:~$ kill -9 pid
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;superset启停脚本&#34;&gt;Superset启停脚本
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;创建superset.sh文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim superset.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;内容如下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

superset_status(){
    result=`ps -ef | awk &#39;/gunicorn/ &amp;amp;&amp;amp; !/awk/{print $2}&#39; | wc -l`
    if [[ $result -eq 0 ]]; then
        return 0
    else
        return 1
    fi
}
superset_start(){
        source ~/.bashrc
        superset_status &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
        if [[ $? -eq 0 ]]; then
            source ~/superset/bin/activate ; gunicorn --workers 5 --timeout 120 --bind hadoop01:8787 --daemon &#39;superset.app:create_app()&#39;
        else
            echo &amp;quot;superset正在运行&amp;quot;
        fi

}

superset_stop(){
    superset_status &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
    if [[ $? -eq 0 ]]; then
        echo &amp;quot;superset未在运行&amp;quot;
    else
        ps -ef | awk &#39;/gunicorn/ &amp;amp;&amp;amp; !/awk/{print $2}&#39; | xargs kill -9
    fi
}


case $1 in
    start )
        echo &amp;quot;启动Superset&amp;quot;
        superset_start
    ;;
    stop )
        echo &amp;quot;停止Superset&amp;quot;
        superset_stop
    ;;
    restart )
        echo &amp;quot;重启Superset&amp;quot;
        superset_stop
        superset_start
    ;;
    status )
        superset_status &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
        if [[ $? -eq 0 ]]; then
            echo &amp;quot;superset未在运行&amp;quot;
        else
            echo &amp;quot;superset正在运行&amp;quot;
        fi
esac

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;加执行权限&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chmod +x superset.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;测试&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#启动superset
superset.sh start
#停止superset
superset.sh stop
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Ubuntu22.04安装MySQL8.0.35</title>
        <link>https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/</link>
        <pubDate>Wed, 04 Sep 2024 23:18:48 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/</guid>
        <description>&lt;h2 id=&#34;更新软件包&#34;&gt;更新软件包
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get update 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/1.png&#34;
	width=&#34;874&#34;
	height=&#34;281&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/1_hu10208442681550117401.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/1_hu1540946352521276743.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;311&#34;
		data-flex-basis=&#34;746px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;下载mysql&#34;&gt;下载MySQL
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install mysql-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/2.png&#34;
	width=&#34;715&#34;
	height=&#34;471&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/2_hu3499638476653893172.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/2_hu13321327387705561269.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;364px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;登入mysql&#34;&gt;登入MySQL
&lt;/h2&gt;&lt;p&gt;MySQL安装完成后会有默认用户和密码，通过默认的用户和密码登入MySQL后可以新建用户并对该用户赋权&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;查看默认用户和密码的命令&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo cat /etc/mysql/debian.cnf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/3.png&#34;
	width=&#34;645&#34;
	height=&#34;318&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/3_hu6395335293921905352.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/3_hu3445967368468062197.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;202&#34;
		data-flex-basis=&#34;486px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;使用默认用户和密码登入数据库&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;mysql -u用户名 -p
输入密码
用户名和密码分别为上图中的user 和password&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mysql -udebian-sys-maint -p

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/4.png&#34;
	width=&#34;772&#34;
	height=&#34;401&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/4_hu13038779922474440114.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/4_hu1796599610772816749.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;192&#34;
		data-flex-basis=&#34;462px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;新建用户-设置密码-赋权&#34;&gt;新建用户 设置密码 赋权
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;设置root用户的密码（我的密码设置为123456，根据自己的需求修改命令）&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;use mysql;
update user set authentication_string=&#39;&#39; where user=&#39;root&#39;;
alter user &#39;root&#39;@&#39;localhost&#39; identified with mysql_native_password by &#39;123456&#39;;
quit;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/5.png&#34;
	width=&#34;848&#34;
	height=&#34;578&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/5_hu13115251342486511113.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/5_hu4830470020606109148.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;使用root用户登入数据库，并新建用户和赋权&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图为查询用户密码（加密过的）的命令
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/6.png&#34;
	width=&#34;1191&#34;
	height=&#34;500&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/6_hu4511073906702965881.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/6_hu14249002274118037829.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;571px&#34;
	
&gt;
下列命令的意思是：
创建用户rust 并设置rust用户可以访问的位置为%（本地访问和远程访问，仅本地访问为localhost）
复制所有数据库的所有权限给rust用户
刷新权限&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE USER &#39;rust&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;rust&#39;@&#39;%&#39; WITH GRANT OPTION;
flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;设置mysql数据库允许远程访问&#34;&gt;设置MySQL数据库允许远程访问
&lt;/h2&gt;&lt;p&gt;默认情况下，MySQL服务器只允许本地连接。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;编辑MySQL配置文件（/etc/mysql/mysql.conf.d/mysqld.cnf）并注释掉以下行（在 bind-address 行前面添加#）：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo gedit /etc/mysql/mysql.conf.d/mysqld.cnf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/7.png&#34;
	width=&#34;904&#34;
	height=&#34;788&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/7_hu11885888147539780446.png 480w, https://rusthx.github.io/p/ubuntu22.04%E5%AE%89%E8%A3%85mysql8.0.35/7_hu2354824758386346848.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;114&#34;
		data-flex-basis=&#34;275px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;保存文件并重启MySQL服务器&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo systemctl restart mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mysql执行顺序&#34;&gt;MySQL执行顺序
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/Elsa15/article/details/108544943&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/Elsa15/article/details/108544943&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;(9) SELECT (10)DISTINCT column,(6) AGG_FUNC(column or expression),...
(1）FROM left_table
(3）J0IN right_table
(2） ON tablename.column =
 other_tablename.column
 (4）WHERE constraint_expression(5)GROUP BY column
(7)WITH CUBE | ROLLUP
(8)HAVING constraint_expression(11)ORDER BY column ASCIDEsc
(12)LIMIT count OFFSET count;
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Ubuntu22.04扩展虚拟机的磁盘空间</title>
        <link>https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/</link>
        <pubDate>Wed, 04 Sep 2024 23:10:48 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/</guid>
        <description>&lt;p&gt;可视化界面的操作简单易上手，主要是基于Gparted,非常适合新手。但是可视化界面的操作也有无法解决的问题，比如因为某些操作（例如编译系统或者下载大小未知的文件）可能会导致系统磁盘空间被占满从而无法下载GParted甚至无法正常开机的状况，这种时候就要使用命令行的扩容方案。&lt;/p&gt;
&lt;h2 id=&#34;可视化界面操作方案&#34;&gt;可视化界面操作方案
&lt;/h2&gt;&lt;h3 id=&#34;vmware给虚拟机扩展空间不是虚拟机可以直接跳过此步骤&#34;&gt;VMware给虚拟机扩展空间（不是虚拟机可以直接跳过此步骤）
&lt;/h3&gt;&lt;p&gt;在虚拟机设置里的磁盘选项点击扩展，选择要扩展到的磁盘大小，我的虚拟机本来就有80G,所以这里就只扩展5G作为演示。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/1.png&#34;
	width=&#34;1208&#34;
	height=&#34;985&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/1_hu12106751947029339970.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/1_hu6196415264076441985.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;122&#34;
		data-flex-basis=&#34;294px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/2.png&#34;
	width=&#34;859&#34;
	height=&#34;975&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/2_hu9565770717993669400.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/2_hu15163141580311301028.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;211px&#34;
	
&gt;
扩容完成后还需要在虚拟机里分区和扩展文件系统。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/3.png&#34;
	width=&#34;467&#34;
	height=&#34;270&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/3_hu1773551381671098408.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/3_hu18111936894384987885.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;查看系统占用情况&#34;&gt;查看系统占用情况
&lt;/h3&gt;&lt;p&gt;可视化界面可以在左侧点击文件管理后，点击其他位置，正上方的计算机那里可以看到计算机的使用情况
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/4.png&#34;
	width=&#34;1721&#34;
	height=&#34;571&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/4_hu2007246107059773133.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/4_hu7408267796379412263.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;301&#34;
		data-flex-basis=&#34;723px&#34;
	
&gt;
终端界面，可以输入&lt;code&gt;df -h&lt;/code&gt;或者&lt;code&gt;sudo fdisk -l&lt;/code&gt;查看系统占用情况
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/5.png&#34;
	width=&#34;678&#34;
	height=&#34;233&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/5_hu11591823085248474772.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/5_hu7497566207331258488.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;290&#34;
		data-flex-basis=&#34;698px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/6.png&#34;
	width=&#34;630&#34;
	height=&#34;600&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/6_hu10768229985305003616.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/6_hu15012015003107074853.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;252px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;下载分区管理软件gparted&#34;&gt;下载分区管理软件GParted
&lt;/h3&gt;&lt;p&gt;在终端中输入下面的命令下载GParted&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install gparted
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/7.png&#34;
	width=&#34;724&#34;
	height=&#34;542&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/7_hu18236979346184824430.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/7_hu8463672506275937872.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;对磁盘进行分区&#34;&gt;对磁盘进行分区
&lt;/h3&gt;&lt;p&gt;点击左下角的九个点（显示应用程序），找到GParted。因为涉及磁盘数据，所以需要root权限，在弹出界面输入root用户密码即可。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/8.png&#34;
	width=&#34;630&#34;
	height=&#34;600&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/8_hu10768229985305003616.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/8_hu15012015003107074853.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;252px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/9.png&#34;
	width=&#34;937&#34;
	height=&#34;519&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/9_hu13732989479892242957.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/9_hu1920041380140205096.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;
打开软件可以看到目前虚拟机的磁盘情况，灰色的是刚刚在VMware给虚拟机扩容的5G,还没有分配，需要手动分配。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/10.png&#34;
	width=&#34;937&#34;
	height=&#34;481&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/10_hu8036443337925835756.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/10_hu1497489823618280859.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;
可以看到，&lt;code&gt;/dev/sda3&lt;/code&gt;是被挂载到了根目录下面，我们扩容也是要对根目录扩容。右键&lt;code&gt;/dev/sda3&lt;/code&gt;，点击调整大小/移动选项，直接滑动条拉到底或者编辑新大小调整空间。然后点击调整大小。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/11.png&#34;
	width=&#34;777&#34;
	height=&#34;533&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/11_hu9168923410551075940.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/11_hu14848813474366135717.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;349px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/12.png&#34;
	width=&#34;777&#34;
	height=&#34;575&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/12_hu9769587233959993197.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/12_hu10839976496606617712.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;
然后左下角会显示一项操作待处理，点击绿色的√后点击应用操作
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/13.png&#34;
	width=&#34;783&#34;
	height=&#34;535&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/13_hu13650397478392655371.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/13_hu689082093374461633.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;351px&#34;
	
&gt;
此时计算机的空间就成功扩容5G
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/14.png&#34;
	width=&#34;792&#34;
	height=&#34;536&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/14_hu5341166121250603329.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/14_hu3563252421528596862.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;354px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;出现无法调整只读文件系统的大小cannot-resize-read-only-file-system的解决办法&#34;&gt;出现无法调整只读文件系统的大小(cannot resize read-only file system)的解决办法
&lt;/h3&gt;&lt;p&gt;右键/dev/sda3，点击信息，查看挂载点，重新挂载文件夹目录的读写权限。这里系统挂载了几个目录就要重新挂载几个目录的文件读写权限。
这里因为演示的这台机是一台新机，还没有用过火狐浏览器什么的，所以只挂载了根目录。我用另外一台机进行演示
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/15.png&#34;
	width=&#34;1417&#34;
	height=&#34;276&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/15_hu8590855065025474934.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/15_hu929876264231526366.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;513&#34;
		data-flex-basis=&#34;1232px&#34;
	
&gt;
打开终端，重新挂载这几个目录的读写权限&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo mount -o remount -rw /
sudo mount -o remount -rw /var/snap/firefox/common/host-hunspell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/16.png&#34;
	width=&#34;778&#34;
	height=&#34;540&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/16_hu12044048748551198719.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/16_hu16549570152843178858.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;345px&#34;
	
&gt;
重新打开GParted或者点击左上角的刷新设备，再次对磁盘进行分区（参照上述教程）&lt;/p&gt;
&lt;h2 id=&#34;命令行操作方案&#34;&gt;命令行操作方案
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/ynstxx/article/details/129068856&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/ynstxx/article/details/129068856&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;硬盘占满无法开机&#34;&gt;硬盘占满无法开机
&lt;/h3&gt;&lt;p&gt;如果磁盘空间还能支持开机，就开机后使用终端；
如果磁盘已经满了不能正常开机（开机时卡在&lt;code&gt;/dev/sda* clean&lt;/code&gt;），使用CTRL+ALT+F2进入终端界面，输入用户名和密码进入系统。
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/17.png&#34;
	width=&#34;758&#34;
	height=&#34;370&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/17_hu3930587950499533969.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/17_hu821852536552560395.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/18.png&#34;
	width=&#34;974&#34;
	height=&#34;487&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/18_hu8272817670038035462.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/18_hu8275156758171272472.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;
下面就可以按照正常的命令行操作步骤进行操作（按照此方法打开的终端会有文本显示错误的问题，如上图中的棱形，这是中文显示错误，不影响实际操作，为了演示美观，我就不用这个演示了）&lt;/p&gt;
&lt;h3 id=&#34;查看系统占用情况-1&#34;&gt;查看系统占用情况
&lt;/h3&gt;&lt;p&gt;扩展虚拟机空间和查看系统占用情况可参照上述教程
输入命令 &lt;code&gt;sudo fdisk -l&lt;/code&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/19.png&#34;
	width=&#34;755&#34;
	height=&#34;385&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/19_hu12496287535317245089.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/19_hu288711113874393157.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;470px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/20.png&#34;
	width=&#34;603&#34;
	height=&#34;158&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/20_hu7655303471002176168.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/20_hu2602743695652585532.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;381&#34;
		data-flex-basis=&#34;915px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;用parted--l命令解决爆红部分的分区表问题&#34;&gt;用&lt;code&gt;parted -l&lt;/code&gt;命令解决爆红部分的分区表问题
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/21.png&#34;
	width=&#34;758&#34;
	height=&#34;536&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/21_hu12504574874930846555.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/21_hu15701136059759300342.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;339px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;使用parted命令将devsda3扩容&#34;&gt;使用parted命令将&lt;code&gt;/dev/sda3&lt;/code&gt;扩容
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo parted /dev/sda

unit s（设置Size单位）

p free（查看磁盘详情）

resizepart 3（对第3个盘进行扩容）

Yes（分区正在使用中，确认是否继续）

188743646s（需要将磁盘扩容到的大小值，此处参考自己的空间）

q（退出磁盘分区模式）
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/22.png&#34;
	width=&#34;838&#34;
	height=&#34;678&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/22_hu16198667942365521885.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/22_hu10614763616713566062.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;123&#34;
		data-flex-basis=&#34;296px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;使用sudo-resize2fs-devsda3命令更新磁盘3的容量&#34;&gt;使用&lt;code&gt;sudo resize2fs /dev/sda3&lt;/code&gt;命令更新磁盘3的容量
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo resize2fs /dev/sda3
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;再次通过df--h或者sudo-fdisk--l命令查看磁盘情况&#34;&gt;再次通过&lt;code&gt;df -h&lt;/code&gt;或者&lt;code&gt;sudo fdisk -l&lt;/code&gt;命令查看磁盘情况
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;df -h
sudo fdisk -l
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/23.png&#34;
	width=&#34;687&#34;
	height=&#34;392&#34;
	srcset=&#34;https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/23_hu14240377433136994924.png 480w, https://rusthx.github.io/p/ubuntu22.04%E6%89%A9%E5%B1%95%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/23_hu2204547631708861333.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;420px&#34;
	
&gt;
扩容完成，如果是硬盘占满通过CTRL+ALT+F2打开的终端，此时输入命令&lt;code&gt;reboot&lt;/code&gt;重启电脑即可正常启动&lt;/p&gt;
</description>
        </item>
        <item>
        <title>VMvare安装配置Ubuntu虚拟机</title>
        <link>https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/</link>
        <pubDate>Tue, 03 Sep 2024 23:14:48 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/</guid>
        <description>&lt;h2 id=&#34;安装虚拟机&#34;&gt;安装虚拟机
&lt;/h2&gt;&lt;h3 id=&#34;下载vmvare&#34;&gt;下载vmvare
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.vmware.com/products/desktop-hypervisor.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.vmware.com/products/desktop-hypervisor.html&lt;/a&gt;
现在的vmvare安装变得麻烦起来了，还要登陆网站。这里我用的是我之前下载的vmvare16pro。如果官网下载不太容易也可以直接搜索vmvare16安装，浏览器上应该还有留存的资源。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/1.png&#34;
	width=&#34;1762&#34;
	height=&#34;927&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/1_hu16557380544197006931.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/1_hu12099559846922593663.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;456px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;下载ubuntu2404&#34;&gt;下载Ubuntu24.04
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://cn.ubuntu.com/download/desktop&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://cn.ubuntu.com/download/desktop&lt;/a&gt;
Ubuntu的镜像文件大了很多，Ubuntu22.04只有3G左右，Ubuntu24.04就已经5G了。自行选择吧，两种都可以。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/2.png&#34;
	width=&#34;1588&#34;
	height=&#34;799&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/2_hu5034123142382739712.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/2_hu16011023535640819816.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装虚拟机-1&#34;&gt;安装虚拟机
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/3.png&#34;
	width=&#34;1718&#34;
	height=&#34;888&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/3_hu15028365153493613592.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/3_hu15452238232751100552.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/4.png&#34;
	width=&#34;571&#34;
	height=&#34;540&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/4_hu1906887181596660575.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/4_hu1601084356099696181.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;253px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/5.png&#34;
	width=&#34;561&#34;
	height=&#34;540&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/5_hu12018164241888597293.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/5_hu9722857219868767260.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;103&#34;
		data-flex-basis=&#34;249px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/6.png&#34;
	width=&#34;568&#34;
	height=&#34;544&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/6_hu17938781139678690530.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/6_hu12451276316271238826.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;250px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/7.png&#34;
	width=&#34;573&#34;
	height=&#34;537&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/7_hu6471993612658994229.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/7_hu17382715070509250368.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/8.png&#34;
	width=&#34;568&#34;
	height=&#34;537&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/8_hu13202302061932934917.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/8_hu17743998864326022790.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;253px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/9.png&#34;
	width=&#34;573&#34;
	height=&#34;545&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/9_hu2745729919336683621.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/9_hu639251567336138858.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;252px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这次设置多少其实都可以，但是建议不要给的太少。尤其是磁盘空间，调整起来有点麻烦。官网给了最少资源。个人建议初始安装内存给4G，磁盘给40G。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/10.png&#34;
	width=&#34;576&#34;
	height=&#34;546&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/10_hu5758192834789665648.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/10_hu15642381799053459483.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;253px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/11.png&#34;
	width=&#34;566&#34;
	height=&#34;542&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/11_hu13281064805977630105.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/11_hu12367515838884204110.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;250px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/12.png&#34;
	width=&#34;570&#34;
	height=&#34;534&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/12_hu3522227781166646788.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/12_hu7136029950188540953.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/13.png&#34;
	width=&#34;565&#34;
	height=&#34;539&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/13_hu8819568958471314455.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/13_hu13586334632508796147.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;251px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/14.png&#34;
	width=&#34;569&#34;
	height=&#34;546&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/14_hu6540135934770001600.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/14_hu10417702362518257062.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;250px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/15.png&#34;
	width=&#34;573&#34;
	height=&#34;539&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/15_hu7952648301021769732.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/15_hu3608462757434159084.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;255px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/16.png&#34;
	width=&#34;574&#34;
	height=&#34;534&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/16_hu16530258296814023170.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/16_hu4541536905588181365.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;107&#34;
		data-flex-basis=&#34;257px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/17.png&#34;
	width=&#34;569&#34;
	height=&#34;541&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/17_hu6189455046104476310.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/17_hu15990332048400057851.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;252px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/18.png&#34;
	width=&#34;863&#34;
	height=&#34;975&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/18_hu3096994197635748497.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/18_hu10327417413162066484.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;212px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/19.png&#34;
	width=&#34;1446&#34;
	height=&#34;756&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/19_hu12548177497760397300.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/19_hu6988785480551902577.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;459px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/20.png&#34;
	width=&#34;1709&#34;
	height=&#34;903&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/20_hu12579660711719448843.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/20_hu4587039506186872072.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;454px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/21.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/21_hu10420091755745894221.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/21_hu3377065777164935675.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/22.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/22_hu11295597172791205370.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/22_hu5523378164038518786.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/23.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/23_hu7497618973226286304.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/23_hu8533696951094452684.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/24.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/24_hu14030744347810444039.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/24_hu9539955547272611243.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/25.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/25_hu5905385333063574499.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/25_hu15819918448633135432.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
这里安装扩展集合也可以，会比默认集合多装一些办公应用、视频播放器之类的东西。&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/26.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/26_hu1787816568771006314.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/26_hu735685695584713460.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/27.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/27_hu16091323265296203925.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/27_hu9384123171394196745.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/28.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/28_hu492185345550698962.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/28_hu5439676092115104215.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
谨慎设置用户名，电脑主机名修改比较容易，但是用户名修改比较困难。密码的话随意设置一个就可以。反正虚拟机是学习使用，太复杂的还是防自己罢了。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/29.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/29_hu8785505390027796326.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/29_hu13560469346167128808.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/30.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/30_hu14798414081270724491.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/30_hu9865016295976400892.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/31.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/31_hu12051295113381248772.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/31_hu14975761621986591206.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
这个安装过程可能会很慢，应该会花几分钟。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/32.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/32_hu7425494666619658598.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/32_hu15729690338553605309.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/33.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/33_hu9017715892290158905.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/33_hu4445784544299796534.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
重启后会提示按enter键。&lt;/p&gt;
&lt;h2 id=&#34;ubuntu配置&#34;&gt;Ubuntu配置
&lt;/h2&gt;&lt;h3 id=&#34;配置网络&#34;&gt;配置网络
&lt;/h3&gt;&lt;p&gt;刚安装的虚拟机里没有网，需要手动设置网络。设置网络有两种，一种是修改配置文件，一种是可视化界面（GUI）修改。我个人倾向GUI修改。
配置文件修改的方案参考&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/zyw2002/article/details/123486055&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/zyw2002/article/details/123486055&lt;/a&gt; 的2.2小节
可视化界面修改网络配置信息步骤如下：
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/34.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/34_hu13286299046669570766.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/34_hu455850788699419707.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/35.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/35_hu3009377958740211709.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/35_hu15917547603358531633.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
点击左上角的编辑，虚拟网络编辑器，VMnet8。记住子网IP。比如我的是192.168.146.0
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/36.png&#34;
	width=&#34;603&#34;
	height=&#34;499&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/36_hu17394159914278540588.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/36_hu1194596890129698324.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;290px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/37.png&#34;
	width=&#34;706&#34;
	height=&#34;678&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/37_hu7011728155877382789.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/37_hu16209175943937799583.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;249px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/38.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/38_hu15343548983789215768.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/38_hu18169459468758911853.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
我的VMnet8子网ip为192.168.146.0。所以这里ip地址我填入了192.168.146.xxx（这里xxx可以填入小于255的数，但是建议不要填10以内的数）。子网掩码填入255.255.255.0即可。网关和DNS参照我的填入即可。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/39.png&#34;
	width=&#34;1280&#34;
	height=&#34;800&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/39_hu3831698291706307480.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/39_hu18404129481492276149.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
应用配置后重启一下连接就可以正常连接网络。右上角的网络标记变成图中的标志时就表示联网正常。没有可视化界面的可以ping一下外网查看情况。&lt;code&gt;ping baidu.com&lt;/code&gt;。按CTRL+C即可终止命令。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/40.png&#34;
	width=&#34;598&#34;
	height=&#34;134&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/40_hu17376055650997726811.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/40_hu9538698749771221281.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;446&#34;
		data-flex-basis=&#34;1071px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装vmtools&#34;&gt;安装vmtools
&lt;/h3&gt;&lt;p&gt;安装vmtools后可以解决屏幕显示比例的问题，可以在虚拟机外复制然后粘贴到虚拟机里，这很重要！
右键，在终端中打开。安装命令如下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt update
sudo apt install open-vm-tools -y
sudo apt install open-vm-tools-desktop -y
sudo reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/41.png&#34;
	width=&#34;810&#34;
	height=&#34;431&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/41_hu11721447381091044109.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/41_hu1019678563954530347.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;451px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/42.png&#34;
	width=&#34;806&#34;
	height=&#34;361&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/42_hu6082613264663902680.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/42_hu4011609726656300791.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;535px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/43.png&#34;
	width=&#34;637&#34;
	height=&#34;197&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/43_hu18145367479649830960.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/43_hu17543789475112457655.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;776px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;配置用户免密&#34;&gt;配置用户免密
&lt;/h3&gt;&lt;p&gt;在使用sudo命令时普通用户需要输入密码。每次都需要输入密码很麻烦，设置免密后使用sudo就不需要再输入密码。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo passwd root #给root用户设置一个密码
sudo apt install gedit # gedit是一个文本编辑器，可以让ubuntu上编辑文件像Windows的记事本
sudo apt install vim #vim 是一个纯终端的文本编辑器
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/44.png&#34;
	width=&#34;347&#34;
	height=&#34;119&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/44_hu7359312516820342846.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/44_hu17787348785431070939.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;291&#34;
		data-flex-basis=&#34;699px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/45.png&#34;
	width=&#34;719&#34;
	height=&#34;311&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/45_hu4945677856340161550.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/45_hu5317292109880695809.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;554px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/46.png&#34;
	width=&#34;583&#34;
	height=&#34;436&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/46_hu7038207894010284767.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/46_hu10892438613526012861.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo chmod 777 /etc/sudoers # /etc/sudoers是一个只读文件，需要修改权限
su root
gedit /etc/sudoers #在文件中添加如下标注部分
chmod 440 /etc/sudoers #将文件权限修改回来，解决报错/etc/sudoers可被任何人写
exit;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/47.png&#34;
	width=&#34;412&#34;
	height=&#34;28&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/47_hu12680780704706754853.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/47_hu16165549152694486022.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1471&#34;
		data-flex-basis=&#34;3531px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/48.png&#34;
	width=&#34;1718&#34;
	height=&#34;888&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/48_hu7468098753458918934.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/48_hu361869018477048918.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/49.png&#34;
	width=&#34;593&#34;
	height=&#34;363&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/49_hu17408402789675260201.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/49_hu7080031693843312013.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;392px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装ssh&#34;&gt;安装SSH
&lt;/h3&gt;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install openssh-server
sudo gedit /etc/ssh/sshd_config
reboot #重启生效设置
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/50.png&#34;
	width=&#34;569&#34;
	height=&#34;232&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/50_hu10880904346983278671.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/50_hu14808256641867900731.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;588px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/51.png&#34;
	width=&#34;1718&#34;
	height=&#34;888&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/51_hu5090744386881797321.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/51_hu18060283699003644061.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;
尝试ssh远程登陆
设置主机映射
修改Windows的&lt;code&gt;C:\Windows\System32\drivers\etc&lt;/code&gt;下的hosts文件。这里修改可能会有权限问题，可以复制hosts文件，粘贴到能修改的地方，比如桌面。修改完成后删除&lt;code&gt;C:\Windows\System32\drivers\etc&lt;/code&gt;下的hosts，将修改后的hosts文件粘贴进来。
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/52.png&#34;
	width=&#34;805&#34;
	height=&#34;262&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/52_hu14003622279397167009.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/52_hu7574007154804546225.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;307&#34;
		data-flex-basis=&#34;737px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/53.png&#34;
	width=&#34;784&#34;
	height=&#34;865&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/53_hu11982123495247602341.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/53_hu10618876749760878688.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;90&#34;
		data-flex-basis=&#34;217px&#34;
	
&gt;
打开Windows的命令终端，输入命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ssh rust@bird # rust为ubuntu的用户名，bird为刚才设置的主机映射名
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/54.png&#34;
	width=&#34;1483&#34;
	height=&#34;762&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/54_hu4899606701917429376.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/54_hu13328165002540383673.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装java&#34;&gt;安装Java
&lt;/h3&gt;&lt;p&gt;Ubuntu安装java可以手动安装，也可以命令行安装。手动安装需要设置环境变量，建议使用命令行安装。命令行安装卸载比较方便。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo apt-get install openjdk-8-jdk
java -version  #查看安装是否成功
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/55.png&#34;
	width=&#34;739&#34;
	height=&#34;276&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/55_hu13542097576863628029.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/55_hu7571619688027331613.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;267&#34;
		data-flex-basis=&#34;642px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/56.png&#34;
	width=&#34;680&#34;
	height=&#34;96&#34;
	srcset=&#34;https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/56_hu17584511672992408648.png 480w, https://rusthx.github.io/p/vmvare%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA/56_hu7429805898108029076.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;708&#34;
		data-flex-basis=&#34;1700px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>https://rusthx.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://rusthx.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>关于</title>
        <link>https://rusthx.github.io/%E5%85%B3%E4%BA%8E/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://rusthx.github.io/%E5%85%B3%E4%BA%8E/</guid>
        <description>&lt;p&gt;This is a test page for i18n support.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>链接</title>
        <link>https://rusthx.github.io/%E9%93%BE%E6%8E%A5/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://rusthx.github.io/%E9%93%BE%E6%8E%A5/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;links:
  - title: GitHub
    description: GitHub is the world&#39;s largest software development platform.
    website: https://github.com
    image: https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
  - title: TypeScript
    description: TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.
    website: https://www.typescriptlang.org
    image: ts-logo-128.jpg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索</title>
        <link>https://rusthx.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://rusthx.github.io/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
