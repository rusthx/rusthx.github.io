<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>SparkStreaming on rustWood</title>
        <link>https://rusthx.github.io/tags/sparkstreaming/</link>
        <description>Recent content in SparkStreaming on rustWood</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>rustWood</copyright>
        <lastBuildDate>Sat, 07 Sep 2024 11:55:09 +0800</lastBuildDate><atom:link href="https://rusthx.github.io/tags/sparkstreaming/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>SparkStreaming使用socket</title>
        <link>https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/</link>
        <pubDate>Sat, 07 Sep 2024 11:55:09 +0800</pubDate>
        
        <guid>https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV11A411L7CK?p=188&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV11A411L7CK?p=188&amp;amp;vd_source=2db7c64d895a2907954a5b8725db55d5&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;终端打印大量日志影响结果查看可以看我首页的博客解决。
踩坑如下：
1.socket编程不会，写socket发送数据查了很多资料才写出来
2.Windows没有netcat命令，但是MACOS和Ubuntu有,所以理所当然的想到用虚拟机的端口来收集数据和输入数据，事实上这个想法确实没有问题，分别做的话是能正常实现的，但是这也为后续的错误埋下了大坑。想当然的把socket当成kafka用（producer和consumer），是我踩坑的一大原因。
3.被教程误导，socket发送数据到端口，但是不知道socket有服务器和客户端之分，发送数据和处理数据的都是客户端，导致发送端可以和nc -lk &lt;Port&gt;结合使用，能正常监听到数据；接收端也能和nc -lk &lt;Port&gt;结合使用，在监听的端口出输入数据可以正常计算；但是两者结合就没办法计算了&lt;/p&gt;
&lt;h2 id=&#34;windows安装netcat&#34;&gt;Windows安装netcat
&lt;/h2&gt;&lt;p&gt;下载链接： &lt;a class=&#34;link&#34; href=&#34;https://nmap.org/download.html#windows&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://nmap.org/download.html#windows&lt;/a&gt;
下载的是一个exe包，点击exe包一路next即可完成安装。&lt;/p&gt;
&lt;p&gt;端口同时接收数据和计算数据时使用命令监听会无法访问，即启动socket数据发送程序和SparkStreaming数据计算程序后无法监听。但是监听命令可以用来分别调试两个程序。&lt;/p&gt;
&lt;p&gt;注意：Windows的netcat命令与Ubuntu和MacOS都不一样。Windows的命令是 &lt;code&gt;ncat -lk &amp;lt;Port&amp;gt;&lt;/code&gt;，参数的意思可以通过&lt;code&gt;ncat -h&lt;/code&gt;查看。
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1.png&#34;
	width=&#34;960&#34;
	height=&#34;634&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1_hu3612333662547381058.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/1_hu16466038784867921191.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;363px&#34;
	
&gt;
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2.png&#34;
	width=&#34;1481&#34;
	height=&#34;760&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2_hu3790405143218445351.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/2_hu11535289130947449563.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;sparkstreaming-socket编程&#34;&gt;SparkStreaming socket编程
&lt;/h2&gt;&lt;p&gt;题目：1）写一个应用程序利用套接字每隔2秒生成20条大学主页用户访问日志（可以自定义内容），数据形式如下：“系统时间戳，位置城市，用户ID+姓名，访问大学主页”。其中城市自定义 9个，用户ID 10个，大学主页 7个。
2）写第二个程序每隔2秒不断获取套接字产生的数据，并将词频统计结果打印出来。
导入依赖&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spark-streaming_2.12&amp;lt;/artifactId&amp;gt;
   &amp;lt;version&amp;gt;3.3.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SparkStreaming1

import java.io.{BufferedWriter, IOException, OutputStreamWriter}
import java.net.ServerSocket
import scala.util.Random

object task11 {
  def main(args: Array[String]): Unit = {

    // 定义城市和用户ID
    val cities = Seq(&amp;quot;杭州&amp;quot;, &amp;quot;南京&amp;quot;, &amp;quot;长沙&amp;quot;, &amp;quot;天津&amp;quot;, &amp;quot;北京&amp;quot;, &amp;quot;上海&amp;quot;, &amp;quot;成都&amp;quot;, &amp;quot;广州&amp;quot;, &amp;quot;深圳&amp;quot;)
    val userIds = Seq(&amp;quot;0:阿良良木历&amp;quot;, &amp;quot;1:忍野忍&amp;quot;, &amp;quot;2:战场原黑仪&amp;quot;, &amp;quot;3:羽川翼&amp;quot;, &amp;quot;4:八九寺真宵&amp;quot;,
      &amp;quot;5:神原骏河&amp;quot;, &amp;quot;6:千石抚子&amp;quot;, &amp;quot;7:阿良良木火怜&amp;quot;, &amp;quot;8:阿良良木月火&amp;quot;, &amp;quot;9:姬丝秀忒·雅赛劳拉莉昂·刃下心&amp;quot;)
    val universityUrls = Seq(&amp;quot;www.nju.edu.cn&amp;quot;, &amp;quot;www.ustc.edu.cn&amp;quot;,
      &amp;quot;www.zju.edu.cn&amp;quot;, &amp;quot;www.fudan.edu.cn&amp;quot;, &amp;quot;www.tsinghua.edu.cn&amp;quot;, &amp;quot;www.pku.edu.cn&amp;quot;, &amp;quot;www.scu.edu.cn&amp;quot;)

    try {
      // 创建一个 socket 连接
//      val socket = new Socket(&amp;quot;hadoop3&amp;quot;, 9765)
      val socketServer = new ServerSocket(9765)
      val client = socketServer.accept()
      println(&amp;quot;连接！&amp;quot;)
      val out = new BufferedWriter(new OutputStreamWriter(client.getOutputStream))
//val in = new BufferedReader(new InputStreamReader(client.getInputStream))
      while (true){
        for (_ &amp;lt;- 1 to 20) {
          // 发送多条数据
          val currentTime = System.currentTimeMillis()
          val city = cities(Random.nextInt(cities.length))
          val userId = userIds(Random.nextInt(userIds.length))
          val universityUrl = universityUrls(Random.nextInt(universityUrls.length))
          val logLine = s&amp;quot;$currentTime $city $userId $universityUrl&amp;quot;

          out.write(logLine + &amp;quot;\n&amp;quot;) // 添加换行符以区分消息
          out.flush() // 确保数据被发送出去
          println(logLine)
        }
        Thread.sleep(2000) // 休眠2秒，模拟连续发送
      }

      // 关闭 socket
      out.close()
//      socket.close()
      client.close()
    } catch {
      case e: IOException =&amp;gt;
        e.printStackTrace()
    }

  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;package SparkStreaming1

import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession
import org.apache.spark.streaming.{Seconds, StreamingContext}


object task12{
  def main(args: Array[String]): Unit = {
    val sparkConf: SparkConf = new SparkConf().setMaster(&amp;quot;local[*]&amp;quot;).setAppName(&amp;quot;job7task12&amp;quot;)
    val spark = SparkSession.builder().config(sparkConf).getOrCreate()
    val ssc = new StreamingContext(spark.sparkContext, Seconds(2))

    // 从套接字获取数据流
    val lines = ssc.socketTextStream(&amp;quot;localhost&amp;quot;, 9765)
    
    lines.map(_.split(&amp;quot; &amp;quot;)(2))
      .map((_, 1))
      .reduceByKey(_ + _)
      .print()
    
    ssc.start()

    ssc.awaitTermination()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启动时需要先启动数据计算程序，再启动数据发送程序。
成功运行截图：
&lt;img src=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3.png&#34;
	width=&#34;692&#34;
	height=&#34;371&#34;
	srcset=&#34;https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3_hu4369904911137244949.png 480w, https://rusthx.github.io/p/sparkstreaming%E4%BD%BF%E7%94%A8socket/3_hu4522820763415712476.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;447px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
